
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>LayerShuffle: Enhancing Robustness in Vision Transformers by Randomizing Layer Execution Order</title>
        <style>
            body { font-family: Arial, sans-serif; line-height: 1.6; padding: 20px; max-width: 800px; margin: 0 auto; }
            h1 { color: #333; }
            .authors { font-style: italic; color: #666; margin-bottom: 20px; }
            .summary, .reasoning { background-color: #f9f9f9; padding: 15px; border-radius: 5px; margin-bottom: 20px; }
            .paper-link { display: inline-block; background-color: #4CAF50; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px; margin-top: 20px; }
            .paper-link:hover { background-color: #45a049; }
            .ai-notice { font-size: 0.8em; text-align: right; margin-top: 20px; color: #999; }
        </style>
    </head>
    <body>
        <h1>LayerShuffle: Enhancing Robustness in Vision Transformers by Randomizing Layer Execution Order</h1>
        <p><strong>Date:</strong> 2024-07-05</p>
        <p class="authors"><strong>Authors:</strong> ['Matthias Freiberger', 'Peter Kun', 'Anders Sundnes LÃ¸vlie', 'Sebastian Risi']</p>
        <div class="summary">
            <h2>Abstract</h2>
            <p>Due to their architecture and how they are trained, artificial neural
networks are typically not robust toward pruning, replacing, or shuffling
layers at test time. However, such properties would be desirable for different
applications, such as distributed neural network architectures where the order
of execution cannot be guaranteed or parts of the network can fail during
inference. In this work, we address these issues through a number of proposed
training approaches for vision transformers whose most important component is
randomizing the execution order of attention modules at training time. We show
that with our proposed approaches, vision transformers are indeed capable to
adapt to arbitrary layer execution orders at test time assuming one tolerates a
reduction (about 20\%) in accuracy at the same model size. We also find that
our trained models can be randomly merged with each other resulting in
functional ("Frankenstein") models without loss of performance compared to the
source models. Finally, we layer-prune our models at test time and find that
their performance declines gracefully.</p>
        </div>
        <div class="reasoning">
            <h2>AI-Generated Summary</h2>
            <p>The paper focuses on training approaches for vision transformers, including randomizing the execution order of attention modules, a key aspect of prompt engineering.</p>
        </div>
        <a href="http://arxiv.org/pdf/2407.04513v1" class="paper-link" target="_blank">Read the full paper</a>
        <p class="ai-notice">The summary is AI-generated and may not perfectly reflect the paper's content.</p>
    </body>
    </html>
    