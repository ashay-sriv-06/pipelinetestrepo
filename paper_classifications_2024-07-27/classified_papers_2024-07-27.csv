title,authors,abstract,pdf_url,published,arxiv_id,Title,Model,Rating,Reasoning
Exploring Scaling Trends in LLM Robustness,"['Nikolhaus Howe', 'Micha≈Ç Zajac', 'Ian McKenzie', 'Oskar Hollinsworth', 'Tom Tseng', 'Pierre-Luc Bacon', 'Adam Gleave']","Language model capabilities predictably improve from scaling a model's size
and training data. Motivated by this, increasingly large language models have
been trained, yielding an array of impressive capabilities. Yet these models
are vulnerable to adversarial prompts, such as ""jailbreaks"" that hijack models
to perform undesired behaviors, posing a significant risk of misuse. Prior work
indicates that computer vision models become more robust with model and data
scaling, raising the question: does language model robustness also improve with
scale? We study this question empirically, finding that larger models respond
substantially better to adversarial training, but there is little to no benefit
from model scale in the absence of explicit defenses.",http://arxiv.org/pdf/2407.18213v1,2024-07-25,2407.18213v1,Exploring Scaling Trends in LLM Robustness,gpt-4,somewhat relevant,"The paper discusses the role of adversarial prompts in the context of large language models, but does not primarily focus on the specific techniques or the engineering of hard prefix prompts."
AttentionHand: Text-driven Controllable Hand Image Generation for 3D Hand Reconstruction in the Wild,"['Junho Park', 'Kyeongbo Kong', 'Suk-Ju Kang']","Recently, there has been a significant amount of research conducted on 3D
hand reconstruction to use various forms of human-computer interaction.
However, 3D hand reconstruction in the wild is challenging due to extreme lack
of in-the-wild 3D hand datasets. Especially, when hands are in complex pose
such as interacting hands, the problems like appearance similarity, self-handed
occclusion and depth ambiguity make it more difficult. To overcome these
issues, we propose AttentionHand, a novel method for text-driven controllable
hand image generation. Since AttentionHand can generate various and numerous
in-the-wild hand images well-aligned with 3D hand label, we can acquire a new
3D hand dataset, and can relieve the domain gap between indoor and outdoor
scenes. Our method needs easy-to-use four modalities (i.e, an RGB image, a hand
mesh image from 3D label, a bounding box, and a text prompt). These modalities
are embedded into the latent space by the encoding phase. Then, through the
text attention stage, hand-related tokens from the given text prompt are
attended to highlight hand-related regions of the latent embedding. After the
highlighted embedding is fed to the visual attention stage, hand-related
regions in the embedding are attended by conditioning global and local hand
mesh images with the diffusion-based pipeline. In the decoding phase, the final
feature is decoded to new hand images, which are well-aligned with the given
hand mesh image and text prompt. As a result, AttentionHand achieved
state-of-the-art among text-to-hand image generation models, and the
performance of 3D hand mesh reconstruction was improved by additionally
training with hand images generated by AttentionHand.",http://arxiv.org/pdf/2407.18034v1,2024-07-25,2407.18034v1,AttentionHand: Text-driven Controllable Hand Image Generation for 3D Hand Reconstruction in the Wild,gpt-4,somewhat relevant,"The paper explores the creation of a model for text-driven hand image generation in order to facilitate 3D hand reconstruction in complex scenarios. Though it mentions the use of text prompts in its method, it appears that this technique is not focused on or specifically related to hard prefix prompting or prompt engineering."
GermanPartiesQA: Benchmarking Commercial Large Language Models for Political Bias and Sycophancy,"['Jan Batzner', 'Volker Stocker', 'Stefan Schmid', 'Gjergji Kasneci']","LLMs are changing the way humans create and interact with content,
potentially affecting citizens' political opinions and voting decisions. As
LLMs increasingly shape our digital information ecosystems, auditing to
evaluate biases, sycophancy, or steerability has emerged as an active field of
research. In this paper, we evaluate and compare the alignment of six LLMs by
OpenAI, Anthropic, and Cohere with German party positions and evaluate
sycophancy based on a prompt experiment. We contribute to evaluating political
bias and sycophancy in multi-party systems across major commercial LLMs. First,
we develop the benchmark dataset GermanPartiesQA based on the Voting Advice
Application Wahl-o-Mat covering 10 state and 1 national elections between 2021
and 2023. In our study, we find a left-green tendency across all examined LLMs.
We then conduct our prompt experiment for which we use the benchmark and
sociodemographic data of leading German parliamentarians to evaluate changes in
LLMs responses. To differentiate between sycophancy and steerabilty, we use 'I
am [politician X], ...' and 'You are [politician X], ...' prompts. Against our
expectations, we do not observe notable differences between prompting 'I am'
and 'You are'. While our findings underscore that LLM responses can be
ideologically steered with political personas, they suggest that observed
changes in LLM outputs could be better described as personalization to the
given context rather than sycophancy.",http://arxiv.org/pdf/2407.18008v1,2024-07-25,2407.18008v1,GermanPartiesQA: Benchmarking Commercial Large Language Models for Political Bias and Sycophancy,gpt-4,somewhat relevant,"The paper touches upon the use of prompts for experimenting with the responses of large language models, particularly in the context of political bias and steerability. However, it doesn't focus on or discuss the specific methods of prompt engineering."
The Power of Combining Data and Knowledge: GPT-4o is an Effective Interpreter of Machine Learning Models in Predicting Lymph Node Metastasis of Lung Cancer,"['Danqing Hu', 'Bing Liu', 'Xiaofeng Zhu', 'Nan Wu']","Lymph node metastasis (LNM) is a crucial factor in determining the initial
treatment for patients with lung cancer, yet accurate preoperative diagnosis of
LNM remains challenging. Recently, large language models (LLMs) have garnered
significant attention due to their remarkable text generation capabilities.
Leveraging the extensive medical knowledge learned from vast corpora, LLMs can
estimate probabilities for clinical problems, though their performance has
historically been inferior to data-driven machine learning models. In this
paper, we propose a novel ensemble method that combines the medical knowledge
acquired by LLMs with the latent patterns identified by machine learning models
to enhance LNM prediction performance. Initially, we developed machine learning
models using patient data. We then designed a prompt template to integrate the
patient data with the predicted probability from the machine learning model.
Subsequently, we instructed GPT-4o, the most advanced LLM developed by OpenAI,
to estimate the likelihood of LNM based on patient data and then adjust the
estimate using the machine learning output. Finally, we collected three outputs
from the GPT-4o using the same prompt and ensembled these results as the final
prediction. Using the proposed method, our models achieved an AUC value of
0.765 and an AP value of 0.415 for LNM prediction, significantly improving
predictive performance compared to baseline machine learning models. The
experimental results indicate that GPT-4o can effectively leverage its medical
knowledge and the probabilities predicted by machine learning models to achieve
more accurate LNM predictions. These findings demonstrate that LLMs can perform
well in clinical risk prediction tasks, offering a new paradigm for integrating
medical knowledge and patient data in clinical predictions.",http://arxiv.org/pdf/2407.17900v1,2024-07-25,2407.17900v1,The Power of Combining Data and Knowledge: GPT-4o is an Effective Interpreter of Machine Learning Models in Predicting Lymph Node Metastasis of Lung Cancer,gpt-4,somewhat relevant,"While the paper involves the use of a prompt in a language model, GPT-4o, it primarily discusses using this model as part of an ensemble method to improve cancer prognosis, rather than focusing on the technique of prompt engineering itself."
The Dark Side of Function Calling: Pathways to Jailbreaking Large Language Models,"['Zihui Wu', 'Haichang Gao', 'Jianping He', 'Ping Wang']","Large language models (LLMs) have demonstrated remarkable capabilities, but
their power comes with significant security considerations. While extensive
research has been conducted on the safety of LLMs in chat mode, the security
implications of their function calling feature have been largely overlooked.
This paper uncovers a critical vulnerability in the function calling process of
LLMs, introducing a novel ""jailbreak function"" attack method that exploits
alignment discrepancies, user coercion, and the absence of rigorous safety
filters. Our empirical study, conducted on six state-of-the-art LLMs including
GPT-4o, Claude-3.5-Sonnet, and Gemini-1.5-pro, reveals an alarming average
success rate of over 90\% for this attack. We provide a comprehensive analysis
of why function calls are susceptible to such attacks and propose defensive
strategies, including the use of defensive prompts. Our findings highlight the
urgent need for enhanced security measures in the function calling capabilities
of LLMs, contributing to the field of AI safety by identifying a previously
unexplored risk, designing an effective attack method, and suggesting practical
defensive measures. Our code is available at
https://github.com/wooozihui/jailbreakfunction.",http://arxiv.org/pdf/2407.17915v1,2024-07-25,2407.17915v1,The Dark Side of Function Calling: Pathways to Jailbreaking Large Language Models,gpt-4,neutrally relevant,"The paper speaks about function calling in large language models and its security considerations. Although it mentions the use of defensive prompts, it does not specify whether these are hard prefix prompts or even relates to the process of prompt engineering."
Recursive Introspection: Teaching Language Model Agents How to Self-Improve,"['Yuxiao Qu', 'Tianjun Zhang', 'Naman Garg', 'Aviral Kumar']","A central piece in enabling intelligent agentic behavior in foundation models
is to make them capable of introspecting upon their behavior, reasoning, and
correcting their mistakes as more computation or interaction is available. Even
the strongest proprietary large language models (LLMs) do not quite exhibit the
ability of continually improving their responses sequentially, even in
scenarios where they are explicitly told that they are making a mistake. In
this paper, we develop RISE: Recursive IntroSpEction, an approach for
fine-tuning LLMs to introduce this capability, despite prior work hypothesizing
that this capability may not be possible to attain. Our approach prescribes an
iterative fine-tuning procedure, which attempts to teach the model how to alter
its response after having executed previously unsuccessful attempts to solve a
hard test-time problem, with optionally additional environment feedback. RISE
poses fine-tuning for a single-turn prompt as solving a multi-turn Markov
decision process (MDP), where the initial state is the prompt. Inspired by
principles in online imitation learning and reinforcement learning, we propose
strategies for multi-turn data collection and training so as to imbue an LLM
with the capability to recursively detect and correct its previous mistakes in
subsequent iterations. Our experiments show that RISE enables Llama2, Llama3,
and Mistral models to improve themselves with more turns on math reasoning
tasks, outperforming several single-turn strategies given an equal amount of
inference-time computation. We also find that RISE scales well, often attaining
larger benefits with more capable models. Our analysis shows that RISE makes
meaningful improvements to responses to arrive at the correct solution for
challenging prompts, without disrupting one-turn abilities as a result of
expressing more complex distributions.",http://arxiv.org/pdf/2407.18219v1,2024-07-25,2407.18219v1,Recursive Introspection: Teaching Language Model Agents How to Self-Improve,gpt-4,somewhat irrelevant,"While the paper does use prompts and fine-tuning in an iterative process to improve model responses, it focuses more on model training and addressing model errors but not explicitly on hard prefix prompts or prompt engineering techniques."
Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning,"['Tianduo Wang', 'Shichen Li', 'Wei Lu']","Effective training of language models (LMs) for mathematical reasoning tasks
demands high-quality supervised fine-tuning data. Besides obtaining annotations
from human experts, a common alternative is sampling from larger and more
powerful LMs. However, this knowledge distillation approach can be costly and
unstable, particularly when relying on closed-source, proprietary LMs like
GPT-4, whose behaviors are often unpredictable. In this work, we demonstrate
that the reasoning abilities of small-scale LMs can be enhanced through
self-training, a process where models learn from their own outputs. We also
show that the conventional self-training can be further augmented by a
preference learning algorithm called Direct Preference Optimization (DPO). By
integrating DPO into self-training, we leverage preference data to guide LMs
towards more accurate and diverse chain-of-thought reasoning. We evaluate our
method across various mathematical reasoning tasks using different base models.
Our experiments show that this approach not only improves LMs' reasoning
performance but also offers a more cost-effective and scalable solution
compared to relying on large proprietary LMs.",http://arxiv.org/pdf/2407.18248v1,2024-07-25,2407.18248v1,Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning,gpt-4,highly irrelevant,"The paper focuses on the self-training and process of language models, with no specific mention of prompts or prompt engineering techniques."
LoRA-Pro: Are Low-Rank Adapters Properly Optimized?,"['Zhengbo Wang', 'Jian Liang']","Low-Rank Adaptation, also known as LoRA, has emerged as a prominent method
for parameter-efficient fine-tuning foundation models by re-parameterizing the
original matrix into the product of two low-rank matrices. Despite its
efficiency, LoRA often yields inferior performance compared to full
fine-tuning. In this paper, we propose LoRA-Pro to bridge this performance gap.
Firstly, we delve into the optimization processes in LoRA and full fine-tuning.
We reveal that while LoRA employs low-rank approximation, it neglects to
approximate the optimization process of full fine-tuning. To address this, we
introduce a novel concept called the ""equivalent gradient."" This virtual
gradient makes the optimization process on the re-parameterized matrix
equivalent to LoRA, which can be used to quantify the differences between LoRA
and full fine-tuning. The equivalent gradient is derived from the gradients of
matrices $A$ and $B$. To narrow the performance gap, our approach minimizes the
differences between the equivalent gradient and the gradient obtained from full
fine-tuning during the optimization process. By solving this objective, we
derive optimal closed-form solutions for updating matrices $A$ and $B$. Our
method constrains the optimization process, shrinking the performance gap
between LoRA and full fine-tuning. Extensive experiments on natural language
processing tasks validate the effectiveness of our method.",http://arxiv.org/pdf/2407.18242v1,2024-07-25,2407.18242v1,LoRA-Pro: Are Low-Rank Adapters Properly Optimized?,gpt-4,highly irrelevant,"This paper focuses on fine-tuning models using Low-Rank Adaptation, which is a different topic to hard prefix prompt engineering."
Differentiable Quantum Architecture Search in Asynchronous Quantum Reinforcement Learning,['Samuel Yen-Chi Chen'],"The emergence of quantum reinforcement learning (QRL) is propelled by
advancements in quantum computing (QC) and machine learning (ML), particularly
through quantum neural networks (QNN) built on variational quantum circuits
(VQC). These advancements have proven successful in addressing sequential
decision-making tasks. However, constructing effective QRL models demands
significant expertise due to challenges in designing quantum circuit
architectures, including data encoding and parameterized circuits, which
profoundly influence model performance. In this paper, we propose addressing
this challenge with differentiable quantum architecture search (DiffQAS),
enabling trainable circuit parameters and structure weights using
gradient-based optimization. Furthermore, we enhance training efficiency
through asynchronous reinforcement learning (RL) methods facilitating parallel
training. Through numerical simulations, we demonstrate that our proposed
DiffQAS-QRL approach achieves performance comparable to manually-crafted
circuit architectures across considered environments, showcasing stability
across diverse scenarios. This methodology offers a pathway for designing QRL
models without extensive quantum knowledge, ensuring robust performance and
fostering broader application of QRL.",http://arxiv.org/pdf/2407.18202v1,2024-07-25,2407.18202v1,Differentiable Quantum Architecture Search in Asynchronous Quantum Reinforcement Learning,gpt-4,highly irrelevant,"The paper focuses on quantum reinforcement learning and quantum architectures, without any discussion or mention of hard prefix prompting or prompt engineering."
Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning,"['Sindhura Kommu', 'Yizhi Wang', 'Yue Wang', 'Xuan Wang']","Inferring gene regulatory networks (GRNs) from single-cell RNA sequencing
(scRNA-seq) data is a complex challenge that requires capturing the intricate
relationships between genes and their regulatory interactions. In this study,
we tackle this challenge by leveraging the single-cell BERT-based pre-trained
transformer model (scBERT), trained on extensive unlabeled scRNA-seq data, to
augment structured biological knowledge from existing GRNs. We introduce a
novel joint graph learning approach that combines the rich contextual
representations learned by pre-trained single-cell language models with the
structured knowledge encoded in GRNs using graph neural networks (GNNs). By
integrating these two modalities, our approach effectively reasons over boththe
gene expression level constraints provided by the scRNA-seq data and the
structured biological knowledge inherent in GRNs. We evaluate our method on
human cell benchmark datasets from the BEELINE study with cell type-specific
ground truth networks. The results demonstrate superior performance over
current state-of-the-art baselines, offering a deeper understanding of cellular
regulatory mechanisms.",http://arxiv.org/pdf/2407.18181v1,2024-07-25,2407.18181v1,Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning,gpt-4,highly irrelevant,"This paper revolves around the training and application of pre-trained transformers for gene regulatory network inference, but there are no elements of hard prefix prompt engineering discussed."
"PianoMime: Learning a Generalist, Dexterous Piano Player from Internet Demonstrations","['Cheng Qian', 'Julen Urain', 'Kevin Zakka', 'Jan Peters']","In this work, we introduce PianoMime, a framework for training a
piano-playing agent using internet demonstrations. The internet is a promising
source of large-scale demonstrations for training our robot agents. In
particular, for the case of piano-playing, Youtube is full of videos of
professional pianists playing a wide myriad of songs. In our work, we leverage
these demonstrations to learn a generalist piano-playing agent capable of
playing any arbitrary song. Our framework is divided into three parts: a data
preparation phase to extract the informative features from the Youtube videos,
a policy learning phase to train song-specific expert policies from the
demonstrations and a policy distillation phase to distil the policies into a
single generalist agent. We explore different policy designs to represent the
agent and evaluate the influence of the amount of training data on the
generalization capability of the agent to novel songs not available in the
dataset. We show that we are able to learn a policy with up to 56\% F1 score on
unseen songs.",http://arxiv.org/pdf/2407.18178v1,2024-07-25,2407.18178v1,"PianoMime: Learning a Generalist, Dexterous Piano Player from Internet Demonstrations",gpt-4,highly irrelevant,The paper focuses on training a robot agent to play piano using internet demonstrations and does not discuss or mention anything related to hard prefix prompting or prompt engineering.
Quasar-ViT: Hardware-Oriented Quantization-Aware Architecture Search for Vision Transformers,"['Zhengang Li', 'Alec Lu', 'Yanyue Xie', 'Zhenglun Kong', 'Mengshu Sun', 'Hao Tang', 'Zhong Jia Xue', 'Peiyan Dong', 'Caiwen Ding', 'Yanzhi Wang', 'Xue Lin', 'Zhenman Fang']","Vision transformers (ViTs) have demonstrated their superior accuracy for
computer vision tasks compared to convolutional neural networks (CNNs).
However, ViT models are often computation-intensive for efficient deployment on
resource-limited edge devices. This work proposes Quasar-ViT, a
hardware-oriented quantization-aware architecture search framework for ViTs, to
design efficient ViT models for hardware implementation while preserving the
accuracy. First, Quasar-ViT trains a supernet using our row-wise flexible
mixed-precision quantization scheme, mixed-precision weight entanglement, and
supernet layer scaling techniques. Then, it applies an efficient
hardware-oriented search algorithm, integrated with hardware latency and
resource modeling, to determine a series of optimal subnets from supernet under
different inference latency targets. Finally, we propose a series of
model-adaptive designs on the FPGA platform to support the architecture search
and mitigate the gap between the theoretical computation reduction and the
practical inference speedup. Our searched models achieve 101.5, 159.6, and
251.6 frames-per-second (FPS) inference speed on the AMD/Xilinx ZCU102 FPGA
with 80.4%, 78.6%, and 74.9% top-1 accuracy, respectively, for the ImageNet
dataset, consistently outperforming prior works.",http://arxiv.org/pdf/2407.18175v1,2024-07-25,2407.18175v1,Quasar-ViT: Hardware-Oriented Quantization-Aware Architecture Search for Vision Transformers,gpt-4,highly irrelevant,"The paper is focused on architecture search and optimization of Vision Transformers for computer vision tasks, not on prompt engineering or hard prefix prompting."
The FIGNEWS Shared Task on News Media Narratives,"['Wajdi Zaghouani', 'Mustafa Jarrar', 'Nizar Habash', 'Houda Bouamor', 'Imed Zitouni', 'Mona Diab', 'Samhaa R. El-Beltagy', 'Muhammed AbuOdeh']","We present an overview of the FIGNEWS shared task, organized as part of the
ArabicNLP 2024 conference co-located with ACL 2024. The shared task addresses
bias and propaganda annotation in multilingual news posts. We focus on the
early days of the Israel War on Gaza as a case study. The task aims to foster
collaboration in developing annotation guidelines for subjective tasks by
creating frameworks for analyzing diverse narratives highlighting potential
bias and propaganda. In a spirit of fostering and encouraging diversity, we
address the problem from a multilingual perspective, namely within five
languages: English, French, Arabic, Hebrew, and Hindi. A total of 17 teams
participated in two annotation subtasks: bias (16 teams) and propaganda (6
teams). The teams competed in four evaluation tracks: guidelines development,
annotation quality, annotation quantity, and consistency. Collectively, the
teams produced 129,800 data points. Key findings and implications for the field
are discussed.",http://arxiv.org/pdf/2407.18147v1,2024-07-25,2407.18147v1,The FIGNEWS Shared Task on News Media Narratives,gpt-4,highly irrelevant,"This paper focuses on bias and propaganda annotation in multilingual news posts, not hard prefix prompting or prompt engineering."
Taxonomy-Aware Continual Semantic Segmentation in Hyperbolic Spaces for Open-World Perception,"['Julia Hindel', 'Daniele Cattaneo', 'Abhinav Valada']","Semantic segmentation models are typically trained on a fixed set of classes,
limiting their applicability in open-world scenarios. Class-incremental
semantic segmentation aims to update models with emerging new classes while
preventing catastrophic forgetting of previously learned ones. However,
existing methods impose strict rigidity on old classes, reducing their
effectiveness in learning new incremental classes. In this work, we propose
Taxonomy-Oriented Poincar\'e-regularized Incremental-Class Segmentation
(TOPICS) that learns feature embeddings in hyperbolic space following explicit
taxonomy-tree structures. This supervision provides plasticity for old classes,
updating ancestors based on new classes while integrating new classes at
fitting positions. Additionally, we maintain implicit class relational
constraints on the geometric basis of the Poincar\'e ball. This ensures that
the latent space can continuously adapt to new constraints while maintaining a
robust structure to combat catastrophic forgetting. We also establish eight
realistic incremental learning protocols for autonomous driving scenarios,
where novel classes can originate from known classes or the background.
Extensive evaluations of TOPICS on the Cityscapes and Mapillary Vistas 2.0
benchmarks demonstrate that it achieves state-of-the-art performance. We make
the code and trained models publicly available at
http://topics.cs.uni-freiburg.de.",http://arxiv.org/pdf/2407.18145v1,2024-07-25,2407.18145v1,Taxonomy-Aware Continual Semantic Segmentation in Hyperbolic Spaces for Open-World Perception,gpt-4,highly irrelevant,"The paper focuses on semantic segmentation, incremental learning, and feature embeddings, none of which directly relate to the topic of hard prefix prompt engineering."
Maximum Entropy On-Policy Actor-Critic via Entropy Advantage Estimation,"['Jean Seong Bjorn Choe', 'Jong-Kook Kim']","Entropy Regularisation is a widely adopted technique that enhances policy
optimisation performance and stability. A notable form of entropy
regularisation is augmenting the objective with an entropy term, thereby
simultaneously optimising the expected return and the entropy. This framework,
known as maximum entropy reinforcement learning (MaxEnt RL), has shown
theoretical and empirical successes. However, its practical application in
straightforward on-policy actor-critic settings remains surprisingly
underexplored. We hypothesise that this is due to the difficulty of managing
the entropy reward in practice. This paper proposes a simple method of
separating the entropy objective from the MaxEnt RL objective, which
facilitates the implementation of MaxEnt RL in on-policy settings. Our
empirical evaluations demonstrate that extending Proximal Policy Optimisation
(PPO) and Trust Region Policy Optimisation (TRPO) within the MaxEnt framework
improves policy optimisation performance in both MuJoCo and Procgen tasks.
Additionally, our results highlight MaxEnt RL's capacity to enhance
generalisation.",http://arxiv.org/pdf/2407.18143v1,2024-07-25,2407.18143v1,Maximum Entropy On-Policy Actor-Critic via Entropy Advantage Estimation,gpt-4,highly irrelevant,"The paper discusses various techniques in maximum entropy reinforcement learning and policy optimisation, which does not relate to the concept of hard prefix prompts or prompt engineering."
Dallah: A Dialect-Aware Multimodal Large Language Model for Arabic,"['Fakhraddin Alwajih', 'Gagan Bhatia', 'Muhammad Abdul-Mageed']","Recent advancements have significantly enhanced the capabilities of
Multimodal Large Language Models (MLLMs) in generating and understanding
image-to-text content. Despite these successes, progress is predominantly
limited to English due to the scarcity of high quality multimodal resources in
other languages. This limitation impedes the development of competitive models
in languages such as Arabic. To alleviate this situation, we introduce an
efficient Arabic multimodal assistant, dubbed Dallah, that utilizes an advanced
language model based on LLaMA-2 to facilitate multimodal interactions. Dallah
demonstrates state-of-the-art performance in Arabic MLLMs. Through fine-tuning
six Arabic dialects, Dallah showcases its capability to handle complex
dialectal interactions incorporating both textual and visual elements. The
model excels in two benchmark tests: one evaluating its performance on Modern
Standard Arabic (MSA) and another specifically designed to assess dialectal
responses. Beyond its robust performance in multimodal interaction tasks,
Dallah has the potential to pave the way for further development of
dialect-aware Arabic MLLMs.",http://arxiv.org/pdf/2407.18129v1,2024-07-25,2407.18129v1,Dallah: A Dialect-Aware Multimodal Large Language Model for Arabic,gpt-4,highly irrelevant,"The paper discusses the development of a multimodal language model with a focus on Arabic dialects, but it does not mention anything about prompt engineering or hard prefix prompting."
Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images,"['Roberto Di Via', 'Francesca Odone', 'Vito Paolo Pastore']","In the last few years, deep neural networks have been extensively applied in
the medical domain for different tasks, ranging from image classification and
segmentation to landmark detection. However, the application of these
technologies in the medical domain is often hindered by data scarcity, both in
terms of available annotations and images. This study introduces a new
self-supervised pre-training protocol based on diffusion models for landmark
detection in x-ray images. Our results show that the proposed self-supervised
framework can provide accurate landmark detection with a minimal number of
available annotated training images (up to 50), outperforming ImageNet
supervised pre-training and state-of-the-art self-supervised pre-trainings for
three popular x-ray benchmark datasets. To our knowledge, this is the first
exploration of diffusion models for self-supervised learning in landmark
detection, which may offer a valuable pre-training approach in few-shot
regimes, for mitigating data scarcity.",http://arxiv.org/pdf/2407.18125v1,2024-07-25,2407.18125v1,Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images,gpt-4,highly irrelevant,"The paper focuses on self-supervised pre-training protocols in the context of landmark detection in x-ray images, without any mention of prompt engineering or hard prefix prompting."
Tracking linguistic information in transformer-based sentence embeddings through targeted sparsification,"['Vivi Nastase', 'Paola Merlo']","Analyses of transformer-based models have shown that they encode a variety of
linguistic information from their textual input. While these analyses have shed
a light on the relation between linguistic information on one side, and
internal architecture and parameters on the other, a question remains
unanswered: how is this linguistic information reflected in sentence
embeddings? Using datasets consisting of sentences with known structure, we
test to what degree information about chunks (in particular noun, verb or
prepositional phrases), such as grammatical number, or semantic role, can be
localized in sentence embeddings. Our results show that such information is not
distributed over the entire sentence embedding, but rather it is encoded in
specific regions. Understanding how the information from an input text is
compressed into sentence embeddings helps understand current transformer models
and help build future explainable neural models.",http://arxiv.org/pdf/2407.18119v1,2024-07-25,2407.18119v1,Tracking linguistic information in transformer-based sentence embeddings through targeted sparsification,gpt-4,highly irrelevant,"This paper is focused on the understanding of linguistic information encoding and sentence embedding in a transformer model, not on the specifics of hard prefix prompts or prompt engineering techniques."
MapTune: Advancing ASIC Technology Mapping via Reinforcement Learning Guided Library Tuning,"['Mingju Liu', 'Daniel Robinson', 'Yingjie Li', 'Cunxi Yu']","Technology mapping involves mapping logical circuits to a library of cells.
Traditionally, the full technology library is used, leading to a large search
space and potential overhead. Motivated by randomly sampled technology mapping
case studies, we propose MapTune framework that addresses this challenge by
utilizing reinforcement learning to make design-specific choices during cell
selection. By learning from the environment, MapTune refines the cell selection
process, resulting in a reduced search space and potentially improved mapping
quality.
  The effectiveness of MapTune is evaluated on a wide range of benchmarks,
different technology libraries and technology mappers. The experimental results
demonstrate that MapTune achieves higher mapping accuracy and reducing
delay/area across diverse circuit designs, technology libraries and mappers.
The paper also discusses the Pareto-Optimal exploration and confirms the
perpetual delay-area trade-off. Conducted on benchmark suites ISCAS 85/89,
ITC/ISCAS 99, VTR8.0 and EPFL benchmarks, the post-technology mapping and
post-sizing quality-of-results (QoR) have been significantly improved, with
average Area-Delay Product (ADP) improvement of 22.54\% among all different
exploration settings in MapTune. The improvements are consistently remained for
four different technologies (7nm, 45nm, 130nm, and 180 nm) and two different
mappers.",http://arxiv.org/pdf/2407.18110v1,2024-07-25,2407.18110v1,MapTune: Advancing ASIC Technology Mapping via Reinforcement Learning Guided Library Tuning,gpt-4,highly irrelevant,This paper focuses on technology mapping in ASIC via reinforcement learning which is unrelated to the topic of hard prefix prompt engineering in transformers.
Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping,"['Jack Breen', 'Katie Allen', 'Kieran Zucker', 'Nicolas M. Orsi', 'Nishant Ravikumar']","Computer vision models are increasingly capable of classifying ovarian
epithelial cancer subtypes, but they differ from pathologists by processing
small tissue patches at a single resolution. Multi-resolution graph models
leverage the spatial relationships of patches at multiple magnifications,
learning the context for each patch. In this study, we conduct the most
thorough validation of a graph model for ovarian cancer subtyping to date.
Seven models were tuned and trained using five-fold cross-validation on a set
of 1864 whole slide images (WSIs) from 434 patients treated at Leeds Teaching
Hospitals NHS Trust. The cross-validation models were ensembled and evaluated
using a balanced hold-out test set of 100 WSIs from 30 patients, and an
external validation set of 80 WSIs from 80 patients in the Transcanadian Study.
The best-performing model, a graph model using 10x+20x magnification data, gave
balanced accuracies of 73%, 88%, and 99% in cross-validation, hold-out testing,
and external validation, respectively. However, this only exceeded the
performance of attention-based multiple instance learning in external
validation, with a 93% balanced accuracy. Graph models benefitted greatly from
using the UNI foundation model rather than an ImageNet-pretrained ResNet50 for
feature extraction, with this having a much greater effect on performance than
changing the subsequent classification approach. The accuracy of the combined
foundation model and multi-resolution graph network offers a step towards the
clinical applicability of these models, with a new highest-reported performance
for this task, though further validations are still required to ensure the
robustness and usability of the models.",http://arxiv.org/pdf/2407.18105v1,2024-07-25,2407.18105v1,Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping,gpt-4,highly irrelevant,"The paper is fully focused on the application of computer vision and graph models for ovarian cancer subtyping, without any mention of hard prefix prompting or prompt engineering."
Privacy Threats and Countermeasures in Federated Learning for Internet of Things: A Systematic Review,"['Adel ElZemity', 'Budi Arief']","Federated Learning (FL) in the Internet of Things (IoT) environments can
enhance machine learning by utilising decentralised data, but at the same time,
it might introduce significant privacy and security concerns due to the
constrained nature of IoT devices. This represents a research challenge that we
aim to address in this paper. We systematically analysed recent literature to
identify privacy threats in FL within IoT environments, and evaluate the
defensive measures that can be employed to mitigate these threats. Using a
Systematic Literature Review (SLR) approach, we searched five publication
databases (Scopus, IEEE Xplore, Wiley, ACM, and Science Direct), collating
relevant papers published between 2017 and April 2024, a period which spans
from the introduction of FL until now. Guided by the PRISMA protocol, we
selected 49 papers to focus our systematic review on. We analysed these papers,
paying special attention to the privacy threats and defensive measures --
specifically within the context of IoT -- using inclusion and exclusion
criteria tailored to highlight recent advances and critical insights. We
identified various privacy threats, including inference attacks, poisoning
attacks, and eavesdropping, along with defensive measures such as Differential
Privacy and Secure Multi-Party Computation. These defences were evaluated for
their effectiveness in protecting privacy without compromising the functional
integrity of FL in IoT settings. Our review underscores the necessity for
robust and efficient privacy-preserving strategies tailored for IoT
environments. Notably, there is a need for strategies against replay, evasion,
and model stealing attacks. Exploring lightweight defensive measures and
emerging technologies such as blockchain may help improve the privacy of FL in
IoT, leading to the creation of FL models that can operate under variable
network conditions.",http://arxiv.org/pdf/2407.18096v1,2024-07-25,2407.18096v1,Privacy Threats and Countermeasures in Federated Learning for Internet of Things: A Systematic Review,gpt-4,highly irrelevant,"The paper is focused on Federated Learning (FL) in Internet of Things (IoT) environments, privacy threats and defensive measures. No mention of hard prefix prompts, or any kind of prompting or prompt engineering is present."
PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization,"['Christopher Clarke', 'Yuzhao Heng', 'Lingjia Tang', 'Jason Mars']","The recent emergence of Large Language Models (LLMs) has heralded a new era
of human-AI interaction. These sophisticated models, exemplified by Chat-GPT
and its successors, have exhibited remarkable capabilities in language
understanding. However, as these LLMs have undergone exponential growth, a
crucial dimension that remains understudied is the personalization of these
models. Large foundation models such as GPT-3 etc. focus on creating a
universal model that serves a broad range of tasks and users. This approach
emphasizes the model's generalization capabilities, treating users as a
collective rather than as distinct individuals. While practical for many common
applications, this one-size-fits-all approach often fails to address the rich
tapestry of human diversity and individual needs. To explore this issue we
introduce the PEFT-U Benchmark: a new dataset for building and evaluating NLP
models for user personalization. \datasetname{} consists of a series of
user-centered tasks containing diverse and individualized expressions where the
preferences of users can potentially differ for the same input. Using PEFT-U,
we explore the challenge of efficiently personalizing LLMs to accommodate
user-specific preferences in the context of diverse user-centered tasks.",http://arxiv.org/pdf/2407.18078v1,2024-07-25,2407.18078v1,PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization,gpt-4,highly irrelevant,"While the paper discusses fine-tuning of language models for user personalization, there are no mentions of prompting or prompt engineering practices."
Difficulty Estimation and Simplification of French Text Using LLMs,"['Henri Jamet', 'Yash Raj Shrestha', 'Michalis Vlachos']","We leverage generative large language models for language learning
applications, focusing on estimating the difficulty of foreign language texts
and simplifying them to lower difficulty levels. We frame both tasks as
prediction problems and develop a difficulty classification model using labeled
examples, transfer learning, and large language models, demonstrating superior
accuracy compared to previous approaches. For simplification, we evaluate the
trade-off between simplification quality and meaning preservation, comparing
zero-shot and fine-tuned performances of large language models. We show that
meaningful text simplifications can be obtained with limited fine-tuning. Our
experiments are conducted on French texts, but our methods are
language-agnostic and directly applicable to other foreign languages.",http://arxiv.org/pdf/2407.18061v1,2024-07-25,2407.18061v1,Difficulty Estimation and Simplification of French Text Using LLMs,gpt-4,highly irrelevant,"The study focuses on language learning applications, estimation of difficulty levels, and simplification of texts using large language models. It doesn't mention hard prefix prompting or prompt engineering."
I can listen but cannot read: An evaluation of two-tower multimodal systems for instrument recognition,"['Yannis Vasilakis', 'Rachel Bittner', 'Johan Pauwels']","Music two-tower multimodal systems integrate audio and text modalities into a
joint audio-text space, enabling direct comparison between songs and their
corresponding labels. These systems enable new approaches for classification
and retrieval, leveraging both modalities. Despite the promising results they
have shown for zero-shot classification and retrieval tasks, closer inspection
of the embeddings is needed. This paper evaluates the inherent zero-shot
properties of joint audio-text spaces for the case-study of instrument
recognition. We present an evaluation and analysis of two-tower systems for
zero-shot instrument recognition and a detailed analysis of the properties of
the pre-joint and joint embeddings spaces. Our findings suggest that audio
encoders alone demonstrate good quality, while challenges remain within the
text encoder or joint space projection. Specifically, two-tower systems exhibit
sensitivity towards specific words, favoring generic prompts over musically
informed ones. Despite the large size of textual encoders, they do not yet
leverage additional textual context or infer instruments accurately from their
descriptions. Lastly, a novel approach for quantifying the semantic
meaningfulness of the textual space leveraging an instrument ontology is
proposed. This method reveals deficiencies in the systems' understanding of
instruments and provides evidence of the need for fine-tuning text encoders on
musical data.",http://arxiv.org/pdf/2407.18058v1,2024-07-25,2407.18058v1,I can listen but cannot read: An evaluation of two-tower multimodal systems for instrument recognition,gpt-4,highly irrelevant,"This paper focuses on two-tower multimodal systems for instrument recognition, primarily dealing with audio and text encoders but does not discuss hard prefix prompting or prompt engineering."
GaussianSR: High Fidelity 2D Gaussian Splatting for Arbitrary-Scale Image Super-Resolution,"['Jintong Hu', 'Bin Xia', 'Bin Chen', 'Wenming Yang', 'Lei Zhang']","Implicit neural representations (INRs) have significantly advanced the field
of arbitrary-scale super-resolution (ASSR) of images. Most existing INR-based
ASSR networks first extract features from the given low-resolution image using
an encoder, and then render the super-resolved result via a multi-layer
perceptron decoder. Although these approaches have shown promising results,
their performance is constrained by the limited representation ability of
discrete latent codes in the encoded features. In this paper, we propose a
novel ASSR method named GaussianSR that overcomes this limitation through 2D
Gaussian Splatting (2DGS). Unlike traditional methods that treat pixels as
discrete points, GaussianSR represents each pixel as a continuous Gaussian
field. The encoded features are simultaneously refined and upsampled by
rendering the mutually stacked Gaussian fields. As a result, long-range
dependencies are established to enhance representation ability. In addition, a
classifier is developed to dynamically assign Gaussian kernels to all pixels to
further improve flexibility. All components of GaussianSR (i.e., encoder,
classifier, Gaussian kernels, and decoder) are jointly learned end-to-end.
Experiments demonstrate that GaussianSR achieves superior ASSR performance with
fewer parameters than existing methods while enjoying interpretable and
content-aware feature aggregations.",http://arxiv.org/pdf/2407.18046v1,2024-07-25,2407.18046v1,GaussianSR: High Fidelity 2D Gaussian Splatting for Arbitrary-Scale Image Super-Resolution,gpt-4,highly irrelevant,"The paper discusses image super-resolution using Gaussian Splatting and doesn't mention anything about prompting, prompt engineering, or transformers."
Peak-Controlled Logits Poisoning Attack in Federated Distillation,"['Yuhan Tang', 'Aoxu Zhang', 'Zhiyuan Wu', 'Bo Gao', 'Tian Wen', 'Yuwei Wang', 'Sheng Sun']","Federated Distillation (FD) offers an innovative approach to distributed
machine learning, leveraging knowledge distillation for efficient and flexible
cross-device knowledge transfer without necessitating the upload of extensive
model parameters to a central server. While FD has gained popularity, its
vulnerability to poisoning attacks remains underexplored. To address this gap,
we previously introduced FDLA (Federated Distillation Logits Attack), a method
that manipulates logits communication to mislead and degrade the performance of
client models. However, the impact of FDLA on participants with different
identities and the effects of malicious modifications at various stages of
knowledge transfer remain unexplored. To this end, we present PCFDLA
(Peak-Controlled Federated Distillation Logits Attack), an advanced and more
stealthy logits poisoning attack method for FD. PCFDLA enhances the
effectiveness of FDLA by carefully controlling the peak values of logits to
create highly misleading yet inconspicuous modifications. Furthermore, we
introduce a novel metric for better evaluating attack efficacy, demonstrating
that PCFDLA maintains stealth while being significantly more disruptive to
victim models compared to its predecessors. Experimental results across various
datasets confirm the superior impact of PCFDLA on model accuracy, solidifying
its potential threat in federated distillation systems.",http://arxiv.org/pdf/2407.18039v1,2024-07-25,2407.18039v1,Peak-Controlled Logits Poisoning Attack in Federated Distillation,gpt-4,highly irrelevant,"The paper primarily focuses on Federated Distillation and poison attacks in this context, without any mention or implication of hard prefix prompts or prompt engineering techniques."
RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models,"['Haoyu Chen', 'Wenbo Li', 'Jinjin Gu', 'Jingjing Ren', 'Sixiang Chen', 'Tian Ye', 'Renjing Pei', 'Kaiwen Zhou', 'Fenglong Song', 'Lei Zhu']","Natural images captured by mobile devices often suffer from multiple types of
degradation, such as noise, blur, and low light. Traditional image restoration
methods require manual selection of specific tasks, algorithms, and execution
sequences, which is time-consuming and may yield suboptimal results. All-in-one
models, though capable of handling multiple tasks, typically support only a
limited range and often produce overly smooth, low-fidelity outcomes due to
their broad data distribution fitting. To address these challenges, we first
define a new pipeline for restoring images with multiple degradations, and then
introduce RestoreAgent, an intelligent image restoration system leveraging
multimodal large language models. RestoreAgent autonomously assesses the type
and extent of degradation in input images and performs restoration through (1)
determining the appropriate restoration tasks, (2) optimizing the task
sequence, (3) selecting the most suitable models, and (4) executing the
restoration. Experimental results demonstrate the superior performance of
RestoreAgent in handling complex degradation, surpassing human experts.
Furthermore, the system modular design facilitates the fast integration of new
tasks and models, enhancing its flexibility and scalability for various
applications.",http://arxiv.org/pdf/2407.18035v1,2024-07-25,2407.18035v1,RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models,gpt-4,highly irrelevant,"The paper is about image restoration using multimodal large language models, with no mention of hard prefix prompting or prompt engineering."
Learning mental states estimation through self-observation: a developmental synergy between intentions and beliefs representations in a deep-learning model of Theory of Mind,"['Francesca Bianco', 'Silvia Rigato', 'Maria Laura Filippetti', 'Dimitri Ognibene']","Theory of Mind (ToM), the ability to attribute beliefs, intentions, or mental
states to others, is a crucial feature of human social interaction. In complex
environments, where the human sensory system reaches its limits, behaviour is
strongly driven by our beliefs about the state of the world around us.
Accessing others' mental states, e.g., beliefs and intentions, allows for more
effective social interactions in natural contexts. Yet, these variables are not
directly observable, making understanding ToM a challenging quest of interest
for different fields, including psychology, machine learning and robotics. In
this paper, we contribute to this topic by showing a developmental synergy
between learning to predict low-level mental states (e.g., intentions, goals)
and attributing high-level ones (i.e., beliefs). Specifically, we assume that
learning beliefs attribution can occur by observing one's own decision
processes involving beliefs, e.g., in a partially observable environment. Using
a simple feed-forward deep learning model, we show that, when learning to
predict others' intentions and actions, more accurate predictions can be
acquired earlier if beliefs attribution is learnt simultaneously. Furthermore,
we show that the learning performance improves even when observed actors have a
different embodiment than the observer and the gain is higher when observing
beliefs-driven chunks of behaviour. We propose that our computational approach
can inform the understanding of human social cognitive development and be
relevant for the design of future adaptive social robots able to autonomously
understand, assist, and learn from human interaction partners in novel natural
environments and tasks.",http://arxiv.org/pdf/2407.18022v1,2024-07-25,2407.18022v1,Learning mental states estimation through self-observation: a developmental synergy between intentions and beliefs representations in a deep-learning model of Theory of Mind,gpt-4,highly irrelevant,"The paper focuses on mental state estimation in AI and social cognitive development, and does not discuss hard prefix prompting or any sort of prompt engineering."
Quadratic Advantage with Quantum Randomized Smoothing Applied to Time-Series Analysis,"['Nicola Franco', 'Marie Kempkes', 'Jakob Spiegelberg', 'Jeanette Miriam Lorenz']","As quantum machine learning continues to develop at a rapid pace, the
importance of ensuring the robustness and efficiency of quantum algorithms
cannot be overstated. Our research presents an analysis of quantum randomized
smoothing, how data encoding and perturbation modeling approaches can be
matched to achieve meaningful robustness certificates. By utilizing an
innovative approach integrating Grover's algorithm, a quadratic sampling
advantage over classical randomized smoothing is achieved. This strategy
necessitates a basis state encoding, thus restricting the space of meaningful
perturbations. We show how constrained $k$-distant Hamming weight perturbations
are a suitable noise distribution here, and elucidate how they can be
constructed on a quantum computer. The efficacy of the proposed framework is
demonstrated on a time series classification task employing a Bag-of-Words
pre-processing solution. The advantage of quadratic sample reduction is
recovered especially in the regime with large number of samples. This may allow
quantum computers to efficiently scale randomized smoothing to more complex
tasks beyond the reach of classical methods.",http://arxiv.org/pdf/2407.18021v1,2024-07-25,2407.18021v1,Quadratic Advantage with Quantum Randomized Smoothing Applied to Time-Series Analysis,gpt-4,highly irrelevant,The paper focuses on quantum machine learning and doesn't mention prompt engineering or hard prefix prompts.
A Sensitivity Analysis of Cellular Automata and Heterogeneous Topology Networks: Partially-Local Cellular Automata and Homogeneous Homogeneous Random Boolean Networks,"['Tom Eivind Glover', 'Ruben Jahren', 'Francesco Martinuzzi', 'Pedro Gon√ßalves Lind', 'Stefano Nichele']","Elementary Cellular Automata (ECA) are a well-studied computational universe
that is, despite its simple configurations, capable of impressive computational
variety. Harvesting this computation in a useful way has historically shown
itself to be difficult, but if combined with reservoir computing (RC), this
becomes much more feasible. Furthermore, RC and ECA enable energy-efficient AI,
making the combination a promising concept for Edge AI. In this work, we
contrast ECA to substrates of Partially-Local CA (PLCA) and Homogeneous
Homogeneous Random Boolean Networks (HHRBN). They are, in comparison, the
topological heterogeneous counterparts of ECA. This represents a step from ECA
towards more biological-plausible substrates. We analyse these substrates by
testing on an RC benchmark (5-bit memory), using Temporal Derrida plots to
estimate the sensitivity and assess the defect collapse rate. We find that,
counterintuitively, disordered topology does not necessarily mean disordered
computation. There are countering computational ""forces"" of topology
imperfections leading to a higher collapse rate (order) and yet, if accounted
for, an increased sensitivity to the initial condition. These observations
together suggest a shrinking critical range.",http://arxiv.org/pdf/2407.18017v1,2024-07-25,2407.18017v1,A Sensitivity Analysis of Cellular Automata and Heterogeneous Topology Networks: Partially-Local Cellular Automata and Homogeneous Homogeneous Random Boolean Networks,gpt-4,highly irrelevant,"The paper focuses on Cellular Automata and Heterogeneous Topology Networks, and does not discuss prompt engineering or use of hard prefix prompts."
Keep the Cost Down: A Review on Methods to Optimize LLM' s KV-Cache Consumption,"['Shi Luohe', 'Zhang Hongyi', 'Yao Yao', 'Li Zuchao', 'Zhao Hai']","Large Language Models (LLMs), epitomized by ChatGPT' s release in late 2022,
have revolutionized various industries with their advanced language
comprehension. However, their efficiency is challenged by the Transformer
architecture' s struggle with handling long texts. KV-Cache has emerged as a
pivotal solution to this issue, converting the time complexity of token
generation from quadratic to linear, albeit with increased GPU memory overhead
proportional to conversation length. With the development of the LLM community
and academia, various KV-Cache compression methods have been proposed. In this
review, we dissect the various properties of KV-Cache and elaborate on various
methods currently used to optimize the KV-Cache space usage of LLMs. These
methods span the pre-training phase, deployment phase, and inference phase, and
we summarize the commonalities and differences among these methods.
Additionally, we list some metrics for evaluating the long-text capabilities of
large language models, from both efficiency and capability perspectives. Our
review thus sheds light on the evolving landscape of LLM optimization, offering
insights into future advancements in this dynamic field.",http://arxiv.org/pdf/2407.18003v1,2024-07-25,2407.18003v1,Keep the Cost Down: A Review on Methods to Optimize LLM' s KV-Cache Consumption,gpt-4,highly irrelevant,"The paper is focused on KV-Cache and optimizing the memory usage of Large Language Models, with no mention or implication of hard prefix prompts or any form of prompt engineering."
On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures,"['Nick Rossenbach', 'Benedikt Hilmes', 'Ralf Schl√ºter']","In this work we evaluate the utility of synthetic data for training automatic
speech recognition (ASR). We use the ASR training data to train a
text-to-speech (TTS) system similar to FastSpeech-2. With this TTS we reproduce
the original training data, training ASR systems solely on synthetic data. For
ASR, we use three different architectures, attention-based encoder-decoder,
hybrid deep neural network hidden Markov model and a Gaussian mixture hidden
Markov model, showing the different sensitivity of the models to synthetic data
generation. In order to extend previous work, we present a number of ablation
studies on the effectiveness of synthetic vs. real training data for ASR. In
particular we focus on how the gap between training on synthetic and real data
changes by varying the speaker embedding or by scaling the model size. For the
latter we show that the TTS models generalize well, even when training scores
indicate overfitting.",http://arxiv.org/pdf/2407.17997v1,2024-07-25,2407.17997v1,On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures,gpt-4,highly irrelevant,The paper focuses on automatic speech recognition and does not mention or imply the use of hard prefix prompting or prompt engineering techniques.
Personalized and Context-aware Route Planning for Edge-assisted Vehicles,"['Dinesh Cyril Selvaraj', 'Falko Dressler', 'Carla Fabiana Chiasserini']","Conventional route planning services typically offer the same routes to all
drivers, focusing primarily on a few standardized factors such as travel
distance or time, overlooking individual driver preferences. With the inception
of autonomous vehicles expected in the coming years, where vehicles will rely
on routes decided by such planners, there arises a need to incorporate the
specific preferences of each driver, ensuring personalized navigation
experiences. In this work, we propose a novel approach based on graph neural
networks (GNNs) and deep reinforcement learning (DRL), aimed at customizing
routes to suit individual preferences. By analyzing the historical trajectories
of individual drivers, we classify their driving behavior and associate it with
relevant road attributes as indicators of driver preferences. The GNN is
capable of representing the road network as graph-structured data effectively,
while DRL is capable of making decisions utilizing reward mechanisms to
optimize route selection with factors such as travel costs, congestion level,
and driver satisfaction. We evaluate our proposed GNN-based DRL framework using
a real-world road network and demonstrate its ability to accommodate driver
preferences, offering a range of route options tailored to individual drivers.
The results indicate that our framework can select routes that accommodate
driver's preferences with up to a 17% improvement compared to a generic route
planner, and reduce the travel time by 33% (afternoon) and 46% (evening)
relatively to the shortest distance-based approach.",http://arxiv.org/pdf/2407.17980v1,2024-07-25,2407.17980v1,Personalized and Context-aware Route Planning for Edge-assisted Vehicles,gpt-4,highly irrelevant,This paper revolves around route planning services for autonomous vehicles using GNNs and DRL. There is no indication of relevance to the topics of hard prefix prompting or prompt engineering.
What does Kiki look like? Cross-modal associations between speech sounds and visual shapes in vision-and-language models,"['Tessa Verhoef', 'Kiana Shahrasbi', 'Tom Kouwenhoven']","Humans have clear cross-modal preferences when matching certain novel words
to visual shapes. Evidence suggests that these preferences play a prominent
role in our linguistic processing, language learning, and the origins of
signal-meaning mappings. With the rise of multimodal models in AI, such as
vision- and-language (VLM) models, it becomes increasingly important to uncover
the kinds of visio-linguistic associations these models encode and whether they
align with human representations. Informed by experiments with humans, we probe
and compare four VLMs for a well-known human cross-modal preference, the
bouba-kiki effect. We do not find conclusive evidence for this effect but
suggest that results may depend on features of the models, such as architecture
design, model size, and training details. Our findings inform discussions on
the origins of the bouba-kiki effect in human cognition and future developments
of VLMs that align well with human cross-modal associations.",http://arxiv.org/pdf/2407.17974v1,2024-07-25,2407.17974v1,What does Kiki look like? Cross-modal associations between speech sounds and visual shapes in vision-and-language models,gpt-4,highly irrelevant,"The paper is focused on studying the cross-modal associations in multimodal models and their alignment with human cognition, and it's not directly related to any discussion on hard prefix prompting or prompt engineering in AI models."
Relating the Seemingly Unrelated: Principled Understanding of Generalization for Generative Models in Arithmetic Reasoning Tasks,"['Xingcheng Xu', 'Zibo Zhao', 'Haipeng Zhang', 'Yanqing Yang']","Large language models (LLMs) have demonstrated impressive versatility across
numerous tasks, yet their generalization capabilities remain poorly understood.
To investigate these behaviors, arithmetic tasks serve as important venues. In
previous studies, seemingly unrelated mysteries still exist -- (1) models with
appropriate positional embeddings can correctly perform longer unseen
arithmetic operations such as addition, but their effectiveness varies in more
complex tasks like multiplication; (2) models perform well for longer unseen
cases in modular addition under specific moduli (e.g., modulo 100) but struggle
under very close moduli (e.g., modulo 101), regardless of the positional
encoding used. We believe previous studies have been treating the symptoms
rather than addressing the root cause -- they have paid excessive attention to
improving model components, while overlooking the differences in task
properties that may be the real drivers. This is confirmed by our unified
theoretical framework for different arithmetic scenarios. For example, unlike
multiplication, the digital addition task has the property of translation
invariance which naturally aligns with the relative positional encoding, and
this combination leads to successful generalization of addition to unseen
longer domains. The discrepancy in operations modulo 100 and 101 arises from
the base. Modulo 100, unlike 101, is compatible with the decimal system (base
10), such that unseen information in digits beyond the units digit and the tens
digit is actually not needed for the task. Extensive experiments with GPT-like
models validate our theoretical predictions. These findings deepen our
understanding of the generalization mechanisms, and facilitate more
data-efficient model training and objective-oriented AI alignment.",http://arxiv.org/pdf/2407.17963v1,2024-07-25,2407.17963v1,Relating the Seemingly Unrelated: Principled Understanding of Generalization for Generative Models in Arithmetic Reasoning Tasks,gpt-4,highly irrelevant,"The paper focuses on understanding generalization capabilities of large language models in arithmetic tasks and data-efficient model training, not hard prefix prompting or prompt engineering."
The Curious Case of Representational Alignment: Unravelling Visio-Linguistic Tasks in Emergent Communication,"['Tom Kouwenhoven', 'Max Peeperkorn', 'Bram van Dijk', 'Tessa Verhoef']","Natural language has the universal properties of being compositional and
grounded in reality. The emergence of linguistic properties is often
investigated through simulations of emergent communication in referential
games. However, these experiments have yielded mixed results compared to
similar experiments addressing linguistic properties of human language. Here we
address representational alignment as a potential contributing factor to these
results. Specifically, we assess the representational alignment between agent
image representations and between agent representations and input images. Doing
so, we confirm that the emergent language does not appear to encode human-like
conceptual visual features, since agent image representations drift away from
inputs whilst inter-agent alignment increases. We moreover identify a strong
relationship between inter-agent alignment and topographic similarity, a common
metric for compositionality, and address its consequences. To address these
issues, we introduce an alignment penalty that prevents representational drift
but interestingly does not improve performance on a compositional
discrimination task. Together, our findings emphasise the key role
representational alignment plays in simulations of language emergence.",http://arxiv.org/pdf/2407.17960v1,2024-07-25,2407.17960v1,The Curious Case of Representational Alignment: Unravelling Visio-Linguistic Tasks in Emergent Communication,gpt-4,highly irrelevant,The paper focuses on understanding emergent communication in referential games without any references to prompt engineering or hard prefix prompting.
Pruning Boolean d-DNNF Circuits Through Tseitin-Awareness,['Vincent Derkinderen'],"Boolean circuits in d-DNNF form enable tractable probabilistic inference.
However, as a key insight of this work, we show that commonly used d-DNNF
compilation approaches introduce irrelevant subcircuits. We call these
subcircuits Tseitin artifacts, as they are introduced due to the Tseitin
transformation step -- a well-established procedure to transform any circuit
into the CNF format required by several d-DNNF knowledge compilers. We discuss
how to detect and remove both Tseitin variables and Tseitin artifacts, leading
to more succinct circuits. We empirically observe an average size reduction of
77.5% when removing both Tseitin variables and artifacts. The additional
pruning of Tseitin artifacts reduces the size by 22.2% on average. This
significantly improves downstream tasks that benefit from a more succinct
circuit, e.g., probabilistic inference tasks.",http://arxiv.org/pdf/2407.17951v1,2024-07-25,2407.17951v1,Pruning Boolean d-DNNF Circuits Through Tseitin-Awareness,gpt-4,highly irrelevant,This paper focuses on the pruning of Boolean d-DNNF Circuits and does not mention any prompting techniques or prompt engineering in its abstract.
Real Time American Sign Language Detection Using Yolo-v9,"['Amna Imran', 'Meghana Shashishekhara Hulikal', 'Hamza A. A. Gardi']","This paper focuses on real-time American Sign Language Detection. YOLO is a
convolutional neural network (CNN) based model, which was first released in
2015. In recent years, it gained popularity for its real-time detection
capabilities. Our study specifically targets YOLO-v9 model, released in 2024.
As the model is newly introduced, not much work has been done on it, especially
not in Sign Language Detection. Our paper provides deep insight on how YOLO- v9
works and better than previous model.",http://arxiv.org/pdf/2407.17950v1,2024-07-25,2407.17950v1,Real Time American Sign Language Detection Using Yolo-v9,gpt-4,highly irrelevant,"The paper discusses American Sign Language detection using a CNN-based model YOLO-v9, but does not mention or seem to apply concepts of prompt engineering or hard prefix prompting."
Positive Text Reframing under Multi-strategy Optimization,"['Shutong Jia', 'Biwei Cao', 'Qingqing Gao', 'Jiuxin Cao', 'Bo Liu']","Differing from sentiment transfer, positive reframing seeks to substitute
negative perspectives with positive expressions while preserving the original
meaning. With the emergence of pre-trained language models (PLMs), it is
possible to achieve acceptable results by fine-tuning PLMs. Nevertheless,
generating fluent, diverse and task-constrained reframing text remains a
significant challenge. To tackle this issue, a \textbf{m}ulti-\textbf{s}trategy
\textbf{o}ptimization \textbf{f}ramework (MSOF) is proposed in this paper.
Starting from the objective of positive reframing, we first design positive
sentiment reward and content preservation reward to encourage the model to
transform the negative expressions of the original text while ensuring the
integrity and consistency of the semantics. Then, different decoding
optimization approaches are introduced to improve the quality of text
generation. Finally, based on the modeling formula of positive reframing, we
propose a multi-dimensional re-ranking method that further selects candidate
sentences from three dimensions: strategy consistency, text similarity and
fluency. Extensive experiments on two Seq2Seq PLMs, BART and T5, demonstrate
our framework achieves significant improvements on unconstrained and controlled
positive reframing tasks.",http://arxiv.org/pdf/2407.17940v1,2024-07-25,2407.17940v1,Positive Text Reframing under Multi-strategy Optimization,gpt-4,highly irrelevant,"The paper makes no mention of prompt engineering or the use of hard prefix prompts in its abstract, rather it is focused on fine-tuning pre-trained models for the task of positive text reframing."
Comparison of different Artificial Neural Networks for Bitcoin price forecasting,"['Silas Baumann', 'Karl A. Busch', 'Hamza A. A. Gardi']","This study investigates the impact of varying sequence lengths on the
accuracy of predicting cryptocurrency returns using Artificial Neural Networks
(ANNs). Utilizing the Mean Absolute Error (MAE) as a threshold criterion, we
aim to enhance prediction accuracy by excluding returns that are smaller than
this threshold, thus mitigating errors associated with minor returns. The
subsequent evaluation focuses on the accuracy of predicted returns that exceed
this threshold. We compare four sequence lengths 168 hours (7 days), 72 hours
(3 days), 24 hours, and 12 hours each with a return prediction interval of 2
hours. Our findings reveal the influence of sequence length on prediction
accuracy and underscore the potential for optimized sequence configurations in
financial forecasting models.",http://arxiv.org/pdf/2407.17930v1,2024-07-25,2407.17930v1,Comparison of different Artificial Neural Networks for Bitcoin price forecasting,gpt-4,highly irrelevant,The paper does not discuss anything about prompt engineering or hard prefix prompting but rather focuses on prediction accuracy in financial forecasting models using artificial neural networks.
Invariance of deep image quality metrics to affine transformations,"['Nuria Alabau-Bosque', 'Paula Daud√©n-Oliver', 'Jorge Vila-Tom√°s', 'Valero Laparra', 'Jes√∫s Malo']","Deep architectures are the current state-of-the-art in predicting subjective
image quality. Usually, these models are evaluated according to their ability
to correlate with human opinion in databases with a range of distortions that
may appear in digital media. However, these oversee affine transformations
which may represent better the changes in the images actually happening in
natural conditions. Humans can be particularly invariant to these natural
transformations, as opposed to the digital ones. In this work, we evaluate
state-of-the-art deep image quality metrics by assessing their invariance to
affine transformations, specifically: rotation, translation, scaling, and
changes in spectral illumination. We propose a methodology to assign
invisibility thresholds for any perceptual metric. This methodology involves
transforming the distance measured by an arbitrary metric to a common distance
representation based on available subjectively rated databases. We
psychophysically measure an absolute detection threshold in that common
representation and express it in the physical units of each affine transform
for each metric. By doing so, we allow the analyzed metrics to be directly
comparable with actual human thresholds. We find that none of the
state-of-the-art metrics shows human-like results under this strong test based
on invisibility thresholds. This means that tuning the models exclusively to
predict the visibility of generic distortions may disregard other properties of
human vision as for instance invariances or invisibility thresholds.",http://arxiv.org/pdf/2407.17927v1,2024-07-25,2407.17927v1,Invariance of deep image quality metrics to affine transformations,gpt-4,highly irrelevant,The paper focuses on the invariance of deep image quality metrics to affine transformations and does not mention or allude to hard prefix prompting or prompt engineering.
Modelling Multimodal Integration in Human Concept Processing with Vision-and-Language Models,"['Anna Bavaresco', 'Marianne de Heer Kloots', 'Sandro Pezzelle', 'Raquel Fern√°ndez']","Representations from deep neural networks (DNNs) have proven remarkably
predictive of neural activity involved in both visual and linguistic
processing. Despite these successes, most studies to date concern unimodal
DNNs, encoding either visual or textual input but not both. Yet, there is
growing evidence that human meaning representations integrate linguistic and
sensory-motor information. Here we investigate whether the integration of
multimodal information operated by current vision-and-language DNN models
(VLMs) leads to representations that are more aligned with human brain activity
than those obtained by language-only and vision-only DNNs. We focus on fMRI
responses recorded while participants read concept words in the context of
either a full sentence or an accompanying picture. Our results reveal that VLM
representations correlate more strongly than language- and vision-only DNNs
with activations in brain areas functionally related to language processing. A
comparison between different types of visuo-linguistic architectures shows that
recent generative VLMs tend to be less brain-aligned than previous
architectures with lower performance on downstream applications. Moreover,
through an additional analysis comparing brain vs. behavioural alignment across
multiple VLMs, we show that -- with one remarkable exception -- representations
that strongly align with behavioural judgments do not correlate highly with
brain responses. This indicates that brain similarity does not go hand in hand
with behavioural similarity, and vice versa.",http://arxiv.org/pdf/2407.17914v1,2024-07-25,2407.17914v1,Modelling Multimodal Integration in Human Concept Processing with Vision-and-Language Models,gpt-4,highly irrelevant,The paper focuses on the multimodal integration in human concept processing with vision-and-language models but doesn't mention anything about hard prompt engineering or prompting techniques.
ReCorD: Reasoning and Correcting Diffusion for HOI Generation,"['Jian-Yu Jiang-Lin', 'Kang-Yang Huang', 'Ling Lo', 'Yi-Ning Huang', 'Terence Lin', 'Jhih-Ciang Wu', 'Hong-Han Shuai', 'Wen-Huang Cheng']","Diffusion models revolutionize image generation by leveraging natural
language to guide the creation of multimedia content. Despite significant
advancements in such generative models, challenges persist in depicting
detailed human-object interactions, especially regarding pose and object
placement accuracy. We introduce a training-free method named Reasoning and
Correcting Diffusion (ReCorD) to address these challenges. Our model couples
Latent Diffusion Models with Visual Language Models to refine the generation
process, ensuring precise depictions of HOIs. We propose an interaction-aware
reasoning module to improve the interpretation of the interaction, along with
an interaction correcting module to refine the output image for more precise
HOI generation delicately. Through a meticulous process of pose selection and
object positioning, ReCorD achieves superior fidelity in generated images while
efficiently reducing computational requirements. We conduct comprehensive
experiments on three benchmarks to demonstrate the significant progress in
solving text-to-image generation tasks, showcasing ReCorD's ability to render
complex interactions accurately by outperforming existing methods in HOI
classification score, as well as FID and Verb CLIP-Score. Project website is
available at https://alberthkyhky.github.io/ReCorD/ .",http://arxiv.org/pdf/2407.17911v1,2024-07-25,2407.17911v1,ReCorD: Reasoning and Correcting Diffusion for HOI Generation,gpt-4,highly irrelevant,"The paper focuses on a training-free diffusion model for image generation using natural language, but does not mention prompting or prompt engineering at all."
Causal Deepsets for Off-policy Evaluation under Spatial or Spatio-temporal Interferences,"['Runpeng Dai', 'Jianing Wang', 'Fan Zhou', 'Shikai Luo', 'Zhiwei Qin', 'Chengchun Shi', 'Hongtu Zhu']","Off-policy evaluation (OPE) is widely applied in sectors such as
pharmaceuticals and e-commerce to evaluate the efficacy of novel products or
policies from offline datasets. This paper introduces a causal deepset
framework that relaxes several key structural assumptions, primarily the
mean-field assumption, prevalent in existing OPE methodologies that handle
spatio-temporal interference. These traditional assumptions frequently prove
inadequate in real-world settings, thereby restricting the capability of
current OPE methods to effectively address complex interference effects. In
response, we advocate for the implementation of the permutation invariance (PI)
assumption. This innovative approach enables the data-driven, adaptive learning
of the mean-field function, offering a more flexible estimation method beyond
conventional averaging. Furthermore, we present novel algorithms that
incorporate the PI assumption into OPE and thoroughly examine their theoretical
foundations. Our numerical analyses demonstrate that this novel approach yields
significantly more precise estimations than existing baseline algorithms,
thereby substantially improving the practical applicability and effectiveness
of OPE methodologies. A Python implementation of our proposed method is
available at https://github.com/BIG-S2/Causal-Deepsets.",http://arxiv.org/pdf/2407.17910v1,2024-07-25,2407.17910v1,Causal Deepsets for Off-policy Evaluation under Spatial or Spatio-temporal Interferences,gpt-4,highly irrelevant,"The paper is about off-policy evaluation methodologies with a focus on the implementation of the permutation invariance assumption, and does not discuss anything about prompt engineering or hard prefix prompts."
3D Hole Filling using Deep Learning Inpainting,"['Marina Hern√°ndez-Bautista', 'F. J. Melero']","The current work presents a novel methodology for completing 3D surfaces
produced from 3D digitization technologies in places where there is a scarcity
of meaningful geometric data. Incomplete or missing data in these
three-dimensional (3D) models can lead to erroneous or flawed renderings,
limiting their usefulness in a variety of applications such as visualization,
geometric computation, and 3D printing. Conventional surface estimation
approaches often produce implausible results, especially when dealing with
complex surfaces. To address this issue, we propose a technique that
incorporates neural network-based 2D inpainting to effectively reconstruct 3D
surfaces. Our customized neural networks were trained on a dataset containing
over 1 million curvature images. These images show the curvature of vertices as
planar representations in 2D. Furthermore, we used a coarse-to-fine surface
deformation technique to improve the accuracy of the reconstructed pictures and
assure surface adaptability. This strategy enables the system to learn and
generalize patterns from input data, resulting in the development of precise
and comprehensive three-dimensional surfaces. Our methodology excels in the
shape completion process, effectively filling complex holes in
three-dimensional surfaces with a remarkable level of realism and precision.",http://arxiv.org/pdf/2407.17896v1,2024-07-25,2407.17896v1,3D Hole Filling using Deep Learning Inpainting,gpt-4,highly irrelevant,This paper focuses on 3D surfaces reconstruction using neural networks and does not discuss prompt engineering or hard prefix prompting techniques.
An Iterative Approach to Topic Modelling,"['Albert Wong', 'Florence Wing Yau Cheng', 'Ashley Keung', 'Yamileth Hercules', 'Mary Alexandra Garcia', 'Yew-Wei Lim', 'Lien Pham']","Topic modelling has become increasingly popular for summarizing text data,
such as social media posts and articles. However, topic modelling is usually
completed in one shot. Assessing the quality of resulting topics is
challenging. No effective methods or measures have been developed for assessing
the results or for making further enhancements to the topics. In this research,
we propose we propose to use an iterative process to perform topic modelling
that gives rise to a sense of completeness of the resulting topics when the
process is complete. Using the BERTopic package, a popular method in topic
modelling, we demonstrate how the modelling process can be applied iteratively
to arrive at a set of topics that could not be further improved upon using one
of the three selected measures for clustering comparison as the decision
criteria. This demonstration is conducted using a subset of the COVIDSenti-A
dataset. The early success leads us to believe that further research using in
using this approach in conjunction with other topic modelling algorithms could
be viable.",http://arxiv.org/pdf/2407.17892v1,2024-07-25,2407.17892v1,An Iterative Approach to Topic Modelling,gpt-4,highly irrelevant,The paper focuses on topic modelling and does not discuss hard-prefix prompting or prompt engineering.
Unraveling the Never-Ending Story of Lifecycles and Vitalizing Processes,"['Stephan A. Fahrenkrog-Petersen', 'Saimir Bala', 'Luise Pufahl', 'Jan Mendling']","Business process management (BPM) has been widely used to discover, model,
analyze, and optimize organizational processes. BPM looks at these processes
with analysis techniques that assume a clearly defined start and end. However,
not all processes adhere to this logic, with the consequence that their
behavior cannot be appropriately captured by BPM analysis techniques. This
paper addresses this research problem at a conceptual level. More specifically,
we introduce the notion of vitalizing business processes that target the
lifecycle process of one or more entities. We show the existence of lifecycle
processes in many industries and that their appropriate conceptualizations pave
the way for the definition of suitable modeling and analysis techniques. This
paper provides a set of requirements for their analysis, and a
conceptualization of lifecycle and vitalizing processes.",http://arxiv.org/pdf/2407.17881v1,2024-07-25,2407.17881v1,Unraveling the Never-Ending Story of Lifecycles and Vitalizing Processes,gpt-4,highly irrelevant,This paper is about business process management and does not mention prompt engineering or any related concepts.
HG-PIPE: Vision Transformer Acceleration with Hybrid-Grained Pipeline,"['Qingyu Guo', 'Jiayong Wan', 'Songqiang Xu', 'Meng Li', 'Yuan Wang']","Vision Transformer (ViT) acceleration with field programmable gate array
(FPGA) is promising but challenging. Existing FPGA-based ViT accelerators
mainly rely on temporal architectures, which process different operators by
reusing the same hardware blocks and suffer from extensive memory access
overhead. Pipelined architectures, either coarse-grained or fine-grained,
unroll the ViT computation spatially for memory access efficiency. However,
they usually suffer from significant hardware resource constraints and pipeline
bubbles induced by the global computation dependency of ViT. In this paper, we
introduce HG-PIPE, a pipelined FPGA accelerator for high-throughput and
low-latency ViT processing. HG-PIPE features a hybrid-grained pipeline
architecture to reduce on-chip buffer cost and couples the computation dataflow
and parallelism design to eliminate the pipeline bubbles. HG-PIPE further
introduces careful approximations to implement both linear and non-linear
operators with abundant Lookup Tables (LUTs), thus alleviating resource
constraints. On a ZCU102 FPGA, HG-PIPE achieves 2.78 times better throughput
and 2.52 times better resource efficiency than the prior-art accelerators,
e.g., AutoViTAcc. With a VCK190 FPGA, HG-PIPE realizes end-to-end ViT
acceleration on a single device and achieves 7118 images/s, which is 2.81 times
faster than a V100 GPU.",http://arxiv.org/pdf/2407.17879v1,2024-07-25,2407.17879v1,HG-PIPE: Vision Transformer Acceleration with Hybrid-Grained Pipeline,gpt-4,highly irrelevant,"The paper focuses on the acceleration of Vision Transformers (ViT) using a FPGA accelerator, not on hard prefix prompting or prompt engineering."
A Large-Scale Sensitivity Analysis on Latent Embeddings and Dimensionality Reductions for Text Spatializations,"['Daniel Atzberger', 'Tim Cech', 'Willy Scheibel', 'J√ºrgen D√∂llner', 'Michael Behrisch', 'Tobias Schreck']","The semantic similarity between documents of a text corpus can be visualized
using map-like metaphors based on two-dimensional scatterplot layouts. These
layouts result from a dimensionality reduction on the document-term matrix or a
representation within a latent embedding, including topic models. Thereby, the
resulting layout depends on the input data and hyperparameters of the
dimensionality reduction and is therefore affected by changes in them.
Furthermore, the resulting layout is affected by changes in the input data and
hyperparameters of the dimensionality reduction. However, such changes to the
layout require additional cognitive efforts from the user. In this work, we
present a sensitivity study that analyzes the stability of these layouts
concerning (1) changes in the text corpora, (2) changes in the hyperparameter,
and (3) randomness in the initialization. Our approach has two stages: data
measurement and data analysis. First, we derived layouts for the combination of
three text corpora and six text embeddings and a grid-search-inspired
hyperparameter selection of the dimensionality reductions. Afterward, we
quantified the similarity of the layouts through ten metrics, concerning local
and global structures and class separation. Second, we analyzed the resulting
42817 tabular data points in a descriptive statistical analysis. From this, we
derived guidelines for informed decisions on the layout algorithm and highlight
specific hyperparameter settings. We provide our implementation as a Git
repository at
https://github.com/hpicgs/Topic-Models-and-Dimensionality-Reduction-Sensitivity-Study
and results as Zenodo archive at https://doi.org/10.5281/zenodo.12772898.",http://arxiv.org/pdf/2407.17876v1,2024-07-25,2407.17876v1,A Large-Scale Sensitivity Analysis on Latent Embeddings and Dimensionality Reductions for Text Spatializations,gpt-4,highly irrelevant,"The paper primarily focuses on sensitivity analysis of latent embeddings and dimensionality for text spatializations, rather than prompt engineering or hard prefix prompting techniques."
Improving Domain-Specific ASR with LLM-Generated Contextual Descriptions,"['Jiwon Suh', 'Injae Na', 'Woohwan Jung']","End-to-end automatic speech recognition (E2E ASR) systems have significantly
improved speech recognition through training on extensive datasets. Despite
these advancements, they still struggle to accurately recognize domain specific
words, such as proper nouns and technical terminologies. To address this
problem, we propose a method to utilize the state-of-the-art Whisper without
modifying its architecture, preserving its generalization performance while
enabling it to leverage descriptions effectively. Moreover, we propose two
additional training techniques to improve the domain specific ASR: decoder
fine-tuning, and context perturbation. We also propose a method to use a Large
Language Model (LLM) to generate descriptions with simple metadata, when
descriptions are unavailable. Our experiments demonstrate that proposed methods
notably enhance domain-specific ASR accuracy on real-life datasets, with
LLM-generated descriptions outperforming human-crafted ones in effectiveness.",http://arxiv.org/pdf/2407.17874v1,2024-07-25,2407.17874v1,Improving Domain-Specific ASR with LLM-Generated Contextual Descriptions,gpt-4,highly irrelevant,The paper focuses on enhancing automatic speech recognition systems with additional training techniques and not on hard prefix prompting or prompt engineering.
