title,authors,abstract,pdf_url,published,arxiv_id,Title,Model,Rating,Reasoning,image,image_description
StyEmp: Stylizing Empathetic Response Generation via Multi-Grained Prefix Encoder and Personality Reinforcement,"['Yahui Fu', 'Chenhui Chu', 'Tatsuya Kawahara']","Recent approaches for empathetic response generation mainly focus on
emotional resonance and user understanding, without considering the system's
personality. Consistent personality is evident in real human expression and is
important for creating trustworthy systems. To address this problem, we propose
StyEmp, which aims to stylize the empathetic response generation with a
consistent personality. Specifically, it incorporates a multi-grained prefix
mechanism designed to capture the intricate relationship between a system's
personality and its empathetic expressions. Furthermore, we introduce a
personality reinforcement module that leverages contrastive learning to
calibrate the generation model, ensuring that responses are both empathetic and
reflective of a distinct personality. Automatic and human evaluations on the
EMPATHETICDIALOGUES benchmark show that StyEmp outperforms competitive
baselines in terms of both empathy and personality expressions.",http://arxiv.org/pdf/2408.02271v1,2024-08-05,2408.02271v1,StyEmp: Stylizing Empathetic Response Generation via Multi-Grained Prefix Encoder and Personality Reinforcement,gpt-4,highly relevant,"The paper introduces a novel method that utilises prefix prompting techniques to stylise responses with a system's consistent personality, and is therefore related to the topic of prompt engineering.",<PIL.PngImagePlugin.PngImageFile image mode=RGB size=2198x916 at 0x7DD724471420>,
Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large Language Models?,"['Mohammad Bahrami Karkevandi', 'Nishant Vishwamitra', 'Peyman Najafirad']","Large Language Models (LLMs) have demonstrated impressive capabilities in
natural language tasks, but their safety and morality remain contentious due to
their training on internet text corpora. To address these concerns, alignment
techniques have been developed to improve the public usability and safety of
LLMs. Yet, the potential for generating harmful content through these models
seems to persist. This paper explores the concept of jailbreaking
LLMs-reversing their alignment through adversarial triggers. Previous methods,
such as soft embedding prompts, manually crafted prompts, and gradient-based
automatic prompts, have had limited success on black-box models due to their
requirements for model access and for producing a low variety of manually
crafted prompts, making them susceptible to being blocked. This paper
introduces a novel approach using reinforcement learning to optimize
adversarial triggers, requiring only inference API access to the target model
and a small surrogate model. Our method, which leverages a BERTScore-based
reward function, enhances the transferability and effectiveness of adversarial
triggers on new black-box models. We demonstrate that this approach improves
the performance of adversarial triggers on a previously untested language
model.",http://arxiv.org/pdf/2408.02651v1,2024-08-05,2408.02651v1,Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large Language Models?,gpt-4,somewhat relevant,"The paper discusses methods of prompt generation such as soft embedding prompts, manually crafted prompts, and gradient-based automatic prompts for language models, making it relevant to the topic of prompt engineering.",,
SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models,"['Muxi Diao', 'Rumei Li', 'Shiyang Liu', 'Guogang Liao', 'Jingang Wang', 'Xunliang Cai', 'Weiran Xu']","As large language models (LLMs) continue to advance in capability and
influence, ensuring their security and preventing harmful outputs has become
crucial. A promising approach to address these concerns involves training
models to automatically generate adversarial prompts for red teaming. However,
the evolving subtlety of vulnerabilities in LLMs challenges the effectiveness
of current adversarial methods, which struggle to specifically target and
explore the weaknesses of these models. To tackle these challenges, we
introduce the $\mathbf{S}\text{elf-}\mathbf{E}\text{volving
}\mathbf{A}\text{dversarial }\mathbf{S}\text{afety }\mathbf{(SEAS)}$
optimization framework, which enhances security by leveraging data generated by
the model itself. SEAS operates through three iterative stages: Initialization,
Attack, and Adversarial Optimization, refining both the Red Team and Target
models to improve robustness and safety. This framework reduces reliance on
manual testing and significantly enhances the security capabilities of LLMs.
Our contributions include a novel adversarial framework, a comprehensive safety
dataset, and after three iterations, the Target model achieves a security level
comparable to GPT-4, while the Red Team model shows a marked increase in attack
success rate (ASR) against advanced models.",http://arxiv.org/pdf/2408.02632v1,2024-08-05,2408.02632v1,SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models,gpt-4,somewhat relevant,"This paper mainly focuses on the security and safety of large language models, working on an adversarial framework and optimization for these models. It discusses generating adversarial prompts, but does not indicate these are hard prefix prompts or that there's a focus on prompt engineering.",,
Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models,"['Zi Liang', 'Haibo Hu', 'Qingqing Ye', 'Yaxin Xiao', 'Haoyang Li']","The drastic increase of large language models' (LLMs) parameters has led to a
new research direction of fine-tuning-free downstream customization by prompts,
i.e., task descriptions. While these prompt-based services (e.g. OpenAI's GPTs)
play an important role in many businesses, there has emerged growing concerns
about the prompt leakage, which undermines the intellectual properties of these
services and causes downstream attacks. In this paper, we analyze the
underlying mechanism of prompt leakage, which we refer to as prompt
memorization, and develop corresponding defending strategies. By exploring the
scaling laws in prompt extraction, we analyze key attributes that influence
prompt extraction, including model sizes, prompt lengths, as well as the types
of prompts. Then we propose two hypotheses that explain how LLMs expose their
prompts. The first is attributed to the perplexity, i.e. the familiarity of
LLMs to texts, whereas the second is based on the straightforward token
translation path in attention matrices. To defend against such threats, we
investigate whether alignments can undermine the extraction of prompts. We find
that current LLMs, even those with safety alignments like GPT-4, are highly
vulnerable to prompt extraction attacks, even under the most straightforward
user attacks. Therefore, we put forward several defense strategies with the
inspiration of our findings, which achieve 83.8\% and 71.0\% drop in the prompt
extraction rate for Llama2-7B and GPT-3.5, respectively. Source code is
avaliable at \url{https://github.com/liangzid/PromptExtractionEval}.",http://arxiv.org/pdf/2408.02416v1,2024-08-05,2408.02416v1,Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models,gpt-4,somewhat relevant,"The paper talks about the usage of prompts in large language models, an analysis on the factors influencing prompt extraction and ways to defend against prompt extraction threats; but it does not specifically discuss hard prefix prompts.",,
A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models,"['Vanni Zavarella', 'Juan Carlos Gamero-Salinas', 'Sergio Consoli']","Knowledge graphs (KGs) have been successfully applied to the analysis of
complex scientific and technological domains, with automatic KG generation
methods typically building upon relation extraction models capturing
fine-grained relations between domain entities in text. While these relations
are fully applicable across scientific areas, existing models are trained on
few domain-specific datasets such as SciERC and do not perform well on new
target domains. In this paper, we experiment with leveraging in-context
learning capabilities of Large Language Models to perform schema-constrained
data annotation, collecting in-domain training instances for a
Transformer-based relation extraction model deployed on titles and abstracts of
research papers in the Architecture, Construction, Engineering and Operations
(AECO) domain. By assessing the performance gain with respect to a baseline
Deep Learning architecture trained on off-domain data, we show that by using a
few-shot learning strategy with structured prompts and only minimal expert
annotation the presented approach can potentially support domain adaptation of
a science KG generation model.",http://arxiv.org/pdf/2408.02377v1,2024-08-05,2408.02377v1,A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models,gpt-4,somewhat relevant,"The paper includes a mention of using structured prompts for a few-shot learning strategy, which aligns with the concept of hard prefix prompts.",,
Operationalizing Contextual Integrity in Privacy-Conscious Assistants,"['Sahra Ghalebikesabi', 'Eugene Bagdasaryan', 'Ren Yi', 'Itay Yona', 'Ilia Shumailov', 'Aneesh Pappu', 'Chongyang Shi', 'Laura Weidinger', 'Robert Stanforth', 'Leonard Berrada', 'Pushmeet Kohli', 'Po-Sen Huang', 'Borja Balle']","Advanced AI assistants combine frontier LLMs and tool access to autonomously
perform complex tasks on behalf of users. While the helpfulness of such
assistants can increase dramatically with access to user information including
emails and documents, this raises privacy concerns about assistants sharing
inappropriate information with third parties without user supervision. To steer
information-sharing assistants to behave in accordance with privacy
expectations, we propose to operationalize $\textit{contextual integrity}$
(CI), a framework that equates privacy with the appropriate flow of information
in a given context. In particular, we design and evaluate a number of
strategies to steer assistants' information-sharing actions to be CI compliant.
Our evaluation is based on a novel form filling benchmark composed of synthetic
data and human annotations, and it reveals that prompting frontier LLMs to
perform CI-based reasoning yields strong results.",http://arxiv.org/pdf/2408.02373v1,2024-08-05,2408.02373v1,Operationalizing Contextual Integrity in Privacy-Conscious Assistants,gpt-4,somewhat relevant,"The paper focuses on using prompting to steer the behavior of the AI assistants, specifically for information sharing, but it doesn't specify whether it utilizes hard prefix prompting.",,
Spin glass model of in-context learning,"['Yuhao Li', 'Ruoran Bai', 'Haiping Huang']","Large language models show a surprising in-context learning ability -- being
able to use a prompt to form a prediction for a query, yet without additional
training, in stark contrast to old-fashioned supervised learning. Providing a
mechanistic interpretation and linking the empirical phenomenon to physics are
thus challenging and remain unsolved. We study a simple yet expressive
transformer with linear attention, and map this structure to a spin glass model
with real-valued spins, where the couplings and fields explain the intrinsic
disorder in data. The spin glass model explains how the weight parameters
interact with each other during pre-training, and most importantly why an
unseen function can be predicted by providing only a prompt yet without
training. Our theory reveals that for single instance learning, increasing the
task diversity leads to the emergence of the in-context learning, by allowing
the Boltzmann distribution to converge to a unique correct solution of weight
parameters. Therefore the pre-trained transformer displays a prediction power
in a novel prompt setting. The proposed spin glass model thus establishes a
foundation to understand the empirical success of large language models.",http://arxiv.org/pdf/2408.02288v1,2024-08-05,2408.02288v1,Spin glass model of in-context learning,gpt-4,somewhat relevant,"While the paper discusses the use of prompts in prediction and learning context, it doesn't specifically address hard prefix prompting or prompt engineering techniques.",,
Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought Decoding,"['Renato Vukovic', 'David Arps', 'Carel van Niekerk', 'Benjamin Matthias Ruppik', 'Hsien-Chin Lin', 'Michael Heck', 'Milica Gašić']","State-of-the-art task-oriented dialogue systems typically rely on
task-specific ontologies for fulfilling user queries. The majority of
task-oriented dialogue data, such as customer service recordings, comes without
ontology and annotation. Such ontologies are normally built manually, limiting
the application of specialised systems. Dialogue ontology construction is an
approach for automating that process and typically consists of two steps: term
extraction and relation extraction. In this work, we focus on relation
extraction in a transfer learning set-up. To improve the generalisation, we
propose an extension to the decoding mechanism of large language models. We
adapt Chain-of-Thought (CoT) decoding, recently developed for reasoning
problems, to generative relation extraction. Here, we generate multiple
branches in the decoding space and select the relations based on a confidence
threshold. By constraining the decoding to ontology terms and relations, we aim
to decrease the risk of hallucination. We conduct extensive experimentation on
two widely used datasets and find improvements in performance on target
ontology for source fine-tuned and one-shot prompted large language models.",http://arxiv.org/pdf/2408.02361v1,2024-08-05,2408.02361v1,Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought Decoding,gpt-4,somewhat irrelevant,"The study discusses the extension of the decoding mechanism of large language models and adaptation of Chain-of-Thought (CoT) decoding for generative relation extraction, but it doesn't make direct reference to hard prefix prompting or prompt engineering.",,
Self-Taught Evaluators,"['Tianlu Wang', 'Ilia Kulikov', 'Olga Golovneva', 'Ping Yu', 'Weizhe Yuan', 'Jane Dwivedi-Yu', 'Richard Yuanzhe Pang', 'Maryam Fazel-Zarandi', 'Jason Weston', 'Xian Li']","Model-based evaluation is at the heart of successful model development -- as
a reward model for training, and as a replacement for human evaluation. To
train such evaluators, the standard approach is to collect a large amount of
human preference judgments over model responses, which is costly and the data
becomes stale as models improve. In this work, we present an approach that aims
to im-prove evaluators without human annotations, using synthetic training data
only. Starting from unlabeled instructions, our iterative self-improvement
scheme generates contrasting model outputs and trains an LLM-as-a-Judge to
produce reasoning traces and final judgments, repeating this training at each
new iteration using the improved predictions. Without any labeled preference
data, our Self-Taught Evaluator can improve a strong LLM (Llama3-70B-Instruct)
from 75.4 to 88.3 (88.7 with majority vote) on RewardBench. This outperforms
commonly used LLM judges such as GPT-4 and matches the performance of the
top-performing reward models trained with labeled examples.",http://arxiv.org/pdf/2408.02666v1,2024-08-05,2408.02666v1,Self-Taught Evaluators,gpt-4,highly irrelevant,"The paper focuses on model-based evaluation and an approach for improving evaluators without human annotations, but does not discuss or mention the concept of hard prefix prompting or prompt engineering.",,
Language Model Can Listen While Speaking,"['Ziyang Ma', 'Yakun Song', 'Chenpeng Du', 'Jian Cong', 'Zhuo Chen', 'Yuping Wang', 'Yuxuan Wang', 'Xie Chen']","Dialogue serves as the most natural manner of human-computer interaction
(HCI). Recent advancements in speech language models (SLM) have significantly
enhanced speech-based conversational AI. However, these models are limited to
turn-based conversation, lacking the ability to interact with humans in
real-time spoken scenarios, for example, being interrupted when the generated
content is not satisfactory. To address these limitations, we explore full
duplex modeling (FDM) in interactive speech language models (iSLM), focusing on
enhancing real-time interaction and, more explicitly, exploring the
quintessential ability of interruption. We introduce a novel model design,
namely listening-while-speaking language model (LSLM), an end-to-end system
equipped with both listening and speaking channels. Our LSLM employs a
token-based decoder-only TTS for speech generation and a streaming
self-supervised learning (SSL) encoder for real-time audio input. LSLM fuses
both channels for autoregressive generation and detects turn-taking in real
time. Three fusion strategies -- early fusion, middle fusion, and late fusion
-- are explored, with middle fusion achieving an optimal balance between speech
generation and real-time interaction. Two experimental settings, command-based
FDM and voice-based FDM, demonstrate LSLM's robustness to noise and sensitivity
to diverse instructions. Our results highlight LSLM's capability to achieve
duplex communication with minimal impact on existing systems. This study aims
to advance the development of interactive speech dialogue systems, enhancing
their applicability in real-world contexts.",http://arxiv.org/pdf/2408.02622v1,2024-08-05,2408.02622v1,Language Model Can Listen While Speaking,gpt-4,highly irrelevant,"The paper focuses on interactive speech dialogue systems and enhancements to real-time conversations, but does not discuss prompt engineering or hard prefix prompting in transformers.",,
Backward explanations via redefinition of predicates,"['Léo Saulières', 'Martin C. Cooper', 'Florence Dupin de Saint Cyr']","History eXplanation based on Predicates (HXP), studies the behavior of a
Reinforcement Learning (RL) agent in a sequence of agent's interactions with
the environment (a history), through the prism of an arbitrary predicate. To
this end, an action importance score is computed for each action in the
history. The explanation consists in displaying the most important actions to
the user. As the calculation of an action's importance is #W[1]-hard, it is
necessary for long histories to approximate the scores, at the expense of their
quality. We therefore propose a new HXP method, called Backward-HXP, to provide
explanations for these histories without having to approximate scores.
Experiments show the ability of B-HXP to summarise long histories.",http://arxiv.org/pdf/2408.02606v1,2024-08-05,2408.02606v1,Backward explanations via redefinition of predicates,gpt-4,highly irrelevant,This paper investigates explanations in reinforcement learning agent behaviour and does not mention nor hint at the topic of hard prefix prompting or prompt engineering.,,
BioMamba: A Pre-trained Biomedical Language Representation Model Leveraging Mamba,"['Ling Yue', 'Sixue Xing', 'Yingzhou Lu', 'Tianfan Fu']","The advancement of natural language processing (NLP) in biology hinges on
models' ability to interpret intricate biomedical literature. Traditional
models often struggle with the complex and domain-specific language in this
field. In this paper, we present BioMamba, a pre-trained model specifically
designed for biomedical text mining. BioMamba builds upon the Mamba
architecture and is pre-trained on an extensive corpus of biomedical
literature. Our empirical studies demonstrate that BioMamba significantly
outperforms models like BioBERT and general-domain Mamba across various
biomedical tasks. For instance, BioMamba achieves a 100 times reduction in
perplexity and a 4 times reduction in cross-entropy loss on the BioASQ test
set. We provide an overview of the model architecture, pre-training process,
and fine-tuning techniques. Additionally, we release the code and trained model
to facilitate further research.",http://arxiv.org/pdf/2408.02600v1,2024-08-05,2408.02600v1,BioMamba: A Pre-trained Biomedical Language Representation Model Leveraging Mamba,gpt-4,highly irrelevant,"The paper focuses on the architecture, training and fine-tuning of a biomedical text mining model, not on prompt engineering or specifically hard prefix prompting.",,
Progressively Selective Label Enhancement for Language Model Alignment,"['Biao Liu', 'Ning Xu', 'Xin Geng']","Large Language Models have demonstrated impressive capabilities in various
language tasks but may produce content that misaligns with human expectations,
raising ethical and legal concerns. Therefore, it is important to explore the
limitations and implement restrictions on the models to ensure safety and
compliance, with Reinforcement Learning from Human Feedback (RLHF) being the
primary method. Due to challenges in stability and scalability with the RLHF
stages, researchers are exploring alternative methods to achieve effects
comparable to those of RLHF. However, these methods often depend on large
high-quality datasets and inefficiently utilize generated data. To deal with
this problem, we propose PSLE, i.e., Progressively Selective Label Enhancement
for Language Model Alignment, a framework that fully utilizes all generated
data by guiding the model with principles to align outputs with human
expectations. Using a dynamically updated threshold, our approach ensures
efficient data utilization by incorporating all generated responses and
weighting them based on their corresponding reward scores. Experimental results
on multiple datasets demonstrate the effectiveness of PSLE compared to existing
language model alignment methods.",http://arxiv.org/pdf/2408.02599v1,2024-08-05,2408.02599v1,Progressively Selective Label Enhancement for Language Model Alignment,gpt-4,highly irrelevant,"The paper focuses on language model alignment and reinforcement learning from human feedback, without any mention of hard prefix prompting or prompt engineering.",,
Modelling Visual Semantics via Image Captioning to extract Enhanced Multi-Level Cross-Modal Semantic Incongruity Representation with Attention for Multimodal Sarcasm Detection,"['Sajal Aggarwal', 'Ananya Pandey', 'Dinesh Kumar Vishwakarma']","Sarcasm is a type of irony, characterized by an inherent mismatch between the
literal interpretation and the intended connotation. Though sarcasm detection
in text has been extensively studied, there are situations in which textual
input alone might be insufficient to perceive sarcasm. The inclusion of
additional contextual cues, such as images, is essential to recognize sarcasm
in social media data effectively. This study presents a novel framework for
multimodal sarcasm detection that can process input triplets. Two components of
these triplets comprise the input text and its associated image, as provided in
the datasets. Additionally, a supplementary modality is introduced in the form
of descriptive image captions. The motivation behind incorporating this visual
semantic representation is to more accurately capture the discrepancies between
the textual and visual content, which are fundamental to the sarcasm detection
task. The primary contributions of this study are: (1) a robust textual feature
extraction branch that utilizes a cross-lingual language model; (2) a visual
feature extraction branch that incorporates a self-regulated residual ConvNet
integrated with a lightweight spatially aware attention module; (3) an
additional modality in the form of image captions generated using an
encoder-decoder architecture capable of reading text embedded in images; (4)
distinct attention modules to effectively identify the incongruities between
the text and two levels of image representations; (5) multi-level cross-domain
semantic incongruity representation achieved through feature fusion. Compared
with cutting-edge baselines, the proposed model achieves the best accuracy of
92.89% and 64.48%, respectively, on the Twitter multimodal sarcasm and
MultiBully datasets.",http://arxiv.org/pdf/2408.02595v1,2024-08-05,2408.02595v1,Modelling Visual Semantics via Image Captioning to extract Enhanced Multi-Level Cross-Modal Semantic Incongruity Representation with Attention for Multimodal Sarcasm Detection,gpt-4,highly irrelevant,"The paper deals with image and text semantic representation for sarcasm detection, which doesn't involve hard prefix prompting or prompt engineering.",,
Leveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality Aspect-Based Summarization,"['Ankan Mullick', 'Sombit Bose', 'Rounak Saha', 'Ayan Kumar Bhowmick', 'Aditya Vempaty', 'Pawan Goyal', 'Niloy Ganguly', 'Prasenjit Dey', 'Ravi Kokku']","The ever-increasing volume of digital information necessitates efficient
methods for users to extract key insights from lengthy documents. Aspect-based
summarization offers a targeted approach, generating summaries focused on
specific aspects within a document. Despite advancements in aspect-based
summarization research, there is a continuous quest for improved model
performance. Given that large language models (LLMs) have demonstrated the
potential to revolutionize diverse tasks within natural language processing,
particularly in the problem of summarization, this paper explores the potential
of fine-tuning LLMs for the aspect-based summarization task. We evaluate the
impact of fine-tuning open-source foundation LLMs, including Llama2, Mistral,
Gemma and Aya, on a publicly available domain-specific aspect based summary
dataset. We hypothesize that this approach will enable these models to
effectively identify and extract aspect-related information, leading to
superior quality aspect-based summaries compared to the state-of-the-art. We
establish a comprehensive evaluation framework to compare the performance of
fine-tuned LLMs against competing aspect-based summarization methods and
vanilla counterparts of the fine-tuned LLMs. Our work contributes to the field
of aspect-based summarization by demonstrating the efficacy of fine-tuning LLMs
for generating high-quality aspect-based summaries. Furthermore, it opens doors
for further exploration of using LLMs for targeted information extraction tasks
across various NLP domains.",http://arxiv.org/pdf/2408.02584v1,2024-08-05,2408.02584v1,Leveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality Aspect-Based Summarization,gpt-4,highly irrelevant,This paper is focused on the fine-tuning of large language models for aspect-based summarization and does not mention or pertain to the topic of prompt engineering or hard prefix prompting.,,
Clustering and Mining Accented Speech for Inclusive and Fair Speech Recognition,"['Jaeyoung Kim', 'Han Lu', 'Soheil Khorram', 'Anshuman Tripathi', 'Qian Zhang', 'Hasim Sak']","Modern automatic speech recognition (ASR) systems are typically trained on
more than tens of thousands hours of speech data, which is one of the main
factors for their great success. However, the distribution of such data is
typically biased towards common accents or typical speech patterns. As a
result, those systems often poorly perform on atypical accented speech. In this
paper, we present accent clustering and mining schemes for fair speech
recognition systems which can perform equally well on under-represented
accented speech. For accent recognition, we applied three schemes to overcome
limited size of supervised accent data: supervised or unsupervised
pre-training, distributionally robust optimization (DRO) and unsupervised
clustering. Three schemes can significantly improve the accent recognition
model especially for unbalanced and small accented speech. Fine-tuning ASR on
the mined Indian accent speech using the proposed supervised or unsupervised
clustering schemes showed 10.0% and 5.3% relative improvements compared to
fine-tuning on the randomly sampled speech, respectively.",http://arxiv.org/pdf/2408.02582v1,2024-08-05,2408.02582v1,Clustering and Mining Accented Speech for Inclusive and Fair Speech Recognition,gpt-4,highly irrelevant,"The paper discusses about automatic speech recognition and accent recognition, with no indication of utilizing or making reference to hard prefix prompting or any form of prompt engineering.",,
Artificial Intelligence for Public Health Surveillance in Africa: Applications and Opportunities,"['Jean Marie Tshimula', 'Mitterrand Kalengayi', 'Dieumerci Makenga', 'Dorcas Lilonge', 'Marius Asumani', 'Déborah Madiya', 'Élie Nkuba Kalonji', 'Hugues Kanda', 'René Manassé Galekwa', 'Josias Kumbu', 'Hardy Mikese', 'Grace Tshimula', 'Jean Tshibangu Muabila', 'Christian N. Mayemba', ""D'Jeff K. Nkashama"", 'Kalonji Kalala', 'Steve Ataky', 'Tighana Wenge Basele', 'Mbuyi Mukendi Didier', 'Selain K. Kasereka', 'Maximilien V. Dialufuma', 'Godwill Ilunga Wa Kumwita', 'Lionel Muyuku', 'Jean-Paul Kimpesa', 'Dominique Muteba', 'Aaron Aruna Abedi', 'Lambert Mukendi Ntobo', 'Gloria M. Bundutidi', 'Désiré Kulimba Mashinda', 'Emmanuel Kabengele Mpinga', 'Nathanaël M. Kasoro']","Artificial Intelligence (AI) is revolutionizing various fields, including
public health surveillance. In Africa, where health systems frequently
encounter challenges such as limited resources, inadequate infrastructure,
failed health information systems and a shortage of skilled health
professionals, AI offers a transformative opportunity. This paper investigates
the applications of AI in public health surveillance across the continent,
presenting successful case studies and examining the benefits, opportunities,
and challenges of implementing AI technologies in African healthcare settings.
Our paper highlights AI's potential to enhance disease monitoring and health
outcomes, and support effective public health interventions. The findings
presented in the paper demonstrate that AI can significantly improve the
accuracy and timeliness of disease detection and prediction, optimize resource
allocation, and facilitate targeted public health strategies. Additionally, our
paper identified key barriers to the widespread adoption of AI in African
public health systems and proposed actionable recommendations to overcome these
challenges.",http://arxiv.org/pdf/2408.02575v1,2024-08-05,2408.02575v1,Artificial Intelligence for Public Health Surveillance in Africa: Applications and Opportunities,gpt-4,highly irrelevant,The paper discusses the application of AI in public health surveillance in Africa but does not mention anything related to prompt engineering or hard prefix prompting.,,
Contrastive Learning-based Multi Modal Architecture for Emoticon Prediction by Employing Image-Text Pairs,"['Ananya Pandey', 'Dinesh Kumar Vishwakarma']","The emoticons are symbolic representations that generally accompany the
textual content to visually enhance or summarize the true intention of a
written message. Although widely utilized in the realm of social media, the
core semantics of these emoticons have not been extensively explored based on
multiple modalities. Incorporating textual and visual information within a
single message develops an advanced way of conveying information. Hence, this
research aims to analyze the relationship among sentences, visuals, and
emoticons. For an orderly exposition, this paper initially provides a detailed
examination of the various techniques for extracting multimodal features,
emphasizing the pros and cons of each method. Through conducting a
comprehensive examination of several multimodal algorithms, with specific
emphasis on the fusion approaches, we have proposed a novel contrastive
learning based multimodal architecture. The proposed model employs the joint
training of dual-branch encoder along with the contrastive learning to
accurately map text and images into a common latent space. Our key finding is
that by integrating the principle of contrastive learning with that of the
other two branches yields superior results. The experimental results
demonstrate that our suggested methodology surpasses existing multimodal
approaches in terms of accuracy and robustness. The proposed model attained an
accuracy of 91% and an MCC-score of 90% while assessing emoticons using the
Multimodal-Twitter Emoticon dataset acquired from Twitter. We provide evidence
that deep features acquired by contrastive learning are more efficient,
suggesting that the proposed fusion technique also possesses strong
generalisation capabilities for recognising emoticons across several modes.",http://arxiv.org/pdf/2408.02571v1,2024-08-05,2408.02571v1,Contrastive Learning-based Multi Modal Architecture for Emoticon Prediction by Employing Image-Text Pairs,gpt-4,highly irrelevant,"This paper does not discuss the concept of hard prefix prompting or prompt engineering at all, it instead focuses on emoticon prediction via multimodal approaches.",,
Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information,"['Yauwai Yim', 'Chunkit Chan', 'Tianyu Shi', 'Zheye Deng', 'Wei Fan', 'Tianshi Zheng', 'Yangqiu Song']","Large language models (LLMs) have shown success in handling simple games with
imperfect information and enabling multi-agent coordination, but their ability
to facilitate practical collaboration against other agents in complex,
imperfect information environments, especially in a non-English environment,
still needs to be explored. This study investigates the applicability of
knowledge acquired by open-source and API-based LLMs to sophisticated
text-based games requiring agent collaboration under imperfect information,
comparing their performance to established baselines using other types of
agents. We propose a Theory of Mind (ToM) planning technique that allows LLM
agents to adapt their strategy against various adversaries using only game
rules, current state, and historical context as input. An external tool was
incorporated to mitigate the challenge of dynamic and extensive action spaces
in this card game. Our results show that although a performance gap exists
between current LLMs and state-of-the-art reinforcement learning (RL) models,
LLMs demonstrate ToM capabilities in this game setting. It consistently
improves their performance against opposing agents, suggesting their ability to
understand the actions of allies and adversaries and establish collaboration
with allies. To encourage further research and understanding, we have made our
codebase openly accessible.",http://arxiv.org/pdf/2408.02559v1,2024-08-05,2408.02559v1,Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information,gpt-4,highly irrelevant,"The paper does not discuss the topic of hard prefix prompts or prompt engineering, focusing instead on agent collaboration and theory of mind in games.",,
MeshAnything V2: Artist-Created Mesh Generation With Adjacent Mesh Tokenization,"['Yiwen Chen', 'Yikai Wang', 'Yihao Luo', 'Zhengyi Wang', 'Zilong Chen', 'Jun Zhu', 'Chi Zhang', 'Guosheng Lin']","We introduce MeshAnything V2, an autoregressive transformer that generates
Artist-Created Meshes (AM) aligned to given shapes. It can be integrated with
various 3D asset production pipelines to achieve high-quality, highly
controllable AM generation. MeshAnything V2 surpasses previous methods in both
efficiency and performance using models of the same size. These improvements
are due to our newly proposed mesh tokenization method: Adjacent Mesh
Tokenization (AMT). Different from previous methods that represent each face
with three vertices, AMT uses a single vertex whenever possible. Compared to
previous methods, AMT requires about half the token sequence length to
represent the same mesh in average. Furthermore, the token sequences from AMT
are more compact and well-structured, fundamentally benefiting AM generation.
Our extensive experiments show that AMT significantly improves the efficiency
and performance of AM generation. Project Page:
https://buaacyw.github.io/meshanything-v2/",http://arxiv.org/pdf/2408.02555v1,2024-08-05,2408.02555v1,MeshAnything V2: Artist-Created Mesh Generation With Adjacent Mesh Tokenization,gpt-4,highly irrelevant,"This paper focuses on mesh generation and tokenization methods in 3D asset production, not on prompt engineering or hard prefix prompting",,
The Role of Functional Muscle Networks in Improving Hand Gesture Perception for Human-Machine Interfaces,"['Costanza Armanini', 'Tuka Alhanai', 'Farah E. Shamout', 'S. Farokh Atashzar']","Developing accurate hand gesture perception models is critical for various
robotic applications, enabling effective communication between humans and
machines and directly impacting neurorobotics and interactive robots. Recently,
surface electromyography (sEMG) has been explored for its rich informational
context and accessibility when combined with advanced machine learning
approaches and wearable systems. The literature presents numerous approaches to
boost performance while ensuring robustness for neurorobots using sEMG, often
resulting in models requiring high processing power, large datasets, and less
scalable solutions. This paper addresses this challenge by proposing the
decoding of muscle synchronization rather than individual muscle activation. We
study coherence-based functional muscle networks as the core of our perception
model, proposing that functional synchronization between muscles and the
graph-based network of muscle connectivity encode contextual information about
intended hand gestures. This can be decoded using shallow machine learning
approaches without the need for deep temporal networks. Our technique could
impact myoelectric control of neurorobots by reducing computational burdens and
enhancing efficiency. The approach is benchmarked on the Ninapro database,
which contains 12 EMG signals from 40 subjects performing 17 hand gestures. It
achieves an accuracy of 85.1%, demonstrating improved performance compared to
existing methods while requiring much less computational power. The results
support the hypothesis that a coherence-based functional muscle network encodes
critical information related to gesture execution, significantly enhancing hand
gesture perception with potential applications for neurorobotic systems and
interactive machines.",http://arxiv.org/pdf/2408.02547v1,2024-08-05,2408.02547v1,The Role of Functional Muscle Networks in Improving Hand Gesture Perception for Human-Machine Interfaces,gpt-4,highly irrelevant,"The paper does not discuss or mention hard prefix prompts, prompt engineering, or anything related to the creation or application of prompts in transformers. Instead, it focuses on hand gesture perception models and neurorobotics, making it irrelevant to prompt engineering.",,
RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation,"['Daniel Fleischer', 'Moshe Berchansky', 'Moshe Wasserblat', 'Peter Izsak']","Implementing Retrieval-Augmented Generation (RAG) systems is inherently
complex, requiring deep understanding of data, use cases, and intricate design
decisions. Additionally, evaluating these systems presents significant
challenges, necessitating assessment of both retrieval accuracy and generative
quality through a multi-faceted approach. We introduce RAG Foundry, an
open-source framework for augmenting large language models for RAG use cases.
RAG Foundry integrates data creation, training, inference and evaluation into a
single workflow, facilitating the creation of data-augmented datasets for
training and evaluating large language models in RAG settings. This integration
enables rapid prototyping and experimentation with various RAG techniques,
allowing users to easily generate datasets and train RAG models using internal
or specialized knowledge sources. We demonstrate the framework effectiveness by
augmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG
configurations, showcasing consistent improvements across three
knowledge-intensive datasets. Code is released as open-source in
https://github.com/IntelLabs/RAGFoundry.",http://arxiv.org/pdf/2408.02545v1,2024-08-05,2408.02545v1,RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation,gpt-4,highly irrelevant,"The paper discusses the development of a framework for Retrieval-Augmented Generation systems, with particular focus on data augmentation, training, and evaluation of large language models, not on prompting techniques or approaches.",,
Caution for the Environment: Multimodal Agents are Susceptible to Environmental Distractions,"['Xinbei Ma', 'Yiting Wang', 'Yao Yao', 'Tongxin Yuan', 'Aston Zhang', 'Zhuosheng Zhang', 'Hai Zhao']","This paper investigates the faithfulness of multimodal large language model
(MLLM) agents in the graphical user interface (GUI) environment, aiming to
address the research question of whether multimodal GUI agents can be
distracted by environmental context. A general setting is proposed where both
the user and the agent are benign, and the environment, while not malicious,
contains unrelated content. A wide range of MLLMs are evaluated as GUI agents
using our simulated dataset, following three working patterns with different
levels of perception. Experimental results reveal that even the most powerful
models, whether generalist agents or specialist GUI agents, are susceptible to
distractions. While recent studies predominantly focus on the helpfulness
(i.e., action accuracy) of multimodal agents, our findings indicate that these
agents are prone to environmental distractions, resulting in unfaithful
behaviors. Furthermore, we switch to the adversarial perspective and implement
environment injection, demonstrating that such unfaithfulness can be exploited,
leading to unexpected risks.",http://arxiv.org/pdf/2408.02544v1,2024-08-05,2408.02544v1,Caution for the Environment: Multimodal Agents are Susceptible to Environmental Distractions,gpt-4,highly irrelevant,"The document discusses multimodal large language models and their susceptibility to distractions in a graphical user interface (GUI) environment, but does not mention anything related to prompt engineering.",,
Counterfactual Shapley Values for Explaining Reinforcement Learning,"['Yiwei Shi', 'Qi Zhang', 'Kevin McAreavey', 'Weiru Liu']","This paper introduces a novel approach Counterfactual Shapley Values (CSV),
which enhances explainability in reinforcement learning (RL) by integrating
counterfactual analysis with Shapley Values. The approach aims to quantify and
compare the contributions of different state dimensions to various action
choices. To more accurately analyze these impacts, we introduce new
characteristic value functions, the ``Counterfactual Difference Characteristic
Value"" and the ``Average Counterfactual Difference Characteristic Value."" These
functions help calculate the Shapley values to evaluate the differences in
contributions between optimal and non-optimal actions. Experiments across
several RL domains, such as GridWorld, FrozenLake, and Taxi, demonstrate the
effectiveness of the CSV method. The results show that this method not only
improves transparency in complex RL systems but also quantifies the differences
across various decisions.",http://arxiv.org/pdf/2408.02529v1,2024-08-05,2408.02529v1,Counterfactual Shapley Values for Explaining Reinforcement Learning,gpt-4,highly irrelevant,The paper focuses on reinforcing learning and quantifying contributions to various action choices as opposed to prompt engineering or hard prefix prompting.,,
Single-tap Latency Reduction with Single- or Double- tap Prediction,"['Naoto Nishida', 'Kaori Ikematsu', 'Junichi Sato', 'Shota Yamanaka', 'Kota Tsubouchi']","Touch surfaces are widely utilized for smartphones, tablet PCs, and laptops
(touchpad), and single and double taps are the most basic and common operations
on them. The detection of single or double taps causes the single-tap latency
problem, which creates a bottleneck in terms of the sensitivity of touch
inputs. To reduce the single-tap latency, we propose a novel
machine-learning-based tap prediction method called PredicTaps. Our method
predicts whether a detected tap is a single tap or the first contact of a
double tap without having to wait for the hundreds of milliseconds
conventionally required. We present three evaluations and one user evaluation
that demonstrate its broad applicability and usability for various tap
situations on two form factors (touchpad and smartphone). The results showed
PredicTaps reduces the single-tap latency from 150-500 ms to 12 ms on laptops
and to 17.6 ms on smartphones without reducing usability.",http://arxiv.org/pdf/2408.02525v1,2024-08-05,2408.02525v1,Single-tap Latency Reduction with Single- or Double- tap Prediction,gpt-4,highly irrelevant,The paper focuses on tap prediction on touch surfaces and does not touch on the topic of prompt engineering or hard prefix prompting.,,
OneLove beyond the field -- A few-shot pipeline for topic and sentiment analysis during the FIFA World Cup in Qatar,"['Christoph Rauchegger', 'Sonja Mei Wang', 'Pieter Delobelle']","The FIFA World Cup in Qatar was discussed extensively in the news and on
social media. Due to news reports with allegations of human rights violations,
there were calls to boycott it. Wearing a OneLove armband was part of a planned
protest activity. Controversy around the armband arose when FIFA threatened to
sanction captains who wear it. To understand what topics Twitter users Tweeted
about and what the opinion of German Twitter users was towards the OneLove
armband, we performed an analysis of German Tweets published during the World
Cup using in-context learning with LLMs. We validated the labels on human
annotations. We found that Twitter users initially discussed the armband's
impact, LGBT rights, and politics; after the ban, the conversation shifted
towards politics in sports in general, accompanied by a subtle shift in
sentiment towards neutrality. Our evaluation serves as a framework for future
research to explore the impact of sports activism and evolving public
sentiment. This is especially useful in settings where labeling datasets for
specific opinions is unfeasible, such as when events are unfolding.",http://arxiv.org/pdf/2408.02520v1,2024-08-05,2408.02520v1,OneLove beyond the field -- A few-shot pipeline for topic and sentiment analysis during the FIFA World Cup in Qatar,gpt-4,highly irrelevant,"The paper utilizes in-context learning with LLMs for tweet analysis, but does not mention any topic related to hard prefix prompts or prompt engineering",,
UnifiedMLLM: Enabling Unified Representation for Multi-modal Multi-tasks With Large Language Model,"['Zhaowei Li', 'Wei Wang', 'YiQing Cai', 'Xu Qi', 'Pengyu Wang', 'Dong Zhang', 'Hang Song', 'Botian Jiang', 'Zhida Huang', 'Tao Wang']","Significant advancements has recently been achieved in the field of
multi-modal large language models (MLLMs), demonstrating their remarkable
capabilities in understanding and reasoning across diverse tasks. However,
these models are often trained for specific tasks and rely on task-specific
input-output formats, limiting their applicability to a broader range of tasks.
This raises a fundamental question: Can we develop a unified approach to
represent and handle different multi-modal tasks to maximize the
generalizability of MLLMs? In this paper, we propose UnifiedMLLM, a
comprehensive model designed to represent various tasks using a unified
representation. Our model exhibits strong capabilities in comprehending the
implicit intent of user instructions and preforming reasoning. In addition to
generating textual responses, our model also outputs task tokens and grounding
tokens, serving as indicators of task types and task granularity. These outputs
are subsequently routed through the task router and directed to specific expert
models for task completion. To train our model, we construct a task-specific
dataset and an 100k multi-task dataset encompassing complex scenarios.
Employing a three-stage training strategy, we equip our model with robust
reasoning and task processing capabilities while preserving its generalization
capacity and knowledge reservoir. Extensive experiments showcase the impressive
performance of our unified representation approach across various tasks,
surpassing existing methodologies. Furthermore, our approach exhibits
exceptional scalability and generality. Our code, model, and dataset will be
available at \url{https://github.com/lzw-lzw/UnifiedMLLM}.",http://arxiv.org/pdf/2408.02503v1,2024-08-05,2408.02503v1,UnifiedMLLM: Enabling Unified Representation for Multi-modal Multi-tasks With Large Language Model,gpt-4,highly irrelevant,"The paper discusses the design and training of a multi-modal large language model, not hard prefix prompting or prompt engineering.",,
A First Look at License Compliance Capability of LLMs in Code Generation,"['Weiwei Xu', 'Kai Gao', 'Hao He', 'Minghui Zhou']","Recent advances in Large Language Models (LLMs) have revolutionized code
generation, leading to widespread adoption of AI coding tools by developers.
However, LLMs can generate license-protected code without providing the
necessary license information, leading to potential intellectual property
violations during software production. This paper addresses the critical, yet
underexplored, issue of license compliance in LLM-generated code by
establishing a benchmark to evaluate the ability of LLMs to provide accurate
license information for their generated code. To establish this benchmark, we
conduct an empirical study to identify a reasonable standard for ""striking
similarity"" that excludes the possibility of independent creation, indicating a
copy relationship between the LLM output and certain open-source code. Based on
this standard, we propose an evaluation benchmark LiCoEval, to evaluate the
license compliance capabilities of LLMs. Using LiCoEval, we evaluate 14 popular
LLMs, finding that even top-performing LLMs produce a non-negligible proportion
(0.88% to 2.01%) of code strikingly similar to existing open-source
implementations. Notably, most LLMs fail to provide accurate license
information, particularly for code under copyleft licenses. These findings
underscore the urgent need to enhance LLM compliance capabilities in code
generation tasks. Our study provides a foundation for future research and
development to improve license compliance in AI-assisted software development,
contributing to both the protection of open-source software copyrights and the
mitigation of legal risks for LLM users.",http://arxiv.org/pdf/2408.02487v1,2024-08-05,2408.02487v1,A First Look at License Compliance Capability of LLMs in Code Generation,gpt-4,highly irrelevant,"The paper is focused on license compliance problems in code generated by Large Language Models, rather than prompt engineering or hard prefix prompting.",,
"From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future","['Haolin Jin', 'Linghan Huang', 'Haipeng Cai', 'Jun Yan', 'Bo Li', 'Huaming Chen']","With the rise of large language models (LLMs), researchers are increasingly
exploring their applications in var ious vertical domains, such as software
engineering. LLMs have achieved remarkable success in areas including code
generation and vulnerability detection. However, they also exhibit numerous
limitations and shortcomings. LLM-based agents, a novel tech nology with the
potential for Artificial General Intelligence (AGI), combine LLMs as the core
for decision-making and action-taking, addressing some of the inherent
limitations of LLMs such as lack of autonomy and self-improvement. Despite
numerous studies and surveys exploring the possibility of using LLMs in
software engineering, it lacks a clear distinction between LLMs and LLM based
agents. It is still in its early stage for a unified standard and benchmarking
to qualify an LLM solution as an LLM-based agent in its domain. In this survey,
we broadly investigate the current practice and solutions for LLMs and
LLM-based agents for software engineering. In particular we summarise six key
topics: requirement engineering, code generation, autonomous decision-making,
software design, test generation, and software maintenance. We review and
differentiate the work of LLMs and LLM-based agents from these six topics,
examining their differences and similarities in tasks, benchmarks, and
evaluation metrics. Finally, we discuss the models and benchmarks used,
providing a comprehensive analysis of their applications and effectiveness in
software engineering. We anticipate this work will shed some lights on pushing
the boundaries of LLM-based agents in software engineering for future research.",http://arxiv.org/pdf/2408.02479v1,2024-08-05,2408.02479v1,"From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future",gpt-4,highly irrelevant,"The paper is focused on the applications, limitations and improvements of Large Language Models and LLM-based agents in the domain of software engineering, without any mention of hard prefix prompting or prompt engineering.",,
An investigation into the causes of race bias in AI-based cine CMR segmentation,"['Tiarna Lee', 'Esther Puyol-Anton', 'Bram Ruijsink', 'Sebastien Roujol', 'Theodore Barfoot', 'Shaheim Ogbomo-Harmitt', 'Miaojing Shi', 'Andrew P. King']","Artificial intelligence (AI) methods are being used increasingly for the
automated segmentation of cine cardiac magnetic resonance (CMR) imaging.
However, these methods have been shown to be subject to race bias, i.e. they
exhibit different levels of performance for different races depending on the
(im)balance of the data used to train the AI model. In this paper we
investigate the source of this bias, seeking to understand its root cause(s) so
that it can be effectively mitigated. We perform a series of classification and
segmentation experiments on short-axis cine CMR images acquired from Black and
White subjects from the UK Biobank and apply AI interpretability methods to
understand the results. In the classification experiments, we found that race
can be predicted with high accuracy from the images alone, but less accurately
from ground truth segmentations, suggesting that the distributional shift
between races, which is often the cause of AI bias, is mostly image-based
rather than segmentation-based. The interpretability methods showed that most
attention in the classification models was focused on non-heart regions, such
as subcutaneous fat. Cropping the images tightly around the heart reduced
classification accuracy to around chance level. Similarly, race can be
predicted from the latent representations of a biased segmentation model,
suggesting that race information is encoded in the model. Cropping images
tightly around the heart reduced but did not eliminate segmentation bias. We
also investigate the influence of possible confounders on the bias observed.",http://arxiv.org/pdf/2408.02462v1,2024-08-05,2408.02462v1,An investigation into the causes of race bias in AI-based cine CMR segmentation,gpt-4,highly irrelevant,This paper primarily focuses on investigating race bias in AR-based cine CMR segmentation and does not mention or imply usage of hard prefix prompting or any form of prompt engineering.,,
Enhancing Heterogeneous Knowledge Graph Completion with a Novel GAT-based Approach,"['Wanxu Wei', 'Yitong Song', 'Bin Yao']","Knowledge graphs (KGs) play a vital role in enhancing search results and
recommendation systems. With the rapid increase in the size of the KGs, they
are becoming inaccuracy and incomplete. This problem can be solved by the
knowledge graph completion methods, of which graph attention network
(GAT)-based methods stand out since their superior performance. However,
existing GAT-based knowledge graph completion methods often suffer from
overfitting issues when dealing with heterogeneous knowledge graphs, primarily
due to the unbalanced number of samples. Additionally, these methods
demonstrate poor performance in predicting the tail (head) entity that shares
the same relation and head (tail) entity with others. To solve these problems,
we propose GATH, a novel GAT-based method designed for Heterogeneous KGs. GATH
incorporates two separate attention network modules that work synergistically
to predict the missing entities. We also introduce novel encoding and feature
transformation approaches, enabling the robust performance of GATH in scenarios
with imbalanced samples. Comprehensive experiments are conducted to evaluate
the GATH's performance. Compared with the existing SOTA GAT-based model on
Hits@10 and MRR metrics, our model improves performance by 5.2% and 5.2% on the
FB15K-237 dataset, and by 4.5% and 14.6% on the WN18RR dataset, respectively.",http://arxiv.org/pdf/2408.02456v1,2024-08-05,2408.02456v1,Enhancing Heterogeneous Knowledge Graph Completion with a Novel GAT-based Approach,gpt-4,highly irrelevant,"The paper focuses on the topic of knowledge graph completion, specifically detailing the development and evaluation of a GAT-based method for heterogeneous knowledge graphs, with no reference to prompt engineering or hard prefix prompting techniques.",,
Let Me Speak Freely? A Study on the Impact of Format Restrictions on Performance of Large Language Models,"['Zhi Rui Tam', 'Cheng-Kuang Wu', 'Yi-Lin Tsai', 'Chieh-Yen Lin', 'Hung-yi Lee', 'Yun-Nung Chen']","Structured generation, the process of producing content in standardized
formats like JSON and XML, is widely utilized in real-world applications to
extract key output information from large language models (LLMs). This study
investigates whether such constraints on generation space impact LLMs'
abilities, including reasoning and domain knowledge comprehension.
Specifically, we evaluate LLMs' performance when restricted to adhere to
structured formats versus generating free-form responses across various common
tasks. Surprisingly, we observe a significant decline in LLMs' reasoning
abilities under format restrictions. Furthermore, we find that stricter format
constraints generally lead to greater performance degradation in reasoning
tasks.",http://arxiv.org/pdf/2408.02442v1,2024-08-05,2408.02442v1,Let Me Speak Freely? A Study on the Impact of Format Restrictions on Performance of Large Language Models,gpt-4,highly irrelevant,"The abstract discusses structure generation in LLMs and their performance with various output format restrictions, but it does not mention prefix prompts or prompt engineering.",,
Long Input Benchmark for Russian Analysis,"['Igor Churin', 'Murat Apishev', 'Maria Tikhonova', 'Denis Shevelev', 'Aydar Bulatov', 'Yuri Kuratov', 'Sergej Averkiev', 'Alena Fenogenova']","Recent advancements in Natural Language Processing (NLP) have fostered the
development of Large Language Models (LLMs) that can solve an immense variety
of tasks. One of the key aspects of their application is their ability to work
with long text documents and to process long sequences of tokens. This has
created a demand for proper evaluation of long-context understanding. To
address this need for the Russian language, we propose LIBRA (Long Input
Benchmark for Russian Analysis), which comprises 21 adapted datasets to study
the LLM's abilities to understand long texts thoroughly. The tests are divided
into four complexity groups and allow the evaluation of models across various
context lengths ranging from 4k up to 128k tokens. We provide the open-source
datasets, codebase, and public leaderboard for LIBRA to guide forthcoming
research.",http://arxiv.org/pdf/2408.02439v1,2024-08-05,2408.02439v1,Long Input Benchmark for Russian Analysis,gpt-4,highly irrelevant,"The paper focuses on the evaluation of Long Language Models (LLMs) and the development of a benchmark for Russian language analysis, but does not mention anything related to hard prefix prompting or prompt engineering.",,
"Infusing Emotions into Task-oriented Dialogue Systems: Understanding, Management, and Generation","['Shutong Feng', 'Hsien-chin Lin', 'Christian Geishauser', 'Nurul Lubis', 'Carel van Niekerk', 'Michael Heck', 'Benjamin Ruppik', 'Renato Vukovic', 'Milica Gašić']","Emotions are indispensable in human communication, but are often overlooked
in task-oriented dialogue (ToD) modelling, where the task success is the
primary focus. While existing works have explored user emotions or similar
concepts in some ToD tasks, none has so far included emotion modelling into a
fully-fledged ToD system nor conducted interaction with human or simulated
users. In this work, we incorporate emotion into the complete ToD processing
loop, involving understanding, management, and generation. To this end, we
extend the EmoWOZ dataset (Feng et al., 2022) with system affective behaviour
labels. Through interactive experimentation involving both simulated and human
users, we demonstrate that our proposed framework significantly enhances the
user's emotional experience as well as the task success.",http://arxiv.org/pdf/2408.02417v1,2024-08-05,2408.02417v1,"Infusing Emotions into Task-oriented Dialogue Systems: Understanding, Management, and Generation",gpt-4,highly irrelevant,"The paper discusses infusing emotions into dialog systems and mentions tasks such as understanding, management, and generation, but does not mention anything related to hard prefix prompting or prompt engineering in general.",,
PENDRAM: Enabling High-Performance and Energy-Efficient Processing of Deep Neural Networks through a Generalized DRAM Data Mapping Policy,"['Rachmad Vidya Wicaksana Putra', 'Muhammad Abdullah Hanif', 'Muhammad Shafique']","Convolutional Neural Networks (CNNs), a prominent type of Deep Neural
Networks (DNNs), have emerged as a state-of-the-art solution for solving
machine learning tasks. To improve the performance and energy efficiency of CNN
inference, the employment of specialized hardware accelerators is prevalent.
However, CNN accelerators still face performance- and energy-efficiency
challenges due to high off-chip memory (DRAM) access latency and energy, which
are especially crucial for latency- and energy-constrained embedded
applications. Moreover, different DRAM architectures have different profiles of
access latency and energy, thus making it challenging to optimize them for high
performance and energy-efficient CNN accelerators. To address this, we present
PENDRAM, a novel design space exploration methodology that enables
high-performance and energy-efficient CNN acceleration through a generalized
DRAM data mapping policy. Specifically, it explores the impact of different
DRAM data mapping policies and DRAM architectures across different CNN
partitioning and scheduling schemes on the DRAM access latency and energy, then
identifies the pareto-optimal design choices. The experimental results show
that our DRAM data mapping policy improves the energy-delay-product of DRAM
accesses in the CNN accelerator over other mapping policies by up to 96%. In
this manner, our PENDRAM methodology offers high-performance and
energy-efficient CNN acceleration under any given DRAM architectures for
diverse embedded AI applications.",http://arxiv.org/pdf/2408.02412v1,2024-08-05,2408.02412v1,PENDRAM: Enabling High-Performance and Energy-Efficient Processing of Deep Neural Networks through a Generalized DRAM Data Mapping Policy,gpt-4,highly irrelevant,"The paper is focused on optimizing performance and energy efficiency for convolutional neural networks through hardware acceleration and DRAM data mapping, not on prompt engineering.",,
Multi-weather Cross-view Geo-localization Using Denoising Diffusion Models,"['Tongtong Feng', 'Qing Li', 'Xin Wang', 'Mingzi Wang', 'Guangyao Li', 'Wenwu Zhu']","Cross-view geo-localization in GNSS-denied environments aims to determine an
unknown location by matching drone-view images with the correct geo-tagged
satellite-view images from a large gallery. Recent research shows that learning
discriminative image representations under specific weather conditions can
significantly enhance performance. However, the frequent occurrence of unseen
extreme weather conditions hinders progress. This paper introduces MCGF, a
Multi-weather Cross-view Geo-localization Framework designed to dynamically
adapt to unseen weather conditions. MCGF establishes a joint optimization
between image restoration and geo-localization using denoising diffusion
models. For image restoration, MCGF incorporates a shared encoder and a
lightweight restoration module to help the backbone eliminate weather-specific
information. For geo-localization, MCGF uses EVA-02 as a backbone for feature
extraction, with cross-entropy loss for training and cosine distance for
testing. Extensive experiments on University160k-WX demonstrate that MCGF
achieves competitive results for geo-localization in varying weather
conditions.",http://arxiv.org/pdf/2408.02408v1,2024-08-05,2408.02408v1,Multi-weather Cross-view Geo-localization Using Denoising Diffusion Models,gpt-4,highly irrelevant,"The paper focuses on geo-localization in varying weather conditions using image restoration and denoising diffusion models, with no mention of prompt engineering or hard prefix prompting.",,
Enhancing AI-based Generation of Software Exploits with Contextual Information,"['Pietro Liguori', 'Cristina Improta', 'Roberto Natella', 'Bojan Cukic', 'Domenico Cotroneo']","This practical experience report explores Neural Machine Translation (NMT)
models' capability to generate offensive security code from natural language
(NL) descriptions, highlighting the significance of contextual understanding
and its impact on model performance. Our study employs a dataset comprising
real shellcodes to evaluate the models across various scenarios, including
missing information, necessary context, and unnecessary context. The
experiments are designed to assess the models' resilience against incomplete
descriptions, their proficiency in leveraging context for enhanced accuracy,
and their ability to discern irrelevant information. The findings reveal that
the introduction of contextual data significantly improves performance.
However, the benefits of additional context diminish beyond a certain point,
indicating an optimal level of contextual information for model training.
Moreover, the models demonstrate an ability to filter out unnecessary context,
maintaining high levels of accuracy in the generation of offensive security
code. This study paves the way for future research on optimizing context use in
AI-driven code generation, particularly for applications requiring a high
degree of technical precision such as the generation of offensive code.",http://arxiv.org/pdf/2408.02402v1,2024-08-05,2408.02402v1,Enhancing AI-based Generation of Software Exploits with Contextual Information,gpt-4,highly irrelevant,This paper is focused on Neural Machine Translation (NMT) models' ability to generate security code based on contextual understanding. It does not discuss prompt engineering or hard prefix prompting techniques.,,
Perfect Information Monte Carlo with Postponing Reasoning,"['Jérôme Arjonilla', 'Abdallah Saffidine', 'Tristan Cazenave']","Imperfect information games, such as Bridge and Skat, present challenges due
to state-space explosion and hidden information, posing formidable obstacles
for search algorithms. Determinization-based algorithms offer a resolution by
sampling hidden information and solving the game in a perfect information
setting, facilitating rapid and effective action estimation. However,
transitioning to perfect information introduces challenges, notably one called
strategy fusion.This research introduces `Extended Perfect Information Monte
Carlo' (EPIMC), an online algorithm inspired by the state-of-the-art
determinization-based approach Perfect Information Monte Carlo (PIMC). EPIMC
enhances the capabilities of PIMC by postponing the perfect information
resolution, reducing alleviating issues related to strategy fusion. However,
the decision to postpone the leaf evaluator introduces novel considerations,
such as the interplay between prior levels of reasoning and the newly deferred
resolution. In our empirical analysis, we investigate the performance of EPIMC
across a range of games, with a particular focus on those characterized by
varying degrees of strategy fusion. Our results demonstrate notable performance
enhancements, particularly in games where strategy fusion significantly impacts
gameplay. Furthermore, our research contributes to the theoretical foundation
of determinization-based algorithms addressing challenges associated with
strategy fusion.%, thereby enhancing our understanding of these algorithms
within the context of imperfect information game scenarios.",http://arxiv.org/pdf/2408.02380v1,2024-08-05,2408.02380v1,Perfect Information Monte Carlo with Postponing Reasoning,gpt-4,highly irrelevant,"The paper is about search algorithms in imperfect information games and does not mention hard prefix prompting, prompt engineering or any related concepts.",,
On the consistent reasoning paradox of intelligence and optimal trust in AI: The power of 'I don't know',"['Alexander Bastounis', 'Paolo Campodonico', 'Mihaela van der Schaar', 'Ben Adcock', 'Anders C. Hansen']","We introduce the Consistent Reasoning Paradox (CRP). Consistent reasoning,
which lies at the core of human intelligence, is the ability to handle tasks
that are equivalent, yet described by different sentences ('Tell me the time!'
and 'What is the time?'). The CRP asserts that consistent reasoning implies
fallibility -- in particular, human-like intelligence in AI necessarily comes
with human-like fallibility. Specifically, it states that there are problems,
e.g. in basic arithmetic, where any AI that always answers and strives to mimic
human intelligence by reasoning consistently will hallucinate (produce wrong,
yet plausible answers) infinitely often. The paradox is that there exists a
non-consistently reasoning AI (which therefore cannot be on the level of human
intelligence) that will be correct on the same set of problems. The CRP also
shows that detecting these hallucinations, even in a probabilistic sense, is
strictly harder than solving the original problems, and that there are problems
that an AI may answer correctly, but it cannot provide a correct logical
explanation for how it arrived at the answer. Therefore, the CRP implies that
any trustworthy AI (i.e., an AI that never answers incorrectly) that also
reasons consistently must be able to say 'I don't know'. Moreover, this can
only be done by implicitly computing a new concept that we introduce, termed
the 'I don't know' function -- something currently lacking in modern AI. In
view of these insights, the CRP also provides a glimpse into the behaviour of
Artificial General Intelligence (AGI). An AGI cannot be 'almost sure', nor can
it always explain itself, and therefore to be trustworthy it must be able to
say 'I don't know'.",http://arxiv.org/pdf/2408.02357v1,2024-08-05,2408.02357v1,On the consistent reasoning paradox of intelligence and optimal trust in AI: The power of 'I don't know',gpt-4,highly irrelevant,"The paper does not mention or imply the use of hard prefix prompting, or prompt engineering instead it discusses the concept of consistent reasoning in AI.",,
Active Sensing of Knee Osteoarthritis Progression with Reinforcement Learning,"['Khanh Nguyen', 'Huy Hoang Nguyen', 'Egor Panfilov', 'Aleksei Tiulpin']","Osteoarthritis (OA) is the most common musculoskeletal disease, which has no
cure. Knee OA (KOA) is one of the highest causes of disability worldwide, and
it costs billions of United States dollars to the global community. Prediction
of KOA progression has been of high interest to the community for years, as it
can advance treatment development through more efficient clinical trials and
improve patient outcomes through more efficient healthcare utilization.
Existing approaches for predicting KOA, however, are predominantly static, i.e.
consider data from a single time point to predict progression many years into
the future, and knee level, i.e. consider progression in a single joint only.
Due to these and related reasons, these methods fail to deliver the level of
predictive performance, which is sufficient to result in cost savings and
better patient outcomes. Collecting extensive data from all patients on a
regular basis could address the issue, but it is limited by the high cost at a
population level. In this work, we propose to go beyond static prediction
models in OA, and bring a novel Active Sensing (AS) approach, designed to
dynamically follow up patients with the objective of maximizing the number of
informative data acquisitions, while minimizing their total cost over a period
of time. Our approach is based on Reinforcement Learning (RL), and it leverages
a novel reward function designed specifically for AS of disease progression in
more than one part of a human body. Our method is end-to-end, relies on
multi-modal Deep Learning, and requires no human input at inference time.
Throughout an exhaustive experimental evaluation, we show that using RL can
provide a higher monetary benefit when compared to state-of-the-art baselines.",http://arxiv.org/pdf/2408.02349v1,2024-08-05,2408.02349v1,Active Sensing of Knee Osteoarthritis Progression with Reinforcement Learning,gpt-4,highly irrelevant,The paper focuses on disease prediction using Reinforcement Learning and does not discuss prompt engineering or any related topics.,,
An approach to optimize inference of the DIART speaker diarization pipeline,"['Roman Aperdannier', 'Sigurd Schacht', 'Alexander Piazza']","Speaker diarization answers the question ""who spoke when"" for an audio file.
In some diarization scenarios, low latency is required for transcription.
Speaker diarization with low latency is referred to as online speaker
diarization. The DIART pipeline is an online speaker diarization system. It
consists of a segmentation and an embedding model. The embedding model has the
largest share of the overall latency. The aim of this paper is to optimize the
inference latency of the DIART pipeline. Different inference optimization
methods such as knowledge distilation, pruning, quantization and layer fusion
are applied to the embedding model of the pipeline. It turns out that knowledge
distillation optimizes the latency, but has a negative effect on the accuracy.
Quantization and layer fusion also have a positive influence on the latency
without worsening the accuracy. Pruning, on the other hand, does not improve
latency.",http://arxiv.org/pdf/2408.02341v1,2024-08-05,2408.02341v1,An approach to optimize inference of the DIART speaker diarization pipeline,gpt-4,highly irrelevant,"The paper focuses on speaker diarization and optimizing inference latency, which is unrelated to the topic of hard prefix prompting or prompt engineering.",,
"Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction","['Albert Sawczyn', 'Katsiaryna Viarenich', 'Konrad Wojtasik', 'Aleksandra Domogała', 'Marcin Oleksy', 'Maciej Piasecki', 'Tomasz Kajdanowicz']","Advancements in AI and natural language processing have revolutionized
machine-human language interactions, with question answering (QA) systems
playing a pivotal role. The knowledge base question answering (KBQA) task,
utilizing structured knowledge graphs (KG), allows for handling extensive
knowledge-intensive questions. However, a significant gap exists in KBQA
datasets, especially for low-resource languages. Many existing construction
pipelines for these datasets are outdated and inefficient in human labor, and
modern assisting tools like Large Language Models (LLM) are not utilized to
reduce the workload. To address this, we have designed and implemented a
modern, semi-automated approach for creating datasets, encompassing tasks such
as KBQA, Machine Reading Comprehension (MRC), and Information Retrieval (IR),
tailored explicitly for low-resource environments. We executed this pipeline
and introduced the PUGG dataset, the first Polish KBQA dataset, and novel
datasets for MRC and IR. Additionally, we provide a comprehensive
implementation, insightful findings, detailed statistics, and evaluation of
baseline models.",http://arxiv.org/pdf/2408.02337v1,2024-08-05,2408.02337v1,"Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction",gpt-4,highly irrelevant,"The abstract primarily discusses constructing datasets for tasks like KBQA, MRC, and IR, with no mention of prompt engineering or hard-prefix prompting techniques.",,
SNFinLLM: Systematic and Nuanced Financial Domain Adaptation of Chinese Large Language Models,"['Shujuan Zhao', 'Lingfeng Qiao', 'Kangyang Luo', 'Qian-Wen Zhang', 'Junru Lu', 'Di Yin']","Large language models (LLMs) have become powerful tools for advancing natural
language processing applications in the financial industry. However, existing
financial LLMs often face challenges such as hallucinations or superficial
parameter training, resulting in suboptimal performance, particularly in
financial computing and machine reading comprehension (MRC). To address these
issues, we propose a novel large language model specifically designed for the
Chinese financial domain, named SNFinLLM. SNFinLLM excels in domain-specific
tasks such as answering questions, summarizing financial research reports,
analyzing sentiment, and executing financial calculations. We then perform the
supervised fine-tuning (SFT) to enhance the model's proficiency across various
financial domains. Specifically, we gather extensive financial data and create
a high-quality instruction dataset composed of news articles, professional
papers, and research reports of finance domain. Utilizing both domain-specific
and general datasets, we proceed with continuous pre-training on an established
open-source base model, resulting in SNFinLLM-base. Following this, we engage
in supervised fine-tuning (SFT) to bolster the model's capability across
multiple financial tasks. Crucially, we employ a straightforward Direct
Preference Optimization (DPO) method to better align the model with human
preferences. Extensive experiments conducted on finance benchmarks and our
evaluation dataset demonstrate that SNFinLLM markedly outperforms other
state-of-the-art financial language models. For more details, check out our
demo video here: https://www.youtube.com/watch?v=GYT-65HZwus.",http://arxiv.org/pdf/2408.02302v1,2024-08-05,2408.02302v1,SNFinLLM: Systematic and Nuanced Financial Domain Adaptation of Chinese Large Language Models,gpt-4,highly irrelevant,"The paper focuses on adapting large language models to the financial industry, and specifically on training and fine-tuning these models; it does not mention prompts or prompt engineering at all.",,
Generalized Gaussian Temporal Difference Error For Uncertainty-aware Reinforcement Learning,"['Seyeon Kim', 'Joonhun Lee', 'Namhoon Cho', 'Sungjun Han', 'Seungeon Baek']","Conventional uncertainty-aware temporal difference (TD) learning methods
often rely on simplistic assumptions, typically including a zero-mean Gaussian
distribution for TD errors. Such oversimplification can lead to inaccurate
error representations and compromised uncertainty estimation. In this paper, we
introduce a novel framework for generalized Gaussian error modeling in deep
reinforcement learning, applicable to both discrete and continuous control
settings. Our framework enhances the flexibility of error distribution modeling
by incorporating higher-order moments, particularly kurtosis, thereby improving
the estimation and mitigation of data-dependent noise, i.e., aleatoric
uncertainty. We examine the influence of the shape parameter of the generalized
Gaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form
expression that demonstrates an inverse relationship between uncertainty and
the shape parameter. Additionally, we propose a theoretically grounded
weighting scheme to fully leverage the GGD. To address epistemic uncertainty,
we enhance the batch inverse variance weighting by incorporating bias reduction
and kurtosis considerations, resulting in improved robustness. Extensive
experimental evaluations using policy gradient algorithms demonstrate the
consistent efficacy of our method, showcasing significant performance
improvements.",http://arxiv.org/pdf/2408.02295v1,2024-08-05,2408.02295v1,Generalized Gaussian Temporal Difference Error For Uncertainty-aware Reinforcement Learning,gpt-4,highly irrelevant,"The paper focuses on uncertainty-aware temporal difference learning methods in deep reinforcement learning, which is unrelated to prompt engineering or hard prefix prompting techniques.",,
Decoupled Vocabulary Learning Enables Zero-Shot Translation from Unseen Languages,"['Carlos Mullov', 'Ngoc-Quan Pham', 'Alexander Waibel']","Multilingual neural machine translation systems learn to map sentences of
different languages into a common representation space. Intuitively, with a
growing number of seen languages the encoder sentence representation grows more
flexible and easily adaptable to new languages. In this work, we test this
hypothesis by zero-shot translating from unseen languages. To deal with unknown
vocabularies from unknown languages we propose a setup where we decouple
learning of vocabulary and syntax, i.e. for each language we learn word
representations in a separate step (using cross-lingual word embeddings), and
then train to translate while keeping those word representations frozen. We
demonstrate that this setup enables zero-shot translation from entirely unseen
languages. Zero-shot translating with a model trained on Germanic and Romance
languages we achieve scores of 42.6 BLEU for Portuguese-English and 20.7 BLEU
for Russian-English on TED domain. We explore how this zero-shot translation
capability develops with varying number of languages seen by the encoder.
Lastly, we explore the effectiveness of our decoupled learning strategy for
unsupervised machine translation. By exploiting our model's zero-shot
translation capability for iterative back-translation we attain near parity
with a supervised setting.",http://arxiv.org/pdf/2408.02290v1,2024-08-05,2408.02290v1,Decoupled Vocabulary Learning Enables Zero-Shot Translation from Unseen Languages,gpt-4,highly irrelevant,"The paper focuses on machine translation and learning of vocabulary and syntax, without any mention of prompts or prompt engineering.",,
Hardware Aware Ensemble Selection for Balancing Predictive Accuracy and Cost,"['Jannis Maier', 'Felix Möller', 'Lennart Purucker']","Automated Machine Learning (AutoML) significantly simplifies the deployment
of machine learning models by automating tasks from data preprocessing to model
selection to ensembling. AutoML systems for tabular data often employ post hoc
ensembling, where multiple models are combined to improve predictive accuracy.
This typically results in longer inference times, a major limitation in
practical deployments. Addressing this, we introduce a hardware-aware ensemble
selection approach that integrates inference time into post hoc ensembling. By
leveraging an existing framework for ensemble selection with quality diversity
optimization, our method evaluates ensemble candidates for their predictive
accuracy and hardware efficiency. This dual focus allows for a balanced
consideration of accuracy and operational efficiency. Thus, our approach
enables practitioners to choose from a Pareto front of accurate and efficient
ensembles. Our evaluation using 83 classification datasets shows that our
approach sustains competitive accuracy and can significantly improve ensembles'
operational efficiency. The results of this study provide a foundation for
extending these principles to additional hardware constraints, setting the
stage for the development of more resource-efficient AutoML systems.",http://arxiv.org/pdf/2408.02280v1,2024-08-05,2408.02280v1,Hardware Aware Ensemble Selection for Balancing Predictive Accuracy and Cost,gpt-4,highly irrelevant,"The paper focuses on Automated Machine Learning and ensemble methods to balance predictive accuracy and cost, but does not mention nor imply the use of hard prefix prompts or prompt engineering.",,
DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for Long Time-Series Forecasting,"['Ruixin Ding', 'Yuqi Chen', 'Yu-Ting Lan', 'Wei Zhang']","Long-term time series forecasting (LTSF) has been widely applied in finance,
traffic prediction, and other domains. Recently, patch-based transformers have
emerged as a promising approach, segmenting data into sub-level patches that
serve as input tokens. However, existing methods mostly rely on predetermined
patch lengths, necessitating expert knowledge and posing challenges in
capturing diverse characteristics across various scales. Moreover, time series
data exhibit diverse variations and fluctuations across different temporal
scales, which traditional approaches struggle to model effectively. In this
paper, we propose a dynamic tokenizer with a dynamic sparse learning algorithm
to capture diverse receptive fields and sparse patterns of time series data. In
order to build hierarchical receptive fields, we develop a multi-scale
Transformer model, coupled with multi-scale sequence extraction, capable of
capturing multi-resolution features. Additionally, we introduce a group-aware
rotary position encoding technique to enhance intra- and inter-group position
awareness among representations across different temporal scales. Our proposed
model, named DRFormer, is evaluated on various real-world datasets, and
experimental results demonstrate its superiority compared to existing methods.
Our code is available at: https://github.com/ruixindingECNU/DRFormer.",http://arxiv.org/pdf/2408.02279v1,2024-08-05,2408.02279v1,DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for Long Time-Series Forecasting,gpt-4,highly irrelevant,"The paper is focused on long-term time series forecasting using a dynamic tokenizer and a multi-scale Transformer model, not on hard prefix prompting or prompt engineering.",,
"Geometric Algebra Meets Large Language Models: Instruction-Based Transformations of Separate Meshes in 3D, Interactive and Controllable Scenes","['Dimitris Angelis', 'Prodromos Kolyvakis', 'Manos Kamarianakis', 'George Papagiannakis']","This paper introduces a novel integration of Large Language Models (LLMs)
with Conformal Geometric Algebra (CGA) to revolutionize controllable 3D scene
editing, particularly for object repositioning tasks, which traditionally
requires intricate manual processes and specialized expertise. These
conventional methods typically suffer from reliance on large training datasets
or lack a formalized language for precise edits. Utilizing CGA as a robust
formal language, our system, shenlong, precisely models spatial transformations
necessary for accurate object repositioning. Leveraging the zero-shot learning
capabilities of pre-trained LLMs, shenlong translates natural language
instructions into CGA operations which are then applied to the scene,
facilitating exact spatial transformations within 3D scenes without the need
for specialized pre-training. Implemented in a realistic simulation
environment, shenlong ensures compatibility with existing graphics pipelines.
To accurately assess the impact of CGA, we benchmark against robust Euclidean
Space baselines, evaluating both latency and accuracy. Comparative performance
evaluations indicate that shenlong significantly reduces LLM response times by
16% and boosts success rates by 9.6% on average compared to the traditional
methods. Notably, shenlong achieves a 100% perfect success rate in common
practical queries, a benchmark where other systems fall short. These
advancements underscore shenlong's potential to democratize 3D scene editing,
enhancing accessibility and fostering innovation across sectors such as
education, digital entertainment, and virtual reality.",http://arxiv.org/pdf/2408.02275v1,2024-08-05,2408.02275v1,"Geometric Algebra Meets Large Language Models: Instruction-Based Transformations of Separate Meshes in 3D, Interactive and Controllable Scenes",gpt-4,highly irrelevant,"The paper focuses on 3D scene editing and largely involves translating natural language instructions into CGA operations using large language models, but does not address or discuss hard prefix prompting or the techniques of prompt engineering.",,
COM Kitchens: An Unedited Overhead-view Video Dataset as a Vision-Language Benchmark,"['Koki Maeda', 'Tosho Hirasawa', 'Atsushi Hashimoto', 'Jun Harashima', 'Leszek Rybicki', 'Yusuke Fukasawa', 'Yoshitaka Ushiku']","Procedural video understanding is gaining attention in the vision and
language community. Deep learning-based video analysis requires extensive data.
Consequently, existing works often use web videos as training resources, making
it challenging to query instructional contents from raw video observations. To
address this issue, we propose a new dataset, COM Kitchens. The dataset
consists of unedited overhead-view videos captured by smartphones, in which
participants performed food preparation based on given recipes. Fixed-viewpoint
video datasets often lack environmental diversity due to high camera setup
costs. We used modern wide-angle smartphone lenses to cover cooking counters
from sink to cooktop in an overhead view, capturing activity without in-person
assistance. With this setup, we collected a diverse dataset by distributing
smartphones to participants. With this dataset, we propose the novel
video-to-text retrieval task Online Recipe Retrieval (OnRR) and new video
captioning domain Dense Video Captioning on unedited Overhead-View videos
(DVC-OV). Our experiments verified the capabilities and limitations of current
web-video-based SOTA methods in handling these tasks.",http://arxiv.org/pdf/2408.02272v1,2024-08-05,2408.02272v1,COM Kitchens: An Unedited Overhead-view Video Dataset as a Vision-Language Benchmark,gpt-4,highly irrelevant,"The paper is focused on video processing, dataset creation, and video-to-text retrieval tasks, not on prompt engineering or hard prefix prompting.",,
To Aggregate or Not to Aggregate. That is the Question: A Case Study on Annotation Subjectivity in Span Prediction,"['Kemal Kurniawan', 'Meladel Mistica', 'Timothy Baldwin', 'Jey Han Lau']","This paper explores the task of automatic prediction of text spans in a legal
problem description that support a legal area label. We use a corpus of problem
descriptions written by laypeople in English that is annotated by practising
lawyers. Inherent subjectivity exists in our task because legal area
categorisation is a complex task, and lawyers often have different views on a
problem, especially in the face of legally-imprecise descriptions of issues.
Experiments show that training on majority-voted spans outperforms training on
disaggregated ones.",http://arxiv.org/pdf/2408.02257v1,2024-08-05,2408.02257v1,To Aggregate or Not to Aggregate. That is the Question: A Case Study on Annotation Subjectivity in Span Prediction,gpt-4,highly irrelevant,This paper focuses on the task of automatic prediction of text spans in a legal problem description without any mention of prompt engineering or hard prefix prompting.,,
