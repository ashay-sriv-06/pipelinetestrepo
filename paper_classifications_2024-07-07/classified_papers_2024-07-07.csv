title,authors,abstract,pdf_url,published,Title,Model,Rating,Reasoning
Accelerated Proton Resonance Frequency-based Magnetic Resonance Thermometry by Optimized Deep Learning Method,"['Sijie Xu', 'Shenyan Zong', 'Chang-Sheng Mei', 'Guofeng Shen', 'Yueran Zhao', 'He Wang']","Proton resonance frequency (PRF) based MR thermometry is essential for
focused ultrasound (FUS) thermal ablation therapies. This work aims to enhance
temporal resolution in dynamic MR temperature map reconstruction using an
improved deep learning method. The training-optimized methods and five
classical neural networks were applied on the 2-fold and 4-fold under-sampling
k-space data to reconstruct the temperature maps. The enhanced training modules
included offline/online data augmentations, knowledge distillation, and the
amplitude-phase decoupling loss function. The heating experiments were
performed by a FUS transducer on phantom and ex vivo tissues, respectively.
These data were manually under-sampled to imitate acceleration procedures and
trained in our method to get the reconstruction model. The additional dozen or
so testing datasets were separately obtained for evaluating the real-time
performance and temperature accuracy. Acceleration factors of 1.9 and 3.7 were
found for 2 times and 4 times k-space under-sampling strategies and the
ResUNet-based deep learning reconstruction performed exceptionally well. In
2-fold acceleration scenario, the RMSE of temperature map patches provided the
values of 0.888 degree centigrade and 1.145 degree centigrade on phantom and ex
vivo testing datasets. The DICE value of temperature areas enclosed by 43
degree centigrade isotherm was 0.809, and the Bland-Altman analysis showed a
bias of -0.253 degree centigrade with the apart of plus or minus 2.16 degree
centigrade. In 4 times under-sampling case, these evaluating values decreased
by approximately 10%. This study demonstrates that deep learning-based
reconstruction can significantly enhance the accuracy and efficiency of MR
thermometry for clinical FUS thermal therapies.",http://arxiv.org/pdf/2407.03308v1,2024-07-03,Accelerated Proton Resonance Frequency-based Magnetic Resonance Thermometry by Optimized Deep Learning Method,gpt-3.5-turbo,highly relevant,"This paper focuses on enhancing the temporal resolution in dynamic MR temperature map reconstruction using deep learning methods, which is a key aspect of prompt engineering."
LLM Internal States Reveal Hallucination Risk Faced With a Query,"['Ziwei Ji', 'Delong Chen', 'Etsuko Ishii', 'Samuel Cahyawijaya', 'Yejin Bang', 'Bryan Wilie', 'Pascale Fung']","The hallucination problem of Large Language Models (LLMs) significantly
limits their reliability and trustworthiness. Humans have a self-awareness
process that allows us to recognize what we don't know when faced with queries.
Inspired by this, our paper investigates whether LLMs can estimate their own
hallucination risk before response generation. We analyze the internal
mechanisms of LLMs broadly both in terms of training data sources and across 15
diverse Natural Language Generation (NLG) tasks, spanning over 700 datasets.
Our empirical analysis reveals two key insights: (1) LLM internal states
indicate whether they have seen the query in training data or not; and (2) LLM
internal states show they are likely to hallucinate or not regarding the query.
Our study explores particular neurons, activation layers, and tokens that play
a crucial role in the LLM perception of uncertainty and hallucination risk. By
a probing estimator, we leverage LLM self-assessment, achieving an average
hallucination estimation accuracy of 84.32\% at run time.",http://arxiv.org/pdf/2407.03282v1,2024-07-03,LLM Internal States Reveal Hallucination Risk Faced With a Query,gpt-3.5-turbo,highly relevant,"The paper explores how LLMs can estimate their own hallucination risk before response generation by analyzing their internal states, which is relevant to understanding prompt engineering."
Self-Evaluation as a Defense Against Adversarial Attacks on LLMs,"['Hannah Brown', 'Leon Lin', 'Kenji Kawaguchi', 'Michael Shieh']","When LLMs are deployed in sensitive, human-facing settings, it is crucial
that they do not output unsafe, biased, or privacy-violating outputs. For this
reason, models are both trained and instructed to refuse to answer unsafe
prompts such as ""Tell me how to build a bomb."" We find that, despite these
safeguards, it is possible to break model defenses simply by appending a space
to the end of a model's input. In a study of eight open-source models, we
demonstrate that this acts as a strong enough attack to cause the majority of
models to generate harmful outputs with very high success rates. We examine the
causes of this behavior, finding that the contexts in which single spaces occur
in tokenized training data encourage models to generate lists when prompted,
overriding training signals to refuse to answer unsafe requests. Our findings
underscore the fragile state of current model alignment and promote the
importance of developing more robust alignment methods. Code and data will be
made available at https://github.com/Linlt-leon/Adversarial-Alignments.",http://arxiv.org/pdf/2407.03234v1,2024-07-03,Self-Evaluation as a Defense Against Adversarial Attacks on LLMs,gpt-3.5-turbo,highly relevant,"The paper discusses adversarial attacks on language models by manipulating model inputs, which is directly related to understanding and improving prompt engineering techniques."
Single Character Perturbations Break LLM Alignment,"['Leon Lin', 'Hannah Brown', 'Kenji Kawaguchi', 'Michael Shieh']","When LLMs are deployed in sensitive, human-facing settings, it is crucial
that they do not output unsafe, biased, or privacy-violating outputs. For this
reason, models are both trained and instructed to refuse to answer unsafe
prompts such as ""Tell me how to build a bomb."" We find that, despite these
safeguards, it is possible to break model defenses simply by appending a space
to the end of a model's input. In a study of eight open-source models, we
demonstrate that this acts as a strong enough attack to cause the majority of
models to generate harmful outputs with very high success rates. We examine the
causes of this behavior, finding that the contexts in which single spaces occur
in tokenized training data encourage models to generate lists when prompted,
overriding training signals to refuse to answer unsafe requests. Our findings
underscore the fragile state of current model alignment and promote the
importance of developing more robust alignment methods. Code and data will be
available at https://github.com/hannah-aught/space_attack.",http://arxiv.org/pdf/2407.03232v1,2024-07-03,Single Character Perturbations Break LLM Alignment,gpt-3.5-turbo,highly relevant,"The paper discusses potential vulnerabilities in language models when given prompts, highlighting the importance of prompt engineering to ensure safe and unbiased model outputs."
TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts,"['Ruida Wang', 'Jipeng Zhang', 'Yizhen Jia', 'Rui Pan', 'Shizhe Diao', 'Renjie Pi', 'Tong Zhang']","Proving mathematical theorems using computer-verifiable formal languages like
Lean significantly impacts mathematical reasoning. One approach to formal
theorem proving involves generating complete proofs using Large Language Models
(LLMs) based on Natural Language (NL) proofs. Similar methods have shown
promising results in code generation. However, most modern LLMs exhibit
suboptimal performance due to the scarcity of aligned NL and Formal Language
(FL) theorem-proving data. This scarcity results in a paucity of methodologies
for training LLMs and techniques to fully utilize their capabilities in
composing formal proofs. To address the challenges, this paper proposes
**TheoremLlama**, an end-to-end framework to train a general-purpose LLM to
become a Lean4 expert. This framework encompasses NL-FL aligned dataset
generation methods, training approaches for the LLM formal theorem prover, and
techniques for LLM Lean4 proof writing. Using the dataset generation method, we
provide *Open Bootstrapped Theorems* (OBT), an NL-FL aligned and bootstrapped
dataset. A key innovation in this framework is the NL-FL bootstrapping method,
where NL proofs are integrated into Lean4 code for training datasets,
leveraging the NL reasoning ability of LLMs for formal reasoning. The
**TheoremLlama** framework achieves cumulative accuracies of 36.48% and 33.61%
on MiniF2F-Valid and Test datasets respectively, surpassing the GPT-4 baseline
of 22.95% and 25.41%. We have also open-sourced our model checkpoints and
generated dataset, and will soon make all the code publicly available.",http://arxiv.org/pdf/2407.03203v1,2024-07-03,TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts,gpt-3.5-turbo,highly relevant,"The paper focuses on developing a framework to train a large language model to become a Lean4 expert, involving dataset generation methods, training approaches, and leveraging natural language reasoning for formal proofs, which aligns with the concept of prompt engineering."
Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages,"['Max Zuo', 'Francisco Piedrahita Velez', 'Xiaochen Li', 'Michael L. Littman', 'Stephen H. Bach']","Many recent works have explored using language models for planning problems.
One line of research focuses on translating natural language descriptions of
planning tasks into structured planning languages, such as the planning domain
definition language (PDDL). While this approach is promising, accurately
measuring the quality of generated PDDL code continues to pose significant
challenges. First, generated PDDL code is typically evaluated using planning
validators that check whether the problem can be solved with a planner. This
method is insufficient because a language model might generate valid PDDL code
that does not align with the natural language description of the task. Second,
existing evaluation sets often have natural language descriptions of the
planning task that closely resemble the ground truth PDDL, reducing the
challenge of the task. To bridge this gap, we introduce \benchmarkName, a
benchmark designed to evaluate language models' ability to generate PDDL code
from natural language descriptions of planning tasks. We begin by creating a
PDDL equivalence algorithm that rigorously evaluates the correctness of PDDL
code generated by language models by flexibly comparing it against a ground
truth PDDL. Then, we present a dataset of $132,037$ text-to-PDDL pairs across
13 different tasks, with varying levels of difficulty. Finally, we evaluate
several API-access and open-weight language models that reveal this task's
complexity. For example, $87.6\%$ of the PDDL problem descriptions generated by
GPT-4o are syntactically parseable, $82.2\%$ are valid, solve-able problems,
but only $35.1\%$ are semantically correct, highlighting the need for a more
rigorous benchmark for this problem.",http://arxiv.org/pdf/2407.03321v1,2024-07-03,Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages,gpt-3.5-turbo,somewhat relevant,"The paper explores utilizing language models to generate structured planning language code from natural language descriptions, which falls under the broader umbrella of prompt engineering."
BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations,"['Zhantao Yang', 'Ruili Feng', 'Keyu Yan', 'Huangji Wang', 'Zhicai Wang', 'Shangwen Zhu', 'Han Zhang', 'Jie Xiao', 'Pingyu Wu', 'Kai Zhu', 'Jixuan Chen', 'Chen-Wei Xie', 'Chaojie Mao', 'Yue Yang', 'Hongyang Zhang', 'Yu Liu', 'Fan Cheng']","This paper presents Bag-of-Concept Graph (BACON) to gift models with limited
linguistic abilities to taste the privilege of Vision Language Models (VLMs)
and boost downstream tasks such as detection, visual question answering (VQA),
and image generation. Since the visual scenes in physical worlds are structured
with complex relations between objects, BACON breaks down annotations into
basic minimum elements and presents them in a graph structure. Element-wise
style enables easy understanding, and structural composition liberates
difficult locating. Careful prompt design births the BACON captions with the
help of public-available VLMs and segmentation methods. In this way, we gather
a dataset with 100K annotated images, which endow VLMs with remarkable
capabilities, such as accurately generating BACON, transforming prompts into
BACON format, envisioning scenarios in the style of BACONr, and dynamically
modifying elements within BACON through interactive dialogue and more. Wide
representative experiments, including detection, VQA, and image generation
tasks, tell BACON as a lifeline to achieve previous out-of-reach tasks or excel
in their current cutting-edge solutions.",http://arxiv.org/pdf/2407.03314v1,2024-07-03,BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations,gpt-3.5-turbo,somewhat relevant,"The paper discusses the careful prompt design used to generate BACON captions, which is relevant to prompt engineering."
A Review of the Applications of Deep Learning-Based Emergent Communication,"['Brendon Boldt', 'David Mortensen']","Emergent communication, or emergent language, is the field of research which
studies how human language-like communication systems emerge de novo in deep
multi-agent reinforcement learning environments. The possibilities of
replicating the emergence of a complex behavior like language have strong
intuitive appeal, yet it is necessary to complement this with clear notions of
how such research can be applicable to other fields of science, technology, and
engineering. This paper comprehensively reviews the applications of emergent
communication research across machine learning, natural language processing,
linguistics, and cognitive science. Each application is illustrated with a
description of its scope, an explication of emergent communication's unique
role in addressing it, a summary of the extant literature working towards the
application, and brief recommendations for near-term research directions.",http://arxiv.org/pdf/2407.03302v1,2024-07-03,A Review of the Applications of Deep Learning-Based Emergent Communication,gpt-3.5-turbo,somewhat relevant,"The paper focuses on emergent communication and its applications across various fields, including machine learning and natural language processing, which are closely related to prompt engineering."
Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning,"['Zhili Shen', 'Pavlos Vougiouklis', 'Chenxin Diao', 'Kaustubh Vyas', 'Yuanyi Ji', 'Jeff Z. Pan']","We focus on Text-to-SQL semantic parsing from the perspective of Large
Language Models. Motivated by challenges related to the size of commercial
database schemata and the deployability of business intelligence solutions, we
propose an approach that dynamically retrieves input database information and
uses abstract syntax trees to select few-shot examples for in-context learning.
  Furthermore, we investigate the extent to which an in-parallel semantic
parser can be leveraged for generating $\textit{approximated}$ versions of the
expected SQL queries, to support our retrieval. We take this approach to the
extreme--we adapt a model consisting of less than $500$M parameters, to act as
an extremely efficient approximator, enhancing it with the ability to process
schemata in a parallelised manner. We apply our approach to monolingual and
cross-lingual benchmarks for semantic parsing, showing improvements over
state-of-the-art baselines. Comprehensive experiments highlight the
contribution of modules involved in this retrieval-augmented generation
setting, revealing interesting directions for future work.",http://arxiv.org/pdf/2407.03227v1,2024-07-03,Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning,gpt-3.5-turbo,somewhat relevant,"The paper focuses on using abstract syntax trees to select few-shot examples for in-context learning and investigates leveraging a semantic parser for generating approximated versions of SQL queries, which aligns with the concept of prompt engineering."
Value-Penalized Auxiliary Control from Examples for Learning without Rewards or Demonstrations,"['Trevor Ablett', 'Bryan Chan', 'Jayce Haoran Wang', 'Jonathan Kelly']","Learning from examples of success is an appealing approach to reinforcement
learning that eliminates many of the disadvantages of using hand-crafted reward
functions or full expert-demonstration trajectories, both of which can be
difficult to acquire, biased, or suboptimal. However, learning from examples
alone dramatically increases the exploration challenge, especially for complex
tasks. This work introduces value-penalized auxiliary control from examples
(VPACE); we significantly improve exploration in example-based control by
adding scheduled auxiliary control and examples of auxiliary tasks.
Furthermore, we identify a value-calibration problem, where policy value
estimates can exceed their theoretical limits based on successful data. We
resolve this problem, which is exacerbated by learning auxiliary tasks, through
the addition of an above-success-level value penalty. Across three simulated
and one real robotic manipulation environment, and 21 different main tasks, we
show that our approach substantially improves learning efficiency. Videos,
code, and datasets are available at https://papers.starslab.ca/vpace.",http://arxiv.org/pdf/2407.03311v1,2024-07-03,Value-Penalized Auxiliary Control from Examples for Learning without Rewards or Demonstrations,gpt-3.5-turbo,somewhat irrelevant,"The paper does not mention anything related to prompt engineering or hard prefix prompting, focusing instead on reinforcement learning techniques without rewards or demonstrations."
STF: Sentence Transformer Fine-Tuning For Topic Categorization With Limited Data,"['Kheir Eddine Daouadi', 'Yaakoub Boualleg', 'Oussama Guehairia']","Nowadays, topic classification from tweets attracts considerable research
attention. Different classification systems have been suggested thanks to these
research efforts. Nevertheless, they face major challenges owing to low
performance metrics due to the limited amount of labeled data. We propose
Sentence Transformers Fine-tuning (STF), a topic detection system that
leverages pretrained Sentence Transformers models and fine-tuning to classify
topics from tweets accurately. Moreover, extensive parameter sensitivity
analyses were conducted to finetune STF parameters for our topic classification
task to achieve the best performance results. Experiments on two benchmark
datasets demonstrated that (1) the proposed STF can be effectively used for
classifying tweet topics and outperforms the latest state-of-the-art
approaches, and (2) the proposed STF does not require a huge amount of labeled
tweets to achieve good accuracy, which is a limitation of many state-of-the-art
approaches. Our main contribution is the achievement of promising results in
tweet topic classification by applying pretrained sentence transformers
language models.",http://arxiv.org/pdf/2407.03253v1,2024-07-03,STF: Sentence Transformer Fine-Tuning For Topic Categorization With Limited Data,gpt-3.5-turbo,somewhat irrelevant,"The paper focuses on using pretrained Sentence Transformers for fine-tuning to classify topics from tweets, which is not directly related to prompt engineering."
CATT: Character-based Arabic Tashkeel Transformer,"['Faris Alasmary', 'Orjuwan Zaafarani', 'Ahmad Ghannam']","Tashkeel, or Arabic Text Diacritization (ATD), greatly enhances the
comprehension of Arabic text by removing ambiguity and minimizing the risk of
misinterpretations caused by its absence. It plays a crucial role in improving
Arabic text processing, particularly in applications such as text-to-speech and
machine translation. This paper introduces a new approach to training ATD
models. First, we finetuned two transformers, encoder-only and encoder-decoder,
that were initialized from a pretrained character-based BERT. Then, we applied
the Noisy-Student approach to boost the performance of the best model. We
evaluated our models alongside 11 commercial and open-source models using two
manually labeled benchmark datasets: WikiNews and our CATT dataset. Our
findings show that our top model surpasses all evaluated models by relative
Diacritic Error Rates (DERs) of 30.83\% and 35.21\% on WikiNews and CATT,
respectively, achieving state-of-the-art in ATD. In addition, we show that our
model outperforms GPT-4-turbo on CATT dataset by a relative DER of 9.36\%. We
open-source our CATT models and benchmark dataset for the research
community\footnote{https://github.com/abjadai/catt}.",http://arxiv.org/pdf/2407.03236v1,2024-07-03,CATT: Character-based Arabic Tashkeel Transformer,gpt-3.5-turbo,somewhat irrelevant,The paper focuses on training ATD models based on transformer architectures and does not specifically mention hard prefix prompting or prompt engineering.
PPO-based Dynamic Control of Uncertain Floating Platforms in the Zero-G Environment,"['Mahya Ramezani', 'M. Amin Alandihallaj', 'Andreas M. Hein']","In the field of space exploration, floating platforms play a crucial role in
scientific investigations and technological advancements. However, controlling
these platforms in zero-gravity environments presents unique challenges,
including uncertainties and disturbances. This paper introduces an innovative
approach that combines Proximal Policy Optimization (PPO) with Model Predictive
Control (MPC) in the zero-gravity laboratory (Zero-G Lab) at the University of
Luxembourg. This approach leverages PPO's reinforcement learning power and
MPC's precision to navigate the complex control dynamics of floating platforms.
Unlike traditional control methods, this PPO-MPC approach learns from MPC
predictions, adapting to unmodeled dynamics and disturbances, resulting in a
resilient control framework tailored to the zero-gravity environment.
Simulations and experiments in the Zero-G Lab validate this approach,
showcasing the adaptability of the PPO agent. This research opens new
possibilities for controlling floating platforms in zero-gravity settings,
promising advancements in space exploration.",http://arxiv.org/pdf/2407.03224v1,2024-07-03,PPO-based Dynamic Control of Uncertain Floating Platforms in the Zero-G Environment,gpt-3.5-turbo,somewhat irrelevant,"The paper focuses on the use of Proximal Policy Optimization (PPO) with Model Predictive Control (MPC) in controlling floating platforms in zero-gravity environments, showcasing advanced control techniques but not specific to prompt engineering."
Learning Disentangled Representation in Object-Centric Models for Visual Dynamics Prediction via Transformers,"['Sanket Gandhi', 'Atul', 'Samanyu Mahajan', 'Vishal Sharma', 'Rushil Gupta', 'Arnab Kumar Mondal', 'Parag Singla']","Recent work has shown that object-centric representations can greatly help
improve the accuracy of learning dynamics while also bringing interpretability.
In this work, we take this idea one step further, ask the following question:
""can learning disentangled representation further improve the accuracy of
visual dynamics prediction in object-centric models?"" While there has been some
attempt to learn such disentangled representations for the case of static
images \citep{nsb}, to the best of our knowledge, ours is the first work which
tries to do this in a general setting for video, without making any specific
assumptions about the kind of attributes that an object might have. The key
building block of our architecture is the notion of a {\em block}, where
several blocks together constitute an object. Each block is represented as a
linear combination of a given number of learnable concept vectors, which is
iteratively refined during the learning process. The blocks in our model are
discovered in an unsupervised manner, by attending over object masks, in a
style similar to discovery of slots \citep{slot_attention}, for learning a
dense object-centric representation. We employ self-attention via transformers
over the discovered blocks to predict the next state resulting in discovery of
visual dynamics. We perform a series of experiments on several benchmark 2-D,
and 3-D datasets demonstrating that our architecture (1) can discover
semantically meaningful blocks (2) help improve accuracy of dynamics prediction
compared to SOTA object-centric models (3) perform significantly better in OOD
setting where the specific attribute combinations are not seen earlier during
training. Our experiments highlight the importance discovery of disentangled
representation for visual dynamics prediction.",http://arxiv.org/pdf/2407.03216v1,2024-07-03,Learning Disentangled Representation in Object-Centric Models for Visual Dynamics Prediction via Transformers,gpt-3.5-turbo,somewhat irrelevant,"The paper focuses on learning disentangled representations in object-centric models for visual dynamics prediction using transformers, which is not directly related to hard prefix prompts or prompt engineering."
How Does Quantization Affect Multilingual LLMs?,"['Kelly Marchisio', 'Saurabh Dash', 'Hongyu Chen', 'Dennis Aumiller', 'Ahmet Üstün', 'Sara Hooker', 'Sebastian Ruder']","Quantization techniques are widely used to improve inference speed and
deployment of large language models. While a wide body of work examines the
impact of quantized LLMs on English tasks, none have examined the effect of
quantization across languages. We conduct a thorough analysis of quantized
multilingual LLMs, focusing on their performance across languages and at
varying scales. We use automatic benchmarks, LLM-as-a-Judge methods, and human
evaluation, finding that (1) harmful effects of quantization are apparent in
human evaluation, and automatic metrics severely underestimate the detriment: a
1.7% average drop in Japanese across automatic tasks corresponds to a 16.0%
drop reported by human evaluators on realistic prompts; (2) languages are
disparately affected by quantization, with non-Latin script languages impacted
worst; and (3) challenging tasks such as mathematical reasoning degrade
fastest. As the ability to serve low-compute models is critical for wide global
adoption of NLP technologies, our results urge consideration of multilingual
performance as a key evaluation criterion for efficient models.",http://arxiv.org/pdf/2407.03211v1,2024-07-03,How Does Quantization Affect Multilingual LLMs?,gpt-3.5-turbo,somewhat irrelevant,"This paper focuses on the impact of quantization techniques on multilingual language models and their performance across languages, which does not directly relate to hard prefix prompting or prompt engineering."
Multiple-Resolution Tokenization for Time Series Forecasting with an Application to Pricing,"['Egon Peršak', 'Miguel F. Anjos', 'Sebastian Lautz', 'Aleksandar Kolev']","We propose a transformer architecture for time series forecasting with a
focus on time series tokenisation and apply it to a real-world prediction
problem from the pricing domain. Our architecture aims to learn effective
representations at many scales across all available data simultaneously. The
model contains a number of novel modules: a differentiated form of time series
patching which employs multiple resolutions, a multiple-resolution module for
time-varying known variables, a mixer-based module for capturing cross-series
information, and a novel output head with favourable scaling to account for the
increased number of tokens. We present an application of this model to a real
world prediction problem faced by the markdown team at a very large retailer.
On the experiments conducted our model outperforms in-house models and the
selected existing deep learning architectures.",http://arxiv.org/pdf/2407.03185v1,2024-07-03,Multiple-Resolution Tokenization for Time Series Forecasting with an Application to Pricing,gpt-3.5-turbo,somewhat irrelevant,"The abstract focuses on proposing a transformer architecture for time series forecasting with novel modules, but does not mention hard prefix prompting or prompt engineering specifically."
InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output,"['Pan Zhang', 'Xiaoyi Dong', 'Yuhang Zang', 'Yuhang Cao', 'Rui Qian', 'Lin Chen', 'Qipeng Guo', 'Haodong Duan', 'Bin Wang', 'Linke Ouyang', 'Songyang Zhang', 'Wenwei Zhang', 'Yining Li', 'Yang Gao', 'Peng Sun', 'Xinyue Zhang', 'Wei Li', 'Jingwen Li', 'Wenhai Wang', 'Hang Yan', 'Conghui He', 'Xingcheng Zhang', 'Kai Chen', 'Jifeng Dai', 'Yu Qiao', 'Dahua Lin', 'Jiaqi Wang']","We present InternLM-XComposer-2.5 (IXC-2.5), a versatile large-vision
language model that supports long-contextual input and output. IXC-2.5 excels
in various text-image comprehension and composition applications, achieving
GPT-4V level capabilities with merely 7B LLM backend. Trained with 24K
interleaved image-text contexts, it can seamlessly extend to 96K long contexts
via RoPE extrapolation. This long-context capability allows IXC-2.5 to excel in
tasks requiring extensive input and output contexts. Compared to its previous
2.0 version, InternLM-XComposer-2.5 features three major upgrades in
vision-language comprehension: (1) Ultra-High Resolution Understanding, (2)
Fine-Grained Video Understanding, and (3) Multi-Turn Multi-Image Dialogue. In
addition to comprehension, IXC-2.5 extends to two compelling applications using
extra LoRA parameters for text-image composition: (1) Crafting Webpages and (2)
Composing High-Quality Text-Image Articles. IXC-2.5 has been evaluated on 28
benchmarks, outperforming existing open-source state-of-the-art models on 16
benchmarks. It also surpasses or competes closely with GPT-4V and Gemini Pro on
16 key tasks. The InternLM-XComposer-2.5 is publicly available at
https://github.com/InternLM/InternLM-XComposer.",http://arxiv.org/pdf/2407.03320v1,2024-07-03,InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output,gpt-3.5-turbo,highly irrelevant,"The paper focuses on a language model specially designed for text-image comprehension and composition tasks, rather than on prompt engineering or hard prefix prompting."
DisCo-Diff: Enhancing Continuous Diffusion Models with Discrete Latents,"['Yilun Xu', 'Gabriele Corso', 'Tommi Jaakkola', 'Arash Vahdat', 'Karsten Kreis']","Diffusion models (DMs) have revolutionized generative learning. They utilize
a diffusion process to encode data into a simple Gaussian distribution.
However, encoding a complex, potentially multimodal data distribution into a
single continuous Gaussian distribution arguably represents an unnecessarily
challenging learning problem. We propose Discrete-Continuous Latent Variable
Diffusion Models (DisCo-Diff) to simplify this task by introducing
complementary discrete latent variables. We augment DMs with learnable discrete
latents, inferred with an encoder, and train DM and encoder end-to-end.
DisCo-Diff does not rely on pre-trained networks, making the framework
universally applicable. The discrete latents significantly simplify learning
the DM's complex noise-to-data mapping by reducing the curvature of the DM's
generative ODE. An additional autoregressive transformer models the
distribution of the discrete latents, a simple step because DisCo-Diff requires
only few discrete variables with small codebooks. We validate DisCo-Diff on toy
data, several image synthesis tasks as well as molecular docking, and find that
introducing discrete latents consistently improves model performance. For
example, DisCo-Diff achieves state-of-the-art FID scores on class-conditioned
ImageNet-64/128 datasets with ODE sampler.",http://arxiv.org/pdf/2407.03300v1,2024-07-03,DisCo-Diff: Enhancing Continuous Diffusion Models with Discrete Latents,gpt-3.5-turbo,highly irrelevant,"The paper focuses on enhancing diffusion models with discrete latent variables and does not mention prompt engineering or hard prefix prompts, making it unrelated to the topic."
Improved Noise Schedule for Diffusion Training,"['Tiankai Hang', 'Shuyang Gu']","Diffusion models have emerged as the de facto choice for generating visual
signals. However, training a single model to predict noise across various
levels poses significant challenges, necessitating numerous iterations and
incurring significant computational costs. Various approaches, such as loss
weighting strategy design and architectural refinements, have been introduced
to expedite convergence. In this study, we propose a novel approach to design
the noise schedule for enhancing the training of diffusion models. Our key
insight is that the importance sampling of the logarithm of the Signal-to-Noise
ratio (logSNR), theoretically equivalent to a modified noise schedule, is
particularly beneficial for training efficiency when increasing the sample
frequency around $\log \text{SNR}=0$. We empirically demonstrate the
superiority of our noise schedule over the standard cosine schedule.
Furthermore, we highlight the advantages of our noise schedule design on the
ImageNet benchmark, showing that the designed schedule consistently benefits
different prediction targets.",http://arxiv.org/pdf/2407.03297v1,2024-07-03,Improved Noise Schedule for Diffusion Training,gpt-3.5-turbo,highly irrelevant,The paper focuses on improving the noise schedule for diffusion models and does not mention anything related to prompt engineering or hard prefix prompting.
VCHAR:Variance-Driven Complex Human Activity Recognition framework with Generative Representation,"['Yuan Sun', 'Navid Salami Pargoo', 'Taqiya Ehsan', 'Zhao Zhang Jorge Ortiz']","Complex human activity recognition (CHAR) remains a pivotal challenge within
ubiquitous computing, especially in the context of smart environments. Existing
studies typically require meticulous labeling of both atomic and complex
activities, a task that is labor-intensive and prone to errors due to the
scarcity and inaccuracies of available datasets. Most prior research has
focused on datasets that either precisely label atomic activities or, at
minimum, their sequence approaches that are often impractical in real world
settings.In response, we introduce VCHAR (Variance-Driven Complex Human
Activity Recognition), a novel framework that treats the outputs of atomic
activities as a distribution over specified intervals. Leveraging generative
methodologies, VCHAR elucidates the reasoning behind complex activity
classifications through video-based explanations, accessible to users without
prior machine learning expertise. Our evaluation across three publicly
available datasets demonstrates that VCHAR enhances the accuracy of complex
activity recognition without necessitating precise temporal or sequential
labeling of atomic activities. Furthermore, user studies confirm that VCHAR's
explanations are more intelligible compared to existing methods, facilitating a
broader understanding of complex activity recognition among non-experts.",http://arxiv.org/pdf/2407.03291v1,2024-07-03,VCHAR:Variance-Driven Complex Human Activity Recognition framework with Generative Representation,gpt-3.5-turbo,highly irrelevant,"The paper focuses on a novel framework for complex human activity recognition using generative methodologies, which is not directly related to hard prefix prompting or prompt engineering."
Evaluating Automatic Metrics with Incremental Machine Translation Systems,"['Guojun Wu', 'Shay B. Cohen', 'Rico Sennrich']","We introduce a dataset comprising commercial machine translations, gathered
weekly over six years across 12 translation directions. Since human A/B testing
is commonly used, we assume commercial systems improve over time, which enables
us to evaluate machine translation (MT) metrics based on their preference for
more recent translations. Our study confirms several previous findings in MT
metrics research and demonstrates the dataset's value as a testbed for metric
evaluation. We release our code at https://github.com/gjwubyron/Evo",http://arxiv.org/pdf/2407.03277v1,2024-07-03,Evaluating Automatic Metrics with Incremental Machine Translation Systems,gpt-3.5-turbo,highly irrelevant,"The paper focuses on evaluating machine translation systems and metrics, which is not directly related to prompt engineering."
Do Quantum Neural Networks have Simplicity Bias?,['Jessica Pointing'],"One hypothesis for the success of deep neural networks (DNNs) is that they
are highly expressive, which enables them to be applied to many problems, and
they have a strong inductive bias towards solutions that are simple, known as
simplicity bias, which allows them to generalise well on unseen data because
most real-world data is structured (i.e. simple). In this work, we explore the
inductive bias and expressivity of quantum neural networks (QNNs), which gives
us a way to compare their performance to those of DNNs. Our results show that
it is possible to have simplicity bias with certain QNNs, but we prove that
this type of QNN limits the expressivity of the QNN. We also show that it is
possible to have QNNs with high expressivity, but they either have no inductive
bias or a poor inductive bias and result in a worse generalisation performance
compared to DNNs. We demonstrate that an artificial (restricted) inductive bias
can be produced by intentionally restricting the expressivity of a QNN. Our
results suggest a bias-expressivity tradeoff. Our conclusion is that the QNNs
we studied can not generally offer an advantage over DNNs, because these QNNs
either have a poor inductive bias or poor expressivity compared to DNNs.",http://arxiv.org/pdf/2407.03266v1,2024-07-03,Do Quantum Neural Networks have Simplicity Bias?,gpt-3.5-turbo,highly irrelevant,"The paper focuses on comparing the inductive bias and expressivity of quantum neural networks (QNNs) and deep neural networks (DNNs), which is not directly related to prompt engineering."
How Similar Are Elected Politicians and Their Constituents? Quantitative Evidence From Online Social Network,"['Waleed Iqbal', 'Gareth Tyson', 'Ignacio Castro']","How similar are politicians to those who vote for them? This is a critical
question at the heart of democratic representation and particularly relevant at
times when political dissatisfaction and populism are on the rise. To answer
this question we compare the online discourse of elected politicians and their
constituents. We collect a two and a half years (September 2020 - February
2023) constituency-level dataset for USA and UK that includes: (i) the Twitter
timelines (5.6 Million tweets) of elected political representatives (595 UK
Members of Parliament and 433 USA Representatives), (ii) the Nextdoor posts
(21.8 Million posts) of the constituency (98.4% USA and 91.5% UK
constituencies). We find that elected politicians tend to be equally similar to
their constituents in terms of content and style regardless of whether a
constituency elects a right or left-wing politician. The size of the electoral
victory and the level of income of a constituency shows a nuanced picture. The
narrower the electoral victory, the more similar the style and the more
dissimilar the content is. The lower the income of a constituency, the more
similar the content is. In terms of style, poorer constituencies tend to have a
more similar sentiment and more dissimilar psychological text traits (i.e.
measured with LIWC categories).",http://arxiv.org/pdf/2407.03255v1,2024-07-03,How Similar Are Elected Politicians and Their Constituents? Quantitative Evidence From Online Social Network,gpt-3.5-turbo,highly irrelevant,"The paper focuses on analyzing the online discourse of elected politicians and their constituents, which does not involve prompt engineering or hard prefix prompts."
TieBot: Learning to Knot a Tie from Visual Demonstration through a Real-to-Sim-to-Real Approach,"['Weikun Peng', 'Jun Lv', 'Yuwei Zeng', 'Haonan Chen', 'Siheng Zhao', 'Jicheng Sun', 'Cewu Lu', 'Lin Shao']","The tie-knotting task is highly challenging due to the tie's high deformation
and long-horizon manipulation actions. This work presents TieBot, a
Real-to-Sim-to-Real learning from visual demonstration system for the robots to
learn to knot a tie. We introduce the Hierarchical Feature Matching approach to
estimate a sequence of tie's meshes from the demonstration video. With these
estimated meshes used as subgoals, we first learn a teacher policy using
privileged information. Then, we learn a student policy with point cloud
observation by imitating teacher policy. Lastly, our pipeline learns a residual
policy when the learned policy is applied to real-world execution, mitigating
the Sim2Real gap. We demonstrate the effectiveness of TieBot in simulation and
the real world. In the real-world experiment, a dual-arm robot successfully
knots a tie, achieving 50% success rate among 10 trials. Videos can be found on
our $\href{https://tiebots.github.io/}{\text{website}}$.",http://arxiv.org/pdf/2407.03245v1,2024-07-03,TieBot: Learning to Knot a Tie from Visual Demonstration through a Real-to-Sim-to-Real Approach,gpt-3.5-turbo,highly irrelevant,"The paper focuses on teaching a robot to perform a task through a learning from demonstration system, which does not directly relate to prompt engineering or hard prefix prompting."
Combining AI Control Systems and Human Decision Support via Robustness and Criticality,"['Walt Woods', 'Alexander Grushin', 'Simon Khan', 'Alvaro Velasquez']","AI-enabled capabilities are reaching the requisite level of maturity to be
deployed in the real world, yet do not always make correct or safe decisions.
One way of addressing these concerns is to leverage AI control systems
alongside and in support of human decisions, relying on the AI control system
in safe situations while calling on a human co-decider for critical situations.
We extend a methodology for adversarial explanations (AE) to state-of-the-art
reinforcement learning frameworks, including MuZero. Multiple improvements to
the base agent architecture are proposed. We demonstrate how this technology
has two applications: for intelligent decision tools and to enhance training /
learning frameworks. In a decision support context, adversarial explanations
help a user make the correct decision by highlighting those contextual factors
that would need to change for a different AI-recommended decision. As another
benefit of adversarial explanations, we show that the learned AI control system
demonstrates robustness against adversarial tampering. Additionally, we
supplement AE by introducing strategically similar autoencoders (SSAs) to help
users identify and understand all salient factors being considered by the AI
system. In a training / learning framework, this technology can improve both
the AI's decisions and explanations through human interaction. Finally, to
identify when AI decisions would most benefit from human oversight, we tie this
combined system to our prior art on statistically verified analyses of the
criticality of decisions at any point in time.",http://arxiv.org/pdf/2407.03210v1,2024-07-03,Combining AI Control Systems and Human Decision Support via Robustness and Criticality,gpt-3.5-turbo,highly irrelevant,"The paper focuses on combining AI control systems with human decision support and does not mention hard prefix prompts or prompt engineering, making it irrelevant to the topic."
CiteAssist: A System for Automated Preprint Citation and BibTeX Generation,"['Lars Benedikt Kaesberg', 'Terry Ruas', 'Jan Philip Wahle', 'Bela Gipp']","We present CiteAssist, a system to automate the generation of BibTeX entries
for preprints, streamlining the process of bibliographic annotation. Our system
extracts metadata, such as author names, titles, publication dates, and
keywords, to create standardized annotations within the document. CiteAssist
automatically attaches the BibTeX citation to the end of a PDF and links it on
the first page of the document so other researchers gain immediate access to
the correct citation of the article. This method promotes platform flexibility
by ensuring that annotations remain accessible regardless of the repository
used to publish or access the preprint. The annotations remain available even
if the preprint is viewed externally to CiteAssist. Additionally, the system
adds relevant related papers based on extracted keywords to the preprint,
providing researchers with additional publications besides those in related
work for further reading. Researchers can enhance their preprints organization
and reference management workflows through a free and publicly available web
interface.",http://arxiv.org/pdf/2407.03192v1,2024-07-03,CiteAssist: A System for Automated Preprint Citation and BibTeX Generation,gpt-3.5-turbo,highly irrelevant,"The paper focuses on automating the generation of BibTeX entries and enhancing reference management workflows, without mentioning any specific use or development of prompt engineering techniques."
MuDiT & MuSiT: Alignment with Colloquial Expression in Description-to-Song Generation,"['Zihao Wang', 'Haoxuan Liu', 'Jiaxing Yu', 'Tao Zhang', 'Yan Liu', 'Kejun Zhang']","Amid the rising intersection of generative AI and human artistic processes,
this study probes the critical yet less-explored terrain of alignment in
human-centric automatic song composition. We propose a novel task of Colloquial
Description-to-Song Generation, which focuses on aligning the generated content
with colloquial human expressions. This task is aimed at bridging the gap
between colloquial language understanding and auditory expression within an AI
model, with the ultimate goal of creating songs that accurately satisfy human
auditory expectations and structurally align with musical norms. Current
datasets are limited due to their narrow descriptive scope, semantic gaps and
inaccuracies. To overcome data scarcity in this domain, we present the Caichong
Music Dataset (CaiMD). CaiMD is manually annotated by both professional
musicians and amateurs, offering diverse perspectives and a comprehensive
understanding of colloquial descriptions. Unlike existing datasets pre-set with
expert annotations or auto-generated ones with inherent biases, CaiMD caters
more sufficiently to our purpose of aligning AI-generated music with widespread
user-desired results. Moreover, we propose an innovative single-stage framework
called MuDiT/MuSiT for enabling effective human-machine alignment in song
creation. This framework not only achieves cross-modal comprehension between
colloquial language and auditory music perceptions but also ensures generated
songs align with user-desired results. MuDiT/MuSiT employs one DiT/SiT model
for end-to-end generation of musical components like melody, harmony, rhythm,
vocals, and instrumentation. The approach ensures harmonious sonic cohesiveness
amongst all generated musical components, facilitating better resonance with
human auditory expectations.",http://arxiv.org/pdf/2407.03188v1,2024-07-03,MuDiT & MuSiT: Alignment with Colloquial Expression in Description-to-Song Generation,gpt-3.5-turbo,highly irrelevant,"The paper focuses on aligning AI-generated content with colloquial human expressions in the context of song generation, without mentioning any aspect related to prompt engineering or hard prefix prompts."
A Formal Model for Artificial Intelligence Applications in Automation Systems,"['Marvin Schieseck', 'Philip Topalis', 'Lasse Reinpold', 'Felix Gehlhoff', 'Alexander Fay']","The integration of Artificial Intelligence (AI) into automation systems has
the potential to enhance efficiency and to address currently unsolved existing
technical challenges. However, the industry-wide adoption of AI is hindered by
the lack of standardized documentation for the complex compositions of
automation systems, AI software, production hardware, and their
interdependencies. This paper proposes a formal model using standards and
ontologies to provide clear and structured documentation of AI applications in
automation systems. The proposed information model for artificial intelligence
in automation systems (AIAS) utilizes ontology design patterns to map and link
various aspects of automation systems and AI software. Validated through a
practical example, the model demonstrates its effectiveness in improving
documentation practices and aiding the sustainable implementation of AI in
industrial settings.",http://arxiv.org/pdf/2407.03183v1,2024-07-03,A Formal Model for Artificial Intelligence Applications in Automation Systems,gpt-3.5-turbo,highly irrelevant,"The paper focuses on the integration of AI into automation systems and proposes a formal model using standards and ontologies to document AI applications, which is not directly related to prompt engineering."
Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models,"['Haritz Puerto', 'Tilek Chubakov', 'Xiaodan Zhu', 'Harish Tayyar Madabushi', 'Iryna Gurevych']","Requiring a Large Language Model to generate intermediary reasoning steps has
been shown to be an effective way of boosting performance. In fact, it has been
found that instruction tuning on these intermediary reasoning steps improves
model performance. In this work, we present a novel method of further improving
performance by requiring models to compare multiple reasoning chains before
generating a solution in a single inference step. We call this method Divergent
CoT (DCoT). We find that instruction tuning on DCoT datasets boosts the
performance of even smaller, and therefore more accessible, LLMs. Through a
rigorous set of experiments spanning a wide range of tasks that require various
reasoning types, we show that fine-tuning on DCoT consistently improves
performance over the CoT baseline across model families and scales (1.3B to
70B). Through a combination of empirical and manual evaluation, we additionally
show that these performance gains stem from models generating multiple
divergent reasoning chains in a single inference step, indicative of the
enabling of self-correction in language models. Our code and data are publicly
available at https://github.com/UKPLab/arxiv2024-divergent-cot.",http://arxiv.org/pdf/2407.03181v1,2024-07-03,Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models,gpt-3.5-turbo,highly irrelevant,"The paper focuses on fine-tuning language models to include intermediary reasoning steps and comparing multiple reasoning chains, which are not directly related to hard prefix prompts or prompt engineering."
A multi-objective combinatorial optimisation framework for large scale hierarchical population synthesis,"['Imran Mahmood', 'Nicholas Bishop', 'Anisoara Calinescu', 'Michael Wooldridge', 'Ioannis Zachos']","In agent-based simulations, synthetic populations of agents are commonly used
to represent the structure, behaviour, and interactions of individuals.
However, generating a synthetic population that accurately reflects real
population statistics is a challenging task, particularly when performed at
scale. In this paper, we propose a multi objective combinatorial optimisation
technique for large scale population synthesis. We demonstrate the
effectiveness of our approach by generating a synthetic population for selected
regions and validating it on contingency tables from real population data. Our
approach supports complex hierarchical structures between individuals and
households, is scalable to large populations and achieves minimal contigency
table reconstruction error. Hence, it provides a useful tool for policymakers
and researchers for simulating the dynamics of complex populations.",http://arxiv.org/pdf/2407.03180v1,2024-07-03,A multi-objective combinatorial optimisation framework for large scale hierarchical population synthesis,gpt-3.5-turbo,highly irrelevant,"The paper focuses on a multi-objective combinatorial optimization technique for generating synthetic populations, which is not directly related to prompt engineering."
