title,authors,abstract,pdf_url,published,arxiv_id,Title,Model,Rating,Reasoning
CAD-Prompted Generative Models: A Pathway to Feasible and Novel Engineering Designs,"['Leah Chong', 'Jude Rayan', 'Steven Dow', 'Ioanna Lykourentzou', 'Faez Ahmed']","Text-to-image generative models have increasingly been used to assist
designers during concept generation in various creative domains, such as
graphic design, user interface design, and fashion design. However, their
applications in engineering design remain limited due to the models' challenges
in generating images of feasible designs concepts. To address this issue, this
paper introduces a method that improves the design feasibility by prompting the
generation with feasible CAD images. In this work, the usefulness of this
method is investigated through a case study with a bike design task using an
off-the-shelf text-to-image model, Stable Diffusion 2.1. A diverse set of bike
designs are produced in seven different generation settings with varying CAD
image prompting weights, and these designs are evaluated on their perceived
feasibility and novelty. Results demonstrate that the CAD image prompting
successfully helps text-to-image models like Stable Diffusion 2.1 create
visibly more feasible design images. While a general tradeoff is observed
between feasibility and novelty, when the prompting weight is kept low around
0.35, the design feasibility is significantly improved while its novelty
remains on par with those generated by text prompts alone. The insights from
this case study offer some guidelines for selecting the appropriate CAD image
prompting weight for different stages of the engineering design process. When
utilized effectively, our CAD image prompting method opens doors to a wider
range of applications of text-to-image models in engineering design.",http://arxiv.org/pdf/2407.08675v1,2024-07-11,2407.08675v1,CAD-Prompted Generative Models: A Pathway to Feasible and Novel Engineering Designs,gpt-4,somewhat relevant,"The paper discusses the use of prompting in generative models, however, it deals with CAD image prompting rather than hard prefix prompting, making it somewhat relevant but not directly in line with the specific topic."
Incorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility,"['Yuchen Xia', 'Jize Zhang', 'Nasser Jazdi', 'Michael Weyrich']","This paper introduces a novel approach to integrating large language model
(LLM) agents into automated production systems, aimed at enhancing task
automation and flexibility. We organize production operations within a
hierarchical framework based on the automation pyramid. Atomic operation
functionalities are modeled as microservices, which are executed through
interface invocation within a dedicated digital twin system. This allows for a
scalable and flexible foundation for orchestrating production processes. In
this digital twin system, low-level, hardware-specific data is semantically
enriched and made interpretable for LLMs for production planning and control
tasks. Large language model agents are systematically prompted to interpret
these production-specific data and knowledge. Upon receiving a user request or
identifying a triggering event, the LLM agents generate a process plan. This
plan is then decomposed into a series of atomic operations, executed as
microservices within the real-world automation system. We implement this
overall approach on an automated modular production facility at our laboratory,
demonstrating how the LLMs can handle production planning and control tasks
through a concrete case study. This results in an intuitive production facility
with higher levels of task automation and flexibility. Finally, we reveal the
several limitations in realizing the full potential of the large language
models in autonomous systems and point out promising benefits. Demos of this
series of ongoing research series can be accessed at:
https://github.com/YuchenXia/GPT4IndustrialAutomation",http://arxiv.org/pdf/2407.08550v1,2024-07-11,2407.08550v1,Incorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility,gpt-4,somewhat relevant,"The paper discusses the use of large language models in an automated production setting, and specifically mentions the systematic prompting of these models to interpret production-specific data and knowledge."
Video Diffusion Alignment via Reward Gradients,"['Mihir Prabhudesai', 'Russell Mendonca', 'Zheyang Qin', 'Katerina Fragkiadaki', 'Deepak Pathak']","We have made significant progress towards building foundational video
diffusion models. As these models are trained using large-scale unsupervised
data, it has become crucial to adapt these models to specific downstream tasks.
Adapting these models via supervised fine-tuning requires collecting target
datasets of videos, which is challenging and tedious. In this work, we utilize
pre-trained reward models that are learned via preferences on top of powerful
vision discriminative models to adapt video diffusion models. These models
contain dense gradient information with respect to generated RGB pixels, which
is critical to efficient learning in complex search spaces, such as videos. We
show that backpropagating gradients from these reward models to a video
diffusion model can allow for compute and sample efficient alignment of the
video diffusion model. We show results across a variety of reward models and
video diffusion models, demonstrating that our approach can learn much more
efficiently in terms of reward queries and computation than prior gradient-free
approaches. Our code, model weights,and more visualization are available at
https://vader-vid.github.io.",http://arxiv.org/pdf/2407.08737v1,2024-07-11,2407.08737v1,Video Diffusion Alignment via Reward Gradients,gpt-4,highly irrelevant,"The paper focuses on video diffusion models and reward models, with no mention of hard prefix prompting or any sort of prompt engineering."
Real-Time Anomaly Detection and Reactive Planning with Large Language Models,"['Rohan Sinha', 'Amine Elhafsi', 'Christopher Agia', 'Matthew Foutter', 'Edward Schmerling', 'Marco Pavone']","Foundation models, e.g., large language models (LLMs), trained on
internet-scale data possess zero-shot generalization capabilities that make
them a promising technology towards detecting and mitigating
out-of-distribution failure modes of robotic systems. Fully realizing this
promise, however, poses two challenges: (i) mitigating the considerable
computational expense of these models such that they may be applied online, and
(ii) incorporating their judgement regarding potential anomalies into a safe
control framework. In this work, we present a two-stage reasoning framework:
First is a fast binary anomaly classifier that analyzes observations in an LLM
embedding space, which may then trigger a slower fallback selection stage that
utilizes the reasoning capabilities of generative LLMs. These stages correspond
to branch points in a model predictive control strategy that maintains the
joint feasibility of continuing along various fallback plans to account for the
slow reasoner's latency as soon as an anomaly is detected, thus ensuring
safety. We show that our fast anomaly classifier outperforms autoregressive
reasoning with state-of-the-art GPT models, even when instantiated with
relatively small language models. This enables our runtime monitor to improve
the trustworthiness of dynamic robotic systems, such as quadrotors or
autonomous vehicles, under resource and time constraints. Videos illustrating
our approach in both simulation and real-world experiments are available on
this project page: https://sites.google.com/view/aesop-llm.",http://arxiv.org/pdf/2407.08735v1,2024-07-11,2407.08735v1,Real-Time Anomaly Detection and Reactive Planning with Large Language Models,gpt-4,highly irrelevant,"Although the paper discusses large language models and their application in anomaly detection for robotic systems, it does not mention or involve prompt engineering or hard prefix prompting techniques."
Transformer Circuit Faithfulness Metrics are not Robust,"['Joseph Miller', 'Bilal Chughtai', 'William Saunders']","Mechanistic interpretability work attempts to reverse engineer the learned
algorithms present inside neural networks. One focus of this work has been to
discover 'circuits' -- subgraphs of the full model that explain behaviour on
specific tasks. But how do we measure the performance of such circuits? Prior
work has attempted to measure circuit 'faithfulness' -- the degree to which the
circuit replicates the performance of the full model. In this work, we survey
many considerations for designing experiments that measure circuit faithfulness
by ablating portions of the model's computation. Concerningly, we find existing
methods are highly sensitive to seemingly insignificant changes in the ablation
methodology. We conclude that existing circuit faithfulness scores reflect both
the methodological choices of researchers as well as the actual components of
the circuit - the task a circuit is required to perform depends on the ablation
used to test it. The ultimate goal of mechanistic interpretability work is to
understand neural networks, so we emphasize the need for more clarity in the
precise claims being made about circuits. We open source a library at
https://github.com/UFO-101/auto-circuit that includes highly efficient
implementations of a wide range of ablation methodologies and circuit discovery
algorithms.",http://arxiv.org/pdf/2407.08734v1,2024-07-11,2407.08734v1,Transformer Circuit Faithfulness Metrics are not Robust,gpt-4,highly irrelevant,"This paper focuses on mechanistic interpretability of neural networks and the evaluation of such circuits, which does not relate to hard prefix prompting or prompt engineering."
Is Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist,"['Zihao Zhou', 'Shudong Liu', 'Maizhen Ning', 'Wei Liu', 'Jindong Wang', 'Derek F. Wong', 'Xiaowei Huang', 'Qiufeng Wang', 'Kaizhu Huang']","Exceptional mathematical reasoning ability is one of the key features that
demonstrate the power of large language models (LLMs). How to comprehensively
define and evaluate the mathematical abilities of LLMs, and even reflect the
user experience in real-world scenarios, has emerged as a critical issue.
Current benchmarks predominantly concentrate on problem-solving capabilities,
which presents a substantial risk of model overfitting and fails to accurately
represent genuine mathematical reasoning abilities. In this paper, we argue
that if a model really understands a problem, it should be robustly and readily
applied across a diverse array of tasks. Motivated by this, we introduce
MATHCHECK, a well-designed checklist for testing task generalization and
reasoning robustness, as well as an automatic tool to generate checklists
efficiently. MATHCHECK includes multiple mathematical reasoning tasks and
robustness test types to facilitate a comprehensive evaluation of both
mathematical reasoning ability and behavior testing. Utilizing MATHCHECK, we
develop MATHCHECK-GSM and MATHCHECK-GEO to assess mathematical textual
reasoning and multi-modal reasoning capabilities, respectively, serving as
upgraded versions of benchmarks including GSM8k, GeoQA, UniGeo, and Geometry3K.
We adopt MATHCHECK-GSM and MATHCHECK-GEO to evaluate over 20 LLMs and 11 MLLMs,
assessing their comprehensive mathematical reasoning abilities. Our results
demonstrate that while frontier LLMs like GPT-4o continue to excel in various
abilities on the checklist, many other model families exhibit a significant
decline. Further experiments indicate that, compared to traditional math
benchmarks, MATHCHECK better reflects true mathematical abilities and
represents mathematical intelligence more linearly, thereby supporting our
design. On our MATHCHECK, we can easily conduct detailed behavior analysis to
deeply investigate models.",http://arxiv.org/pdf/2407.08733v1,2024-07-11,2407.08733v1,Is Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist,gpt-4,highly irrelevant,"The paper focuses on evaluating mathematical reasoning of language models, and doesn't mention or imply any focus on 'hard prefix prompting' or 'prompt engineering'."
MetaUrban: A Simulation Platform for Embodied AI in Urban Spaces,"['Wayne Wu', 'Honglin He', 'Yiran Wang', 'Chenda Duan', 'Jack He', 'Zhizheng Liu', 'Quanyi Li', 'Bolei Zhou']","Public urban spaces like streetscapes and plazas serve residents and
accommodate social life in all its vibrant variations. Recent advances in
Robotics and Embodied AI make public urban spaces no longer exclusive to
humans. Food delivery bots and electric wheelchairs have started sharing
sidewalks with pedestrians, while diverse robot dogs and humanoids have
recently emerged in the street. Ensuring the generalizability and safety of
these forthcoming mobile machines is crucial when navigating through the
bustling streets in urban spaces. In this work, we present MetaUrban, a
compositional simulation platform for Embodied AI research in urban spaces.
MetaUrban can construct an infinite number of interactive urban scenes from
compositional elements, covering a vast array of ground plans, object
placements, pedestrians, vulnerable road users, and other mobile agents'
appearances and dynamics. We design point navigation and social navigation
tasks as the pilot study using MetaUrban for embodied AI research and establish
various baselines of Reinforcement Learning and Imitation Learning. Experiments
demonstrate that the compositional nature of the simulated environments can
substantially improve the generalizability and safety of the trained mobile
agents. MetaUrban will be made publicly available to provide more research
opportunities and foster safe and trustworthy embodied AI in urban spaces.",http://arxiv.org/pdf/2407.08725v1,2024-07-11,2407.08725v1,MetaUrban: A Simulation Platform for Embodied AI in Urban Spaces,gpt-4,highly irrelevant,"This paper centers on Embodied AI research in urban spaces and simulation environments, not on prompt engineering or hard prefix prompting."
WhisperNetV2: SlowFast Siamese Network For Lip-Based Biometrics,"['Abdollah Zakeri', 'Hamid Hassanpour', 'Mohammad Hossein Khosravi', 'Amir Masoud Nourollah']","Lip-based biometric authentication (LBBA) has attracted many researchers
during the last decade. The lip is specifically interesting for biometric
researchers because it is a twin biometric with the potential to function both
as a physiological and a behavioral trait. Although much valuable research was
conducted on LBBA, none of them considered the different emotions of the client
during the video acquisition step of LBBA, which can potentially affect the
client's facial expressions and speech tempo. We proposed a novel network
structure called WhisperNetV2, which extends our previously proposed network
called WhisperNet. Our proposed network leverages a deep Siamese structure with
triplet loss having three identical SlowFast networks as embedding networks.
The SlowFast network is an excellent candidate for our task since the fast
pathway extracts motion-related features (behavioral lip movements) with a high
frame rate and low channel capacity. The slow pathway extracts visual features
(physiological lip appearance) with a low frame rate and high channel capacity.
Using an open-set protocol, we trained our network using the CREMA-D dataset
and acquired an Equal Error Rate (EER) of 0.005 on the test set. Considering
that the acquired EER is less than most similar LBBA methods, our method can be
considered as a state-of-the-art LBBA method.",http://arxiv.org/pdf/2407.08717v1,2024-07-11,2407.08717v1,WhisperNetV2: SlowFast Siamese Network For Lip-Based Biometrics,gpt-4,highly irrelevant,"This paper focuses on lip-based biometric authentication and introduces a novel network structure for it, which is unrelated to the concept of hard prefix prompting or prompt engineering."
A Taxonomy for Data Contamination in Large Language Models,"['Medha Palavalli', 'Amanda Bertsch', 'Matthew R. Gormley']","Large language models pretrained on extensive web corpora demonstrate
remarkable performance across a wide range of downstream tasks. However, a
growing concern is data contamination, where evaluation datasets may be
contained in the pretraining corpus, inflating model performance.
Decontamination, the process of detecting and removing such data, is a
potential solution; yet these contaminants may originate from altered versions
of the test set, evading detection during decontamination. How different types
of contamination impact the performance of language models on downstream tasks
is not fully understood. We present a taxonomy that categorizes the various
types of contamination encountered by LLMs during the pretraining phase and
identify which types pose the highest risk. We analyze the impact of
contamination on two key NLP tasks -- summarization and question answering --
revealing how different types of contamination influence task performance
during evaluation.",http://arxiv.org/pdf/2407.08716v1,2024-07-11,2407.08716v1,A Taxonomy for Data Contamination in Large Language Models,gpt-4,highly irrelevant,"The paper deals with data contamination in large language models, but doesn't touch on the topic of hard prefix prompt engineering or any kind of prompting technique."
GTA: A Benchmark for General Tool Agents,"['Jize Wang', 'Zerun Ma', 'Yining Li', 'Songyang Zhang', 'Cailian Chen', 'Kai Chen', 'Xinyi Le']","Significant focus has been placed on integrating large language models (LLMs)
with various tools in developing general-purpose agents. This poses a challenge
to LLMs' tool-use capabilities. However, there are evident gaps between
existing tool-use evaluations and real-world scenarios. Current evaluations
often use AI-generated queries, single-step tasks, dummy tools, and text-only
interactions, failing to reveal the agents' real-world problem-solving
abilities effectively. To address this, we propose GTA, a benchmark for General
Tool Agents, featuring three main aspects: (i) Real user queries: human-written
queries with simple real-world objectives but implicit tool-use, requiring the
LLM to reason the suitable tools and plan the solution steps. (ii) Real
deployed tools: an evaluation platform equipped with tools across perception,
operation, logic, and creativity categories to evaluate the agents' actual task
execution performance. (iii) Real multimodal inputs: authentic image files,
such as spatial scenes, web page screenshots, tables, code snippets, and
printed/handwritten materials, used as the query contexts to align with
real-world scenarios closely. We design 229 real-world tasks and executable
tool chains to evaluate mainstream LLMs. Our findings show that real-world user
queries are challenging for existing LLMs, with GPT-4 completing less than 50%
of the tasks and most LLMs achieving below 25%. This evaluation reveals the
bottlenecks in the tool-use capabilities of current LLMs in real-world
scenarios, which provides future direction for advancing general-purpose tool
agents. The code and dataset are available at
https://github.com/open-compass/GTA.",http://arxiv.org/pdf/2407.08713v1,2024-07-11,2407.08713v1,GTA: A Benchmark for General Tool Agents,gpt-4,highly irrelevant,"While the paper discusses large language models and their integration with tools for problem solving, it does not mention anything about hard prefix prompting or prompt engineering."
eyeballvul: a future-proof benchmark for vulnerability detection in the wild,['Timothee Chauvin'],"Long contexts of recent LLMs have enabled a new use case: asking models to
find security vulnerabilities in entire codebases. To evaluate model
performance on this task, we introduce eyeballvul: a benchmark designed to test
the vulnerability detection capabilities of language models at scale, that is
sourced and updated weekly from the stream of published vulnerabilities in
open-source repositories. The benchmark consists of a list of revisions in
different repositories, each associated with the list of known vulnerabilities
present at that revision. An LLM-based scorer is used to compare the list of
possible vulnerabilities returned by a model to the list of known
vulnerabilities for each revision. As of July 2024, eyeballvul contains 24,000+
vulnerabilities across 6,000+ revisions and 5,000+ repositories, and is around
55GB in size.",http://arxiv.org/pdf/2407.08708v1,2024-07-11,2407.08708v1,eyeballvul: a future-proof benchmark for vulnerability detection in the wild,gpt-4,highly irrelevant,The paper focuses on introducing a benchmark for vulnerability detection capabilities of language models and does not discuss prompt engineering or hard prefix prompting.
Towards Efficient Deployment of Hybrid SNNs on Neuromorphic and Edge AI Hardware,"['James Seekings', 'Peyton Chandarana', 'Mahsa Ardakani', 'MohammadReza Mohammadi', 'Ramtin Zand']","This paper explores the synergistic potential of neuromorphic and edge
computing to create a versatile machine learning (ML) system tailored for
processing data captured by dynamic vision sensors. We construct and train
hybrid models, blending spiking neural networks (SNNs) and artificial neural
networks (ANNs) using PyTorch and Lava frameworks. Our hybrid architecture
integrates an SNN for temporal feature extraction and an ANN for
classification. We delve into the challenges of deploying such hybrid
structures on hardware. Specifically, we deploy individual components on
Intel's Neuromorphic Processor Loihi (for SNN) and Jetson Nano (for ANN). We
also propose an accumulator circuit to transfer data from the spiking to the
non-spiking domain. Furthermore, we conduct comprehensive performance analyses
of hybrid SNN-ANN models on a heterogeneous system of neuromorphic and edge AI
hardware, evaluating accuracy, latency, power, and energy consumption. Our
findings demonstrate that the hybrid spiking networks surpass the baseline ANN
model across all metrics and outperform the baseline SNN model in accuracy and
latency.",http://arxiv.org/pdf/2407.08704v1,2024-07-11,2407.08704v1,Towards Efficient Deployment of Hybrid SNNs on Neuromorphic and Edge AI Hardware,gpt-4,highly irrelevant,The paper is focused on the deployment of hybrid spiking neural networks on hardware and does not mention prompts or any form of prompting technique.
Flex-TPU: A Flexible TPU with Runtime Reconfigurable Dataflow Architecture,"['Mohammed Elbtity', 'Peyton Chandarana', 'Ramtin Zand']","Tensor processing units (TPUs) are one of the most well-known machine
learning (ML) accelerators utilized at large scale in data centers as well as
in tiny ML applications. TPUs offer several improvements and advantages over
conventional ML accelerators, like graphical processing units (GPUs), being
designed specifically to perform the multiply-accumulate (MAC) operations
required in the matrix-matrix and matrix-vector multiplies extensively present
throughout the execution of deep neural networks (DNNs). Such improvements
include maximizing data reuse and minimizing data transfer by leveraging the
temporal dataflow paradigms provided by the systolic array architecture. While
this design provides a significant performance benefit, the current
implementations are restricted to a single dataflow consisting of either input,
output, or weight stationary architectures. This can limit the achievable
performance of DNN inference and reduce the utilization of compute units.
Therefore, the work herein consists of developing a reconfigurable dataflow
TPU, called the Flex-TPU, which can dynamically change the dataflow per layer
during run-time. Our experiments thoroughly test the viability of the Flex-TPU
comparing it to conventional TPU designs across multiple well-known ML
workloads. The results show that our Flex-TPU design achieves a significant
performance increase of up to 2.75x compared to conventional TPU, with only
minor area and power overheads.",http://arxiv.org/pdf/2407.08700v1,2024-07-11,2407.08700v1,Flex-TPU: A Flexible TPU with Runtime Reconfigurable Dataflow Architecture,gpt-4,highly irrelevant,This paper focuses on machine learning accelerators and TPU design rather than hard prefix prompting or prompt engineering.
Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight,"['Zhiqiang Xie', 'Yujia Zheng', 'Lizi Ottens', 'Kun Zhang', 'Christos Kozyrakis', 'Jonathan Mace']","Runtime failure and performance degradation is commonplace in modern cloud
systems. For cloud providers, automatically determining the root cause of
incidents is paramount to ensuring high reliability and availability as prompt
fault localization can enable faster diagnosis and triage for timely
resolution. A compelling solution explored in recent work is causal reasoning
using causal graphs to capture relationships between varied cloud system
performance metrics. To be effective, however, systems developers must
correctly define the causal graph of their system, which is a time-consuming,
brittle, and challenging task that increases in difficulty for large and
dynamic systems and requires domain expertise. Alternatively, automated
data-driven approaches have limited efficacy for cloud systems due to the
inherent rarity of incidents. In this work, we present Atlas, a novel approach
to automatically synthesizing causal graphs for cloud systems. Atlas leverages
large language models (LLMs) to generate causal graphs using system
documentation, telemetry, and deployment feedback. Atlas is complementary to
data-driven causal discovery techniques, and we further enhance Atlas with a
data-driven validation step. We evaluate Atlas across a range of fault
localization scenarios and demonstrate that Atlas is capable of generating
causal graphs in a scalable and generalizable manner, with performance that far
surpasses that of data-driven algorithms and is commensurate to the
ground-truth baseline.",http://arxiv.org/pdf/2407.08694v1,2024-07-11,2407.08694v1,Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight,gpt-4,highly irrelevant,"The paper is about using large language models (LLMs) for facilitating fault localization in cloud systems, not about the concept of hard prefix prompting or prompt engineering in transformers."
ElasticAST: An Audio Spectrogram Transformer for All Length and Resolutions,"['Jiu Feng', 'Mehmet Hamza Erol', 'Joon Son Chung', 'Arda Senocak']","Transformers have rapidly overtaken CNN-based architectures as the new
standard in audio classification. Transformer-based models, such as the Audio
Spectrogram Transformers (AST), also inherit the fixed-size input paradigm from
CNNs. However, this leads to performance degradation for ASTs in the inference
when input lengths vary from the training. This paper introduces an approach
that enables the use of variable-length audio inputs with AST models during
both training and inference. By employing sequence packing, our method
ElasticAST, accommodates any audio length during training, thereby offering
flexibility across all lengths and resolutions at the inference. This
flexibility allows ElasticAST to maintain evaluation capabilities at various
lengths or resolutions and achieve similar performance to standard ASTs trained
at specific lengths or resolutions. Moreover, experiments demonstrate
ElasticAST's better performance when trained and evaluated on native-length
audio datasets.",http://arxiv.org/pdf/2407.08691v1,2024-07-11,2407.08691v1,ElasticAST: An Audio Spectrogram Transformer for All Length and Resolutions,gpt-4,highly irrelevant,"The paper focuses on audio classification using Transformer-based models, in particular dealing with variable-length audio inputs, and does not mention or imply anything about prompts or prompt engineering."
"Operationalizing the Blueprint for an AI Bill of Rights: Recommendations for Practitioners, Researchers, and Policy Makers","['Alex Oesterling', 'Usha Bhalla', 'Suresh Venkatasubramanian', 'Himabindu Lakkaraju']","As Artificial Intelligence (AI) tools are increasingly employed in diverse
real-world applications, there has been significant interest in regulating
these tools. To this end, several regulatory frameworks have been introduced by
different countries worldwide. For example, the European Union recently passed
the AI Act, the White House issued an Executive Order on safe, secure, and
trustworthy AI, and the White House Office of Science and Technology Policy
issued the Blueprint for an AI Bill of Rights (AI BoR). Many of these
frameworks emphasize the need for auditing and improving the trustworthiness of
AI tools, underscoring the importance of safety, privacy, explainability,
fairness, and human fallback options. Although these regulatory frameworks
highlight the necessity of enforcement, practitioners often lack detailed
guidance on implementing them. Furthermore, the extensive research on
operationalizing each of these aspects is frequently buried in technical papers
that are difficult for practitioners to parse. In this write-up, we address
this shortcoming by providing an accessible overview of existing literature
related to operationalizing regulatory principles. We provide
easy-to-understand summaries of state-of-the-art literature and highlight
various gaps that exist between regulatory guidelines and existing AI research,
including the trade-offs that emerge during operationalization. We hope that
this work not only serves as a starting point for practitioners interested in
learning more about operationalizing the regulatory guidelines outlined in the
Blueprint for an AI BoR but also provides researchers with a list of critical
open problems and gaps between regulations and state-of-the-art AI research.
Finally, we note that this is a working paper and we invite feedback in line
with the purpose of this document as described in the introduction.",http://arxiv.org/pdf/2407.08689v1,2024-07-11,2407.08689v1,"Operationalizing the Blueprint for an AI Bill of Rights: Recommendations for Practitioners, Researchers, and Policy Makers",gpt-4,highly irrelevant,"The paper focuses on AI regulation and its impact on trustworthiness, safety, privacy, and fairness, rather than hard prefix prompts or prompt engineering."
Uncertainty Estimation of Large Language Models in Medical Question Answering,"['Jiaxin Wu', 'Yizhou Yu', 'Hong-Yu Zhou']","Large Language Models (LLMs) show promise for natural language generation in
healthcare, but risk hallucinating factually incorrect information. Deploying
LLMs for medical question answering necessitates reliable uncertainty
estimation (UE) methods to detect hallucinations. In this work, we benchmark
popular UE methods with different model sizes on medical question-answering
datasets. Our results show that current approaches generally perform poorly in
this domain, highlighting the challenge of UE for medical applications. We also
observe that larger models tend to yield better results, suggesting a
correlation between model size and the reliability of UE. To address these
challenges, we propose Two-phase Verification, a probability-free Uncertainty
Estimation approach. First, an LLM generates a step-by-step explanation
alongside its initial answer, followed by formulating verification questions to
check the factual claims in the explanation. The model then answers these
questions twice: first independently, and then referencing the explanation.
Inconsistencies between the two sets of answers measure the uncertainty in the
original response. We evaluate our approach on three biomedical
question-answering datasets using Llama 2 Chat models and compare it against
the benchmarked baseline methods. The results show that our Two-phase
Verification method achieves the best overall accuracy and stability across
various datasets and model sizes, and its performance scales as the model size
increases.",http://arxiv.org/pdf/2407.08662v1,2024-07-11,2407.08662v1,Uncertainty Estimation of Large Language Models in Medical Question Answering,gpt-4,highly irrelevant,"This paper focuses on uncertainty estimation in large language models in the context of medical question answering, and though it uses language models for generation and verification, it does not discuss prefix prompts or prompt engineering."
SPOCKMIP: Segmentation of Vessels in MRAs with Enhanced Continuity using Maximum Intensity Projection as Loss,"['Chethan Radhakrishna', 'Karthikesh Varma Chintalapati', 'Sri Chandana Hudukula Ram Kumar', 'Raviteja Sutrave', 'Hendrik Mattern', 'Oliver Speck', 'Andreas Nürnberger', 'Soumick Chatterjee']","Identification of vessel structures of different sizes in biomedical images
is crucial in the diagnosis of many neurodegenerative diseases. However, the
sparsity of good-quality annotations of such images makes the task of vessel
segmentation challenging. Deep learning offers an efficient way to segment
vessels of different sizes by learning their high-level feature representations
and the spatial continuity of such features across dimensions. Semi-supervised
patch-based approaches have been effective in identifying small vessels of one
to two voxels in diameter. This study focuses on improving the segmentation
quality by considering the spatial correlation of the features using the
Maximum Intensity Projection~(MIP) as an additional loss criterion. Two methods
are proposed with the incorporation of MIPs of label segmentation on the
single~(z-axis) and multiple perceivable axes of the 3D volume. The proposed
MIP-based methods produce segmentations with improved vessel continuity, which
is evident in visual examinations of ROIs. Patch-based training is improved by
introducing an additional loss term, MIP loss, to penalise the predicted
discontinuity of vessels. A training set of 14 volumes is selected from the
StudyForrest dataset comprising of 18 7-Tesla 3D Time-of-Flight~(ToF) Magnetic
Resonance Angiography (MRA) images. The generalisation performance of the
method is evaluated using the other unseen volumes in the dataset. It is
observed that the proposed method with multi-axes MIP loss produces better
quality segmentations with a median Dice of $80.245 \pm 0.129$. Also, the
method with single-axis MIP loss produces segmentations with a median Dice of
$79.749 \pm 0.109$. Furthermore, a visual comparison of the ROIs in the
predicted segmentation reveals a significant improvement in the continuity of
the vessels when MIP loss is incorporated into training.",http://arxiv.org/pdf/2407.08655v1,2024-07-11,2407.08655v1,SPOCKMIP: Segmentation of Vessels in MRAs with Enhanced Continuity using Maximum Intensity Projection as Loss,gpt-4,highly irrelevant,This paper is about MIA image segmentation and not about hard prefix prompting or prompt engineering.
Confidence-based Estimators for Predictive Performance in Model Monitoring,"['Juhani Kivimäki', 'Jakub Białek', 'Jukka K. Nurminen', 'Wojtek Kuberski']","After a machine learning model has been deployed into production, its
predictive performance needs to be monitored. Ideally, such monitoring can be
carried out by comparing the model's predictions against ground truth labels.
For this to be possible, the ground truth labels must be available relatively
soon after inference. However, there are many use cases where ground truth
labels are available only after a significant delay, or in the worst case, not
at all. In such cases, directly monitoring the model's predictive performance
is impossible.
  Recently, novel methods for estimating the predictive performance of a model
when ground truth is unavailable have been developed. Many of these methods
leverage model confidence or other uncertainty estimates and are experimentally
compared against a naive baseline method, namely Average Confidence (AC), which
estimates model accuracy as the average of confidence scores for a given set of
predictions. However, until now the theoretical properties of the AC method
have not been properly explored. In this paper, we try to fill this gap by
reviewing the AC method and show that under certain general assumptions, it is
an unbiased and consistent estimator of model accuracy with many desirable
properties. We also compare this baseline estimator against some more complex
estimators empirically and show that in many cases the AC method is able to
beat the others, although the comparative quality of the different estimators
is heavily case-dependent.",http://arxiv.org/pdf/2407.08649v1,2024-07-11,2407.08649v1,Confidence-based Estimators for Predictive Performance in Model Monitoring,gpt-4,highly irrelevant,The paper discusses the estimation of predictive performance in machine learning models and does not mention or allude to the concept of hard prefix prompting or prompt engineering.
Towards Building Specialized Generalist AI with System 1 and System 2 Fusion,"['Kaiyan Zhang', 'Biqing Qi', 'Bowen Zhou']","In this perspective paper, we introduce the concept of Specialized Generalist
Artificial Intelligence (SGAI or simply SGI) as a crucial milestone toward
Artificial General Intelligence (AGI). Compared to directly scaling general
abilities, SGI is defined as AI that specializes in at least one task,
surpassing human experts, while also retaining general abilities. This fusion
path enables SGI to rapidly achieve high-value areas. We categorize SGI into
three stages based on the level of mastery over professional skills and
generality performance. Additionally, we discuss the necessity of SGI in
addressing issues associated with large language models, such as their
insufficient generality, specialized capabilities, uncertainty in innovation,
and practical applications. Furthermore, we propose a conceptual framework for
developing SGI that integrates the strengths of Systems 1 and 2 cognitive
processing. This framework comprises three layers and four key components,
which focus on enhancing individual abilities and facilitating collaborative
evolution. We conclude by summarizing the potential challenges and suggesting
future directions. We hope that the proposed SGI will provide insights into
further research and applications towards achieving AGI.",http://arxiv.org/pdf/2407.08642v1,2024-07-11,2407.08642v1,Towards Building Specialized Generalist AI with System 1 and System 2 Fusion,gpt-4,highly irrelevant,"The abstract of this paper does not mention or allude to the use of hard prefix prompts, prompt engineering, or similar topics."
$β$-DPO: Direct Preference Optimization with Dynamic $β$,"['Junkang Wu', 'Yuexiang Xie', 'Zhengyi Yang', 'Jiancan Wu', 'Jinyang Gao', 'Bolin Ding', 'Xiang Wang', 'Xiangnan He']","Direct Preference Optimization (DPO) has emerged as a compelling approach for
training Large Language Models (LLMs) to adhere to human preferences. However,
the performance of DPO is sensitive to the fine-tuning of its trade-off
parameter $\beta$, as well as to the quality of the preference data. We analyze
the impact of $\beta$ and data quality on DPO, uncovering that optimal $\beta$
values vary with the informativeness of pairwise data. Addressing the
limitations of static $\beta$ values, we introduce a novel framework that
dynamically calibrates $\beta$ at the batch level, informed by data quality
considerations. Additionally, our method incorporates $\beta$-guided data
filtering to safeguard against the influence of outliers. Through empirical
evaluation, we demonstrate that our dynamic $\beta$ adjustment technique
significantly improves DPO's performance across a range of models and datasets,
offering a more robust and adaptable training paradigm for aligning LLMs with
human feedback. The code is available at
\url{https://github.com/junkangwu/beta-DPO}.",http://arxiv.org/pdf/2407.08639v1,2024-07-11,2407.08639v1,$β$-DPO: Direct Preference Optimization with Dynamic $β$,gpt-4,highly irrelevant,"The paper is about direct preference optimization, a method for training large language models to align with human feedback, and not related to prompting or prompt engineering."
A Novel Framework for Automated Warehouse Layout Generation,"['Atefeh Shahroudnejad', 'Payam Mousavi', 'Oleksii Perepelytsia', 'Sahir', 'David Staszak', 'Matthew E. Taylor', 'Brent Bawel']","Optimizing warehouse layouts is crucial due to its significant impact on
efficiency and productivity. We present an AI-driven framework for automated
warehouse layout generation. This framework employs constrained beam search to
derive optimal layouts within given spatial parameters, adhering to all
functional requirements. The feasibility of the generated layouts is verified
based on criteria such as item accessibility, required minimum clearances, and
aisle connectivity. A scoring function is then used to evaluate the feasible
layouts considering the number of storage locations, access points, and
accessibility costs. We demonstrate our method's ability to produce feasible,
optimal layouts for a variety of warehouse dimensions and shapes, diverse door
placements, and interconnections. This approach, currently being prepared for
deployment, will enable human designers to rapidly explore and confirm options,
facilitating the selection of the most appropriate layout for their use-case.",http://arxiv.org/pdf/2407.08633v1,2024-07-11,2407.08633v1,A Novel Framework for Automated Warehouse Layout Generation,gpt-4,highly irrelevant,"The paper is centered around the optimization of warehouse layouts using an AI framework, and does not discuss or mention prompt engineering or hard prefix prompting techniques."
Tamil Language Computing: the Present and the Future,['Kengatharaiyer Sarveswaran'],"This paper delves into the text processing aspects of Language Computing,
which enables computers to understand, interpret, and generate human language.
Focusing on tasks such as speech recognition, machine translation, sentiment
analysis, text summarization, and language modelling, language computing
integrates disciplines including linguistics, computer science, and cognitive
psychology to create meaningful human-computer interactions. Recent
advancements in deep learning have made computers more accessible and capable
of independent learning and adaptation. In examining the landscape of language
computing, the paper emphasises foundational work like encoding, where Tamil
transitioned from ASCII to Unicode, enhancing digital communication. It
discusses the development of computational resources, including raw data,
dictionaries, glossaries, annotated data, and computational grammars, necessary
for effective language processing. The challenges of linguistic annotation, the
creation of treebanks, and the training of large language models are also
covered, emphasising the need for high-quality, annotated data and advanced
language models. The paper underscores the importance of building practical
applications for languages like Tamil to address everyday communication needs,
highlighting gaps in current technology. It calls for increased research
collaboration, digitization of historical texts, and fostering digital usage to
ensure the comprehensive development of Tamil language processing, ultimately
enhancing global communication and access to digital services.",http://arxiv.org/pdf/2407.08618v1,2024-07-11,2407.08618v1,Tamil Language Computing: the Present and the Future,gpt-4,highly irrelevant,"This paper focuses on the broader field of language computing, including language modeling, speech recognition, translation, and other tasks. It does not discuss hard prefix prompting or prompt engineering specifically."
FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision,"['Jay Shah', 'Ganesh Bikshandi', 'Ying Zhang', 'Vijay Thakkar', 'Pradeep Ramani', 'Tri Dao']","Attention, as a core layer of the ubiquitous Transformer architecture, is the
bottleneck for large language models and long-context applications.
FlashAttention elaborated an approach to speed up attention on GPUs through
minimizing memory reads/writes. However, it has yet to take advantage of new
capabilities present in recent hardware, with FlashAttention-2 achieving only
35% utilization on the H100 GPU. We develop three main techniques to speed up
attention on Hopper GPUs: exploiting asynchrony of the Tensor Cores and TMA to
(1) overlap overall computation and data movement via warp-specialization and
(2) interleave block-wise matmul and softmax operations, and (3) block
quantization and incoherent processing that leverages hardware support for FP8
low-precision. We demonstrate that our method, FlashAttention-3, achieves
speedup on H100 GPUs by 1.5-2.0$\times$ with FP16 reaching up to 740 TFLOPs/s
(75% utilization), and with FP8 reaching close to 1.2 PFLOPs/s. We validate
that FP8 FlashAttention-3 achieves 2.6$\times$ lower numerical error than a
baseline FP8 attention.",http://arxiv.org/pdf/2407.08608v1,2024-07-11,2407.08608v1,FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision,gpt-4,highly irrelevant,"The paper focuses on attention mechanisms and improving efficiency in large language models, rather than on hard prefix prompting or prompt engineering techniques."
Turn-Level Empathy Prediction Using Psychological Indicators,"['Shaz Furniturewala', 'Kokil Jaidka']","For the WASSA 2024 Empathy and Personality Prediction Shared Task, we propose
a novel turn-level empathy detection method that decomposes empathy into six
psychological indicators: Emotional Language, Perspective-Taking, Sympathy and
Compassion, Extroversion, Openness, and Agreeableness. A pipeline of text
enrichment using a Large Language Model (LLM) followed by DeBERTA fine-tuning
demonstrates a significant improvement in the Pearson Correlation Coefficient
and F1 scores for empathy detection, highlighting the effectiveness of our
approach. Our system officially ranked 7th at the CONV-turn track.",http://arxiv.org/pdf/2407.08607v1,2024-07-11,2407.08607v1,Turn-Level Empathy Prediction Using Psychological Indicators,gpt-4,highly irrelevant,"The paper discusses using a Large Language Model for enriching text, but it doesn't mention prompts or prompt engineering, and the focus is more on empathy detection which is a different field."
A Review of Nine Physics Engines for Reinforcement Learning Research,"['Michael Kaup', 'Cornelius Wolff', 'Hyerim Hwang', 'Julius Mayer', 'Elia Bruni']","We present a review of popular simulation engines and frameworks used in
reinforcement learning (RL) research, aiming to guide researchers in selecting
tools for creating simulated physical environments for RL and training setups.
It evaluates nine frameworks (Brax, Chrono, Gazebo, MuJoCo, ODE, PhysX,
PyBullet, Webots, and Unity) based on their popularity, feature range, quality,
usability, and RL capabilities. We highlight the challenges in selecting and
utilizing physics engines for RL research, including the need for detailed
comparisons and an understanding of each framework's capabilities. Key findings
indicate MuJoCo as the leading framework due to its performance and
flexibility, despite usability challenges. Unity is noted for its ease of use
but lacks scalability and simulation fidelity. The study calls for further
development to improve simulation engines' usability and performance and
stresses the importance of transparency and reproducibility in RL research.
This review contributes to the RL community by offering insights into the
selection process for simulation engines, facilitating informed
decision-making.",http://arxiv.org/pdf/2407.08590v1,2024-07-11,2407.08590v1,A Review of Nine Physics Engines for Reinforcement Learning Research,gpt-4,highly irrelevant,The paper focuses on reviewing physics engines for reinforcement learning research and does not mention or discuss hard prefix prompting or prompt engineering.
HACMan++: Spatially-Grounded Motion Primitives for Manipulation,"['Bowen Jiang', 'Yilin Wu', 'Wenxuan Zhou', 'Chris Paxton', 'David Held']","Although end-to-end robot learning has shown some success for robot
manipulation, the learned policies are often not sufficiently robust to
variations in object pose or geometry. To improve the policy generalization, we
introduce spatially-grounded parameterized motion primitives in our method
HACMan++. Specifically, we propose an action representation consisting of three
components: what primitive type (such as grasp or push) to execute, where the
primitive will be grounded (e.g. where the gripper will make contact with the
world), and how the primitive motion is executed, such as parameters specifying
the push direction or grasp orientation. These three components define a novel
discrete-continuous action space for reinforcement learning. Our framework
enables robot agents to learn to chain diverse motion primitives together and
select appropriate primitive parameters to complete long-horizon manipulation
tasks. By grounding the primitives on a spatial location in the environment,
our method is able to effectively generalize across object shape and pose
variations. Our approach significantly outperforms existing methods,
particularly in complex scenarios demanding both high-level sequential
reasoning and object generalization. With zero-shot sim-to-real transfer, our
policy succeeds in challenging real-world manipulation tasks, with
generalization to unseen objects. Videos can be found on the project website:
https://sgmp-rss2024.github.io.",http://arxiv.org/pdf/2407.08585v1,2024-07-11,2407.08585v1,HACMan++: Spatially-Grounded Motion Primitives for Manipulation,gpt-4,highly irrelevant,"The paper mainly focuses on the creation of a spatially-grounded parameterized motion primitives for robot manipulation, rather than hard prefix prompting or prompt engineering."
The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective,"['Zhen Qin', 'Daoyuan Chen', 'Wenhao Zhang', 'Liuyi Yao', 'Yilun Huang', 'Bolin Ding', 'Yaliang Li', 'Shuiguang Deng']","The rapid development of large language models (LLMs) has been witnessed in
recent years. Based on the powerful LLMs, multi-modal LLMs (MLLMs) extend the
modality from text to a broader spectrum of domains, attracting widespread
attention due to the broader range of application scenarios. As LLMs and MLLMs
rely on vast amounts of model parameters and data to achieve emergent
capabilities, the importance of data is receiving increasingly widespread
attention and recognition. Tracing and analyzing recent data-oriented works for
MLLMs, we find that the development of models and data is not two separate
paths but rather interconnected. On the one hand, vaster and higher-quality
data contribute to better performance of MLLMs, on the other hand, MLLMs can
facilitate the development of data. The co-development of multi-modal data and
MLLMs requires a clear view of 1) at which development stage of MLLMs can
specific data-centric approaches be employed to enhance which capabilities, and
2) by utilizing which capabilities and acting as which roles can models
contribute to multi-modal data. To promote the data-model co-development for
MLLM community, we systematically review existing works related to MLLMs from
the data-model co-development perspective. A regularly maintained project
associated with this survey is accessible at
https://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md.",http://arxiv.org/pdf/2407.08583v1,2024-07-11,2407.08583v1,The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective,gpt-4,highly irrelevant,"The paper surveys the co-development of data and multimodal large language models (LLMs), with no mention of hard prefix prompting or any related prompt engineering techniques."
On the Universal Truthfulness Hyperplane Inside LLMs,"['Junteng Liu', 'Shiqi Chen', 'Yu Cheng', 'Junxian He']","While large language models (LLMs) have demonstrated remarkable abilities
across various fields, hallucination remains a significant challenge. Recent
studies have explored hallucinations through the lens of internal
representations, proposing mechanisms to decipher LLMs' adherence to facts.
However, these approaches often fail to generalize to out-of-distribution data,
leading to concerns about whether internal representation patterns reflect
fundamental factual awareness, or only overfit spurious correlations on the
specific datasets. In this work, we investigate whether a universal
truthfulness hyperplane that distinguishes the model's factually correct and
incorrect outputs exists within the model. To this end, we scale up the number
of training datasets and conduct an extensive evaluation -- we train the
truthfulness hyperplane on a diverse collection of over 40 datasets and examine
its cross-task, cross-domain, and in-domain generalization. Our results
indicate that increasing the diversity of the training datasets significantly
enhances the performance in all scenarios, while the volume of data samples
plays a less critical role. This finding supports the optimistic hypothesis
that a universal truthfulness hyperplane may indeed exist within the model,
offering promising directions for future research.",http://arxiv.org/pdf/2407.08582v1,2024-07-11,2407.08582v1,On the Universal Truthfulness Hyperplane Inside LLMs,gpt-4,highly irrelevant,"The study focuses on internal representations in large language models and their ability to distinguish between factually correct and incorrect outputs, with no mention of hard prefix prompting or prompt engineering techniques."
Multi-Group Proportional Representation,"['Alex Oesterling', 'Claudio Mayrink Verdun', 'Carol Xuan Long', 'Alex Glynn', 'Lucas Monteiro Paes', 'Sajani Vithana', 'Martina Cardone', 'Flavio P. Calmon']","Image search and retrieval tasks can perpetuate harmful stereotypes, erase
cultural identities, and amplify social disparities. Current approaches to
mitigate these representational harms balance the number of retrieved items
across population groups defined by a small number of (often binary)
attributes. However, most existing methods overlook intersectional groups
determined by combinations of group attributes, such as gender, race, and
ethnicity. We introduce Multi-Group Proportional Representation (MPR), a novel
metric that measures representation across intersectional groups. We develop
practical methods for estimating MPR, provide theoretical guarantees, and
propose optimization algorithms to ensure MPR in retrieval. We demonstrate that
existing methods optimizing for equal and proportional representation metrics
may fail to promote MPR. Crucially, our work shows that optimizing MPR yields
more proportional representation across multiple intersectional groups
specified by a rich function class, often with minimal compromise in retrieval
accuracy.",http://arxiv.org/pdf/2407.08571v1,2024-07-11,2407.08571v1,Multi-Group Proportional Representation,gpt-4,highly irrelevant,"This paper is focused on image search and retrieval tasks, optimization algorithms and proportional representation across intersectional groups, without any mention of prompt engineering or hard prefix prompts."
The Career Interests of Large Language Models,"['Meng Hua', 'Yuan Cheng', 'Hengshu Zhu']","Recent advancements in Large Language Models (LLMs) have significantly
extended their capabilities, evolving from basic text generation to complex,
human-like interactions. In light of the possibilities that LLMs could assume
significant workplace responsibilities, it becomes imminently necessary to
explore LLMs' capacities as professional assistants. This study focuses on the
aspect of career interests by applying the Occupation Network's Interest
Profiler short form to LLMs as if they were human participants and investigates
their hypothetical career interests and competence, examining how these vary
with language changes and model advancements. We analyzed the answers using a
general linear mixed model approach and found distinct career interest
inclinations among LLMs, particularly towards the social and artistic domains.
Interestingly, these preferences did not align with the occupations where LLMs
exhibited higher competence. This novel approach of using psychometric
instruments and sophisticated statistical tools on LLMs unveils fresh
perspectives on their integration into professional environments, highlighting
human-like tendencies and promoting a reevaluation of LLMs' self-perception and
competency alignment in the workforce.",http://arxiv.org/pdf/2407.08564v1,2024-07-11,2407.08564v1,The Career Interests of Large Language Models,gpt-4,highly irrelevant,"This paper examines the career interests of large language models, rather than discussing anything related to hard prefix prompting or prompt engineering techniques."
"Vox Populi, Vox AI? Using Language Models to Estimate German Public Opinion","['Leah von der Heyde', 'Anna-Carolina Haensch', 'Alexander Wenz']","The recent development of large language models (LLMs) has spurred
discussions about whether LLM-generated ""synthetic samples"" could complement or
replace traditional surveys, considering their training data potentially
reflects attitudes and behaviors prevalent in the population. A number of
mostly US-based studies have prompted LLMs to mimic survey respondents, with
some of them finding that the responses closely match the survey data. However,
several contextual factors related to the relationship between the respective
target population and LLM training data might affect the generalizability of
such findings. In this study, we investigate the extent to which LLMs can
estimate public opinion in Germany, using the example of vote choice. We
generate a synthetic sample of personas matching the individual characteristics
of the 2017 German Longitudinal Election Study respondents. We ask the LLM
GPT-3.5 to predict each respondent's vote choice and compare these predictions
to the survey-based estimates on the aggregate and subgroup levels. We find
that GPT-3.5 does not predict citizens' vote choice accurately, exhibiting a
bias towards the Green and Left parties. While the LLM captures the tendencies
of ""typical"" voter subgroups, such as partisans, it misses the multifaceted
factors swaying individual voter choices. By examining the LLM-based prediction
of voting behavior in a new context, our study contributes to the growing body
of research about the conditions under which LLMs can be leveraged for studying
public opinion. The findings point to disparities in opinion representation in
LLMs and underscore the limitations in applying them for public opinion
estimation.",http://arxiv.org/pdf/2407.08563v1,2024-07-11,2407.08563v1,"Vox Populi, Vox AI? Using Language Models to Estimate German Public Opinion",gpt-4,highly irrelevant,This paper uses language models like GPT-3.5 for public opinion estimation but does not discuss prompt engineering or hard prefix prompting techniques.
ST-Mamba: Spatial-Temporal Mamba for Traffic Flow Estimation Recovery using Limited Data,"['Doncheng Yuan', 'Jianzhe Xue', 'Jinshan Su', 'Wenchao Xu', 'Haibo Zhou']","Traffic flow estimation (TFE) is crucial for urban intelligent traffic
systems. While traditional on-road detectors are hindered by limited coverage
and high costs, cloud computing and data mining of vehicular network data, such
as driving speeds and GPS coordinates, present a promising and cost-effective
alternative. Furthermore, minimizing data collection can significantly reduce
overhead. However, limited data can lead to inaccuracies and instability in
TFE. To address this, we introduce the spatial-temporal Mamba (ST-Mamba), a
deep learning model combining a convolutional neural network (CNN) with a Mamba
framework. ST-Mamba is designed to enhance TFE accuracy and stability by
effectively capturing the spatial-temporal patterns within traffic flow. Our
model aims to achieve results comparable to those from extensive data sets
while only utilizing minimal data. Simulations using real-world datasets have
validated our model's ability to deliver precise and stable TFE across an urban
landscape based on limited data, establishing a cost-efficient solution for
TFE.",http://arxiv.org/pdf/2407.08558v1,2024-07-11,2407.08558v1,ST-Mamba: Spatial-Temporal Mamba for Traffic Flow Estimation Recovery using Limited Data,gpt-4,highly irrelevant,The paper focuses on traffic flow estimation using deep learning models and does not discuss anything related to hard prefix prompting or prompt engineering.
Establishing Rigorous and Cost-effective Clinical Trials for Artificial Intelligence Models,"['Wanling Gao', 'Yunyou Huang', 'Dandan Cui', 'Zhuoming Yu', 'Wenjing Liu', 'Xiaoshuang Liang', 'Jiahui Zhao', 'Jiyue Xie', 'Hao Li', 'Li Ma', 'Ning Ye', 'Yumiao Kang', 'Dingfeng Luo', 'Peng Pan', 'Wei Huang', 'Zhongmou Liu', 'Jizhong Hu', 'Gangyuan Zhao', 'Chongrong Jiang', 'Fan Huang', 'Tianyi Wei', 'Suqin Tang', 'Bingjie Xia', 'Zhifei Zhang', 'Jianfeng Zhan']","A profound gap persists between artificial intelligence (AI) and clinical
practice in medicine, primarily due to the lack of rigorous and cost-effective
evaluation methodologies. State-of-the-art and state-of-the-practice AI model
evaluations are limited to laboratory studies on medical datasets or direct
clinical trials with no or solely patient-centered controls. Moreover, the
crucial role of clinicians in collaborating with AI, pivotal for determining
its impact on clinical practice, is often overlooked. For the first time, we
emphasize the critical necessity for rigorous and cost-effective evaluation
methodologies for AI models in clinical practice, featuring
patient/clinician-centered (dual-centered) AI randomized controlled trials
(DC-AI RCTs) and virtual clinician-based in-silico trials (VC-MedAI) as an
effective proxy for DC-AI RCTs. Leveraging 7500 diagnosis records from
two-phase inaugural DC-AI RCTs across 14 medical centers with 125 clinicians,
our results demonstrate the necessity of DC-AI RCTs and the effectiveness of
VC-MedAI. Notably, VC-MedAI performs comparably to human clinicians,
replicating insights and conclusions from prospective DC-AI RCTs. We envision
DC-AI RCTs and VC-MedAI as pivotal advancements, presenting innovative and
transformative evaluation methodologies for AI models in clinical practice,
offering a preclinical-like setting mirroring conventional medicine, and
reshaping development paradigms in a cost-effective and fast-iterative manner.
Chinese Clinical Trial Registration: ChiCTR2400086816.",http://arxiv.org/pdf/2407.08554v1,2024-07-11,2407.08554v1,Establishing Rigorous and Cost-effective Clinical Trials for Artificial Intelligence Models,gpt-4,highly irrelevant,"The paper discusses methodologies for evaluating AI models in clinical medical trials, but doesn't mention anything about hard prefix prompting or prompt engineering."
Autoregressive Speech Synthesis without Vector Quantization,"['Lingwei Meng', 'Long Zhou', 'Shujie Liu', 'Sanyuan Chen', 'Bing Han', 'Shujie Hu', 'Yanqing Liu', 'Jinyu Li', 'Sheng Zhao', 'Xixin Wu', 'Helen Meng', 'Furu Wei']","We present MELLE, a novel continuous-valued tokens based language modeling
approach for text to speech synthesis (TTS). MELLE autoregressively generates
continuous mel-spectrogram frames directly from text condition, bypassing the
need for vector quantization, which are originally designed for audio
compression and sacrifice fidelity compared to mel-spectrograms. Specifically,
(i) instead of cross-entropy loss, we apply regression loss with a proposed
spectrogram flux loss function to model the probability distribution of the
continuous-valued tokens. (ii) we have incorporated variational inference into
MELLE to facilitate sampling mechanisms, thereby enhancing the output diversity
and model robustness. Experiments demonstrate that, compared to the two-stage
codec language models VALL-E and its variants, the single-stage MELLE mitigates
robustness issues by avoiding the inherent flaws of sampling discrete codes,
achieves superior performance across multiple metrics, and, most importantly,
offers a more streamlined paradigm. See https://aka.ms/melle for demos of our
work.",http://arxiv.org/pdf/2407.08551v1,2024-07-11,2407.08551v1,Autoregressive Speech Synthesis without Vector Quantization,gpt-4,highly irrelevant,"While this paper focuses on a novel language modeling approach for TTS, it does not mention prompt engineering or the use of hard prefix prompts."
Emergent Visual-Semantic Hierarchies in Image-Text Representations,"['Morris Alper', 'Hadar Averbuch-Elor']","While recent vision-and-language models (VLMs) like CLIP are a powerful tool
for analyzing text and images in a shared semantic space, they do not
explicitly model the hierarchical nature of the set of texts which may describe
an image. Conversely, existing multimodal hierarchical representation learning
methods require costly training from scratch, failing to leverage the knowledge
encoded by state-of-the-art multimodal foundation models. In this work, we
study the knowledge of existing foundation models, finding that they exhibit
emergent understanding of visual-semantic hierarchies despite not being
directly trained for this purpose. We propose the Radial Embedding (RE)
framework for probing and optimizing hierarchical understanding, and contribute
the HierarCaps dataset, a benchmark facilitating the study of hierarchical
knowledge in image--text representations, constructed automatically via large
language models. Our results show that foundation VLMs exhibit zero-shot
hierarchical understanding, surpassing the performance of prior models
explicitly designed for this purpose. Furthermore, we show that foundation
models may be better aligned to hierarchical reasoning via a text-only
fine-tuning phase, while retaining pretraining knowledge.",http://arxiv.org/pdf/2407.08521v1,2024-07-11,2407.08521v1,Emergent Visual-Semantic Hierarchies in Image-Text Representations,gpt-4,highly irrelevant,"The paper focuses on analyzing text and images in a shared semantic space using vision-and-language models (VLMs), with no mention of hard prefix prompting or prompt engineering."
Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents,"['Haoyi Xiong', 'Zhiyuan Wang', 'Xuhong Li', 'Jiang Bian', 'Zeke Xie', 'Shahid Mumtaz', 'Laura E. Barnes']","This article explores the convergence of connectionist and symbolic
artificial intelligence (AI), from historical debates to contemporary
advancements. Traditionally considered distinct paradigms, connectionist AI
focuses on neural networks, while symbolic AI emphasizes symbolic
representation and logic. Recent advancements in large language models (LLMs),
exemplified by ChatGPT and GPT-4, highlight the potential of connectionist
architectures in handling human language as a form of symbols. The study argues
that LLM-empowered Autonomous Agents (LAAs) embody this paradigm convergence.
By utilizing LLMs for text-based knowledge modeling and representation, LAAs
integrate neuro-symbolic AI principles, showcasing enhanced reasoning and
decision-making capabilities. Comparing LAAs with Knowledge Graphs within the
neuro-symbolic AI theme highlights the unique strengths of LAAs in mimicking
human-like reasoning processes, scaling effectively with large datasets, and
leveraging in-context samples without explicit re-training. The research
underscores promising avenues in neuro-vector-symbolic integration,
instructional encoding, and implicit reasoning, aimed at further enhancing LAA
capabilities. By exploring the progression of neuro-symbolic AI and proposing
future research trajectories, this work advances the understanding and
development of AI technologies.",http://arxiv.org/pdf/2407.08516v1,2024-07-11,2407.08516v1,Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents,gpt-4,highly irrelevant,"While the paper discusses large language models and neuro-symbolic AI, it does not specifically discuss hard prefix prompting or prompt engineering techniques."
15M Multimodal Facial Image-Text Dataset,"['Dawei Dai', 'YuTang Li', 'YingGe Liu', 'Mingming Jia', 'Zhang YuanHui', 'Guoyin Wang']","Currently, image-text-driven multi-modal deep learning models have
demonstrated their outstanding potential in many fields. In practice, tasks
centered around facial images have broad application prospects. This paper
presents \textbf{FaceCaption-15M}, a large-scale, diverse, and high-quality
dataset of facial images accompanied by their natural language descriptions
(facial image-to-text). This dataset aims to facilitate a study on
face-centered tasks. FaceCaption-15M comprises over 15 million pairs of facial
images and their corresponding natural language descriptions of facial
features, making it the largest facial image-caption dataset to date. We
conducted a comprehensive analysis of image quality, text naturalness, text
complexity, and text-image relevance to demonstrate the superiority of
FaceCaption-15M. To validate the effectiveness of FaceCaption-15M, we first
trained a facial language-image pre-training model (FLIP, similar to CLIP) to
align facial image with its corresponding captions in feature space.
Subsequently, using both image and text encoders and fine-tuning only the
linear layer, our FLIP-based models achieved state-of-the-art results on two
challenging face-centered tasks. The purpose is to promote research in the
field of face-related tasks through the availability of the proposed
FaceCaption-15M dataset. All data, codes, and models are publicly available.
https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M",http://arxiv.org/pdf/2407.08515v1,2024-07-11,2407.08515v1,15M Multimodal Facial Image-Text Dataset,gpt-4,highly irrelevant,"The paper discusses the creation and usage of a dataset for image-text-enhanced deep learning models, but does not mention anything related to prompt engineering or hard prefix prompts."
Latent Conditional Diffusion-based Data Augmentation for Continuous-Time Dynamic Graph Mode,"['Yuxing Tian', 'Yiyan Qi', 'Aiwen Jiang', 'Qi Huang', 'Jian Guo']","Continuous-Time Dynamic Graph (CTDG) precisely models evolving real-world
relationships, drawing heightened interest in dynamic graph learning across
academia and industry. However, existing CTDG models encounter challenges
stemming from noise and limited historical data. Graph Data Augmentation (GDA)
emerges as a critical solution, yet current approaches primarily focus on
static graphs and struggle to effectively address the dynamics inherent in
CTDGs. Moreover, these methods often demand substantial domain expertise for
parameter tuning and lack theoretical guarantees for augmentation efficacy. To
address these issues, we propose Conda, a novel latent diffusion-based GDA
method tailored for CTDGs. Conda features a sandwich-like architecture,
incorporating a Variational Auto-Encoder (VAE) and a conditional diffusion
model, aimed at generating enhanced historical neighbor embeddings for target
nodes. Unlike conventional diffusion models trained on entire graphs via
pre-training, Conda requires historical neighbor sequence embeddings of target
nodes for training, thus facilitating more targeted augmentation. We integrate
Conda into the CTDG model and adopt an alternating training strategy to
optimize performance. Extensive experimentation across six widely used
real-world datasets showcases the consistent performance improvement of our
approach, particularly in scenarios with limited historical data.",http://arxiv.org/pdf/2407.08500v1,2024-07-11,2407.08500v1,Latent Conditional Diffusion-based Data Augmentation for Continuous-Time Dynamic Graph Mode,gpt-4,highly irrelevant,"The paper is focused on graph data augmentation and dynamic graph learning, and there is no mention or implications of prompt engineering or hard prefix prompting."
CE-QArg: Counterfactual Explanations for Quantitative Bipolar Argumentation Frameworks (Technical Report),"['Xiang Yin', 'Nico Potyka', 'Francesca Toni']","There is a growing interest in understanding arguments' strength in
Quantitative Bipolar Argumentation Frameworks (QBAFs). Most existing studies
focus on attribution-based methods that explain an argument's strength by
assigning importance scores to other arguments but fail to explain how to
change the current strength to a desired one. To solve this issue, we introduce
counterfactual explanations for QBAFs. We discuss problem variants and propose
an iterative algorithm named Counterfactual Explanations for Quantitative
bipolar Argumentation frameworks (CE-QArg). CE-QArg can identify valid and
cost-effective counterfactual explanations based on two core modules, polarity
and priority, which help determine the updating direction and magnitude for
each argument, respectively. We discuss some formal properties of our
counterfactual explanations and empirically evaluate CE-QArg on randomly
generated QBAFs.",http://arxiv.org/pdf/2407.08497v1,2024-07-11,2407.08497v1,CE-QArg: Counterfactual Explanations for Quantitative Bipolar Argumentation Frameworks (Technical Report),gpt-4,highly irrelevant,The paper focuses on the topic of counterfactual explanations for Quantitative Bipolar Argumentation Frameworks and doesn't mention any form of prompting or prompt engineering.
Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024,['Ilias Chalkidis'],"Instruction-finetuned Large Language Models exhibit unprecedented Natural
Language Understanding capabilities. Recent work has been exploring political
biases and political reasoning capabilities in LLMs, mainly scoped in the US
context. In light of the recent 2024 European Parliament elections, we are
investigating if LLMs can be used as Voting Advice Applications (VAAs). We
audit MISTRAL and MIXTRAL models and evaluate their accuracy in predicting the
stance of political parties based on the latest ""EU and I"" voting assistance
questionnaire. Furthermore, we explore alternatives to improve models'
performance by augmenting the input context via Retrieval-Augmented Generation
(RAG) relying on web search, and Self-Reflection using staged conversations
that aim to re-collect relevant content from the model's internal memory. We
find that MIXTRAL is highly accurate with an 82% accuracy on average.
Augmenting the input context with expert-curated information can lead to a
significant boost of approx. 9%, which remains an open challenge for automated
approaches.",http://arxiv.org/pdf/2407.08495v1,2024-07-11,2407.08495v1,Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024,gpt-4,highly irrelevant,The paper's focus is on using Large Language Models for predicting political stances and does not mention or involve the concept of hard prefix prompting or prompt engineering.
Lynx: An Open Source Hallucination Evaluation Model,"['Selvan Sunitha Ravi', 'Bartosz Mielczarek', 'Anand Kannappan', 'Douwe Kiela', 'Rebecca Qian']","Retrieval Augmented Generation (RAG) techniques aim to mitigate
hallucinations in Large Language Models (LLMs). However, LLMs can still produce
information that is unsupported or contradictory to the retrieved contexts. We
introduce LYNX, a SOTA hallucination detection LLM that is capable of advanced
reasoning on challenging real-world hallucination scenarios. To evaluate LYNX,
we present HaluBench, a comprehensive hallucination evaluation benchmark,
consisting of 15k samples sourced from various real-world domains. Our
experiment results show that LYNX outperforms GPT-4o, Claude-3-Sonnet, and
closed and open-source LLM-as-a-judge models on HaluBench. We release LYNX,
HaluBench and our evaluation code for public access.",http://arxiv.org/pdf/2407.08488v1,2024-07-11,2407.08488v1,Lynx: An Open Source Hallucination Evaluation Model,gpt-4,highly irrelevant,The paper primarily discusses mitigation of hallucinations in Large Language Models and introduces a hallucination detection model LYNX. It does not cover the topic of hard prefix prompting or prompt engineering.
Robust Generalization of Graph Neural Networks for Carrier Scheduling,"['Daniel F. Perez-Ramirez', 'Carlos Pérez-Penichet', 'Nicolas Tsiftes', 'Dejan Kostic', 'Magnus Boman', 'Thiemo Voigt']","Battery-free sensor tags are devices that leverage backscatter techniques to
communicate with standard IoT devices, thereby augmenting a network's sensing
capabilities in a scalable way. For communicating, a sensor tag relies on an
unmodulated carrier provided by a neighboring IoT device, with a schedule
coordinating this provisioning across the network. Carrier
scheduling--computing schedules to interrogate all sensor tags while minimizing
energy, spectrum utilization, and latency--is an NP-Hard optimization problem.
Recent work introduces learning-based schedulers that achieve resource savings
over a carefully-crafted heuristic, generalizing to networks of up to 60 nodes.
However, we find that their advantage diminishes in networks with hundreds of
nodes, and degrades further in larger setups. This paper introduces
RobustGANTT, a GNN-based scheduler that improves generalization (without
re-training) to networks up to 1000 nodes (100x training topology sizes).
RobustGANTT not only achieves better and more consistent generalization, but
also computes schedules requiring up to 2x less resources than existing
systems. Our scheduler exhibits average runtimes of hundreds of milliseconds,
allowing it to react fast to changing network conditions. Our work not only
improves resource utilization in large-scale backscatter networks, but also
offers valuable insights in learning-based scheduling.",http://arxiv.org/pdf/2407.08479v1,2024-07-11,2407.08479v1,Robust Generalization of Graph Neural Networks for Carrier Scheduling,gpt-4,highly irrelevant,The paper focuses on network scheduling and does not discuss any form of prompting or prompt engineering.
Investigating Public Fine-Tuning Datasets: A Complex Review of Current Practices from a Construction Perspective,"['Runyuan Ma', 'Wei Li', 'Fukai Shang']","With the rapid development of the large model domain, research related to
fine-tuning has concurrently seen significant advancement, given that
fine-tuning is a constituent part of the training process for large-scale
models. Data engineering plays a fundamental role in the training process of
models, which includes data infrastructure, data processing, etc. Data during
fine-tuning likewise forms the base for large models. In order to embrace the
power and explore new possibilities of fine-tuning datasets, this paper reviews
current public fine-tuning datasets from the perspective of data construction.
An overview of public fine-tuning datasets from two sides: evolution and
taxonomy, is provided in this review, aiming to chart the development
trajectory. Construction techniques and methods for public fine-tuning datasets
of Large Language Models (LLMs), including data generation and data
augmentation among others, are detailed. This elaboration follows the
aforementioned taxonomy, specifically across demonstration, comparison, and
generalist categories. Additionally, a category tree of data generation
techniques has been abstracted in our review to assist researchers in gaining a
deeper understanding of fine-tuning datasets from the construction dimension.
Our review also summarizes the construction features in different data
preparation phases of current practices in this field, aiming to provide a
comprehensive overview and inform future research. Fine-tuning dataset
practices, encompassing various data modalities, are also discussed from a
construction perspective in our review. Towards the end of the article, we
offer insights and considerations regarding the future construction and
developments of fine-tuning datasets.",http://arxiv.org/pdf/2407.08475v1,2024-07-11,2407.08475v1,Investigating Public Fine-Tuning Datasets: A Complex Review of Current Practices from a Construction Perspective,gpt-4,highly irrelevant,"This paper focuses on the review of public fine-tuning datasets from a construction perspective, detailing data engineering practices, data generation, and data augmentation techniques. However, there is no specific mention or implication of hard prefix prompting or prompt engineering."
Natural language is not enough: Benchmarking multi-modal generative AI for Verilog generation,"['Kaiyan Chang', 'Zhirong Chen', 'Yunhao Zhou', 'Wenlong Zhu', 'kun wang', 'Haobo Xu', 'Cangyuan Li', 'Mengdi Wang', 'Shengwen Liang', 'Huawei Li', 'Yinhe Han', 'Ying Wang']","Natural language interfaces have exhibited considerable potential in the
automation of Verilog generation derived from high-level specifications through
the utilization of large language models, garnering significant attention.
Nevertheless, this paper elucidates that visual representations contribute
essential contextual information critical to design intent for hardware
architectures possessing spatial complexity, potentially surpassing the
efficacy of natural-language-only inputs. Expanding upon this premise, our
paper introduces an open-source benchmark for multi-modal generative models
tailored for Verilog synthesis from visual-linguistic inputs, addressing both
singular and complex modules. Additionally, we introduce an open-source visual
and natural language Verilog query language framework to facilitate efficient
and user-friendly multi-modal queries. To evaluate the performance of the
proposed multi-modal hardware generative AI in Verilog generation tasks, we
compare it with a popular method that relies solely on natural language. Our
results demonstrate a significant accuracy improvement in the multi-modal
generated Verilog compared to queries based solely on natural language. We hope
to reveal a new approach to hardware design in the large-hardware-design-model
era, thereby fostering a more diversified and productive approach to hardware
design.",http://arxiv.org/pdf/2407.08473v1,2024-07-11,2407.08473v1,Natural language is not enough: Benchmarking multi-modal generative AI for Verilog generation,gpt-4,highly irrelevant,The paper focuses on the use of multi-modal generative models for Verilog synthesis and not on the use of prompting or prompt engineering techniques.
Brain Tumor Segmentation in MRI Images with 3D U-Net and Contextual Transformer,"['Thien-Qua T. Nguyen', 'Hieu-Nghia Nguyen', 'Thanh-Hieu Bui', 'Thien B. Nguyen-Tat', 'Vuong M. Ngo']","This research presents an enhanced approach for precise segmentation of brain
tumor masses in magnetic resonance imaging (MRI) using an advanced 3D-UNet
model combined with a Context Transformer (CoT). By architectural expansion
CoT, the proposed model extends its architecture to a 3D format, integrates it
smoothly with the base model to utilize the complex contextual information
found in MRI scans, emphasizing how elements rely on each other across an
extended spatial range. The proposed model synchronizes tumor mass
characteristics from CoT, mutually reinforcing feature extraction, facilitating
the precise capture of detailed tumor mass structures, including location,
size, and boundaries. Several experimental results present the outstanding
segmentation performance of the proposed method in comparison to current
state-of-the-art approaches, achieving Dice score of 82.0%, 81.5%, 89.0% for
Enhancing Tumor, Tumor Core and Whole Tumor, respectively, on BraTS2019.",http://arxiv.org/pdf/2407.08470v1,2024-07-11,2407.08470v1,Brain Tumor Segmentation in MRI Images with 3D U-Net and Contextual Transformer,gpt-4,highly irrelevant,"This paper primarily focuses on the application of 3D-UNet model and Contextual Transformer (CoT) for the segmentation of brain tumor masses from MRI images, with no mention or relevance to hard prefix prompting or prompt engineering in any context."
TLDR: Unsupervised Goal-Conditioned RL via Temporal Distance-Aware Representations,"['Junik Bae', 'Kwanyoung Park', 'Youngwoon Lee']","Unsupervised goal-conditioned reinforcement learning (GCRL) is a promising
paradigm for developing diverse robotic skills without external supervision.
However, existing unsupervised GCRL methods often struggle to cover a wide
range of states in complex environments due to their limited exploration and
sparse or noisy rewards for GCRL. To overcome these challenges, we propose a
novel unsupervised GCRL method that leverages TemporaL Distance-aware
Representations (TLDR). TLDR selects faraway goals to initiate exploration and
computes intrinsic exploration rewards and goal-reaching rewards, based on
temporal distance. Specifically, our exploration policy seeks states with large
temporal distances (i.e. covering a large state space), while the
goal-conditioned policy learns to minimize the temporal distance to the goal
(i.e. reaching the goal). Our experimental results in six simulated robotic
locomotion environments demonstrate that our method significantly outperforms
previous unsupervised GCRL methods in achieving a wide variety of states.",http://arxiv.org/pdf/2407.08464v1,2024-07-11,2407.08464v1,TLDR: Unsupervised Goal-Conditioned RL via Temporal Distance-Aware Representations,gpt-4,highly irrelevant,"This paper focuses on unsupervised goal-conditioned reinforcement learning, specifically for robotic locomotion environments, and does not discuss hard prefix prompting or prompt engineering."
Model Tells You Where to Merge: Adaptive KV Cache Merging for LLMs on Long-Context Tasks,"['Zheng Wang', 'Boxiao Jin', 'Zhongzhi Yu', 'Minjia Zhang']","How to efficiently serve Large Language Models (LLMs) has become a pressing
issue because of their huge computational cost in their autoregressive
generation process. To mitigate computational costs, LLMs often employ the KV
Cache technique to improve the generation speed. While improving the
computational efficiency, the storage requirements of the KV cache are
substantial, particularly in long-context scenarios, leading to significant
memory consumption. Existing KV cache eviction methods often degrade the
performance of LLMs in long-context scenarios due to the information loss
introduced by eviction. In this paper, we propose a novel KV cache merging
approach, called KVMerger, to achieve adaptive KV cache compression for
long-context tasks without significant performance degradation under
constrained memory budgets. Our approach is inspired by the intriguing
observation that key states exhibit high similarity at the token level within a
single sequence. To facilitate merging, we develop an effective yet
straightforward merging set identification algorithm to identify suitable KV
states for merging. Our merging set identification algorithm stimulates the
second observation that KV cache sparsity, from similarity perspective, is
independent of the dataset and remains persistent at the model level.
Subsequently, we propose a Gaussian kernel weighted merging algorithm to
selectively merge all states within each merging set. We conduct extensive
experiments to demonstrate the effectiveness of KVMerger for long-context tasks
under constrained memory budgets, applying it to models including
Llama2-7B-chat and Llama2-13B-chat. Using the LongBench and ZeroScroll
benchmarks, we compare our method with other KV cache compression techniques,
including H2O and CaM, showing that our method achieves superior performance
across tasks with both 50% and 35% KV cache budgets.",http://arxiv.org/pdf/2407.08454v1,2024-07-11,2407.08454v1,Model Tells You Where to Merge: Adaptive KV Cache Merging for LLMs on Long-Context Tasks,gpt-4,highly irrelevant,"The paper is mainly focused on the computational costs and efficiency of Large Language Models (LLMs), specifically improving the performance of the KV cache for long-context tasks. It does not seem to mention prompts or prompt engineering at all."
Paving the way toward foundation models for irregular and unaligned Satellite Image Time Series,"['Iris Dumeur', 'Silvia Valero', 'Jordi Inglada']","Although recently several foundation models for satellite remote sensing
imagery have been proposed, they fail to address major challenges of
real/operational applications. Indeed, embeddings that don't take into account
the spectral, spatial and temporal dimensions of the data as well as the
irregular or unaligned temporal sampling are of little use for most real world
uses.As a consequence, we propose an ALIgned Sits Encoder (ALISE), a novel
approach that leverages the spatial, spectral, and temporal dimensions of
irregular and unaligned SITS while producing aligned latent representations.
Unlike SSL models currently available for SITS, ALISE incorporates a flexible
query mechanism to project the SITS into a common and learned temporal
projection space. Additionally, thanks to a multi-view framework, we explore
integration of instance discrimination along a masked autoencoding task to
SITS. The quality of the produced representation is assessed through three
downstream tasks: crop segmentation (PASTIS), land cover segmentation
(MultiSenGE), and a novel crop change detection dataset. Furthermore, the
change detection task is performed without supervision. The results suggest
that the use of aligned representations is more effective than previous SSL
methods for linear probing segmentation tasks.",http://arxiv.org/pdf/2407.08448v1,2024-07-11,2407.08448v1,Paving the way toward foundation models for irregular and unaligned Satellite Image Time Series,gpt-4,highly irrelevant,This paper is focused on foundation models for satellite remote sensing imagery and does not mention or imply anything related to prompt engineering or hard prefix prompting.
How Deep is your Guess? A Fresh Perspective on Deep Learning for Medical Time-Series Imputation,"['Linglong Qian', 'Tao Wang', 'Jun Wang', 'Hugh Logan Ellis', 'Robin Mitra', 'Richard Dobson', 'Zina Ibrahim']","We introduce a novel classification framework for time-series imputation
using deep learning, with a particular focus on clinical data. By identifying
conceptual gaps in the literature and existing reviews, we devise a taxonomy
grounded on the inductive bias of neural imputation frameworks, resulting in a
classification of existing deep imputation strategies based on their
suitability for specific imputation scenarios and data-specific properties. Our
review further examines the existing methodologies employed to benchmark deep
imputation models, evaluating their effectiveness in capturing the missingness
scenarios found in clinical data and emphasising the importance of reconciling
mathematical abstraction with clinical insights. Our classification aims to
serve as a guide for researchers to facilitate the selection of appropriate
deep learning imputation techniques tailored to their specific clinical data.
Our novel perspective also highlights the significance of bridging the gap
between computational methodologies and medical insights to achieve clinically
sound imputation models.",http://arxiv.org/pdf/2407.08442v1,2024-07-11,2407.08442v1,How Deep is your Guess? A Fresh Perspective on Deep Learning for Medical Time-Series Imputation,gpt-4,highly irrelevant,This paper focuses on deep learning for time-series imputation in medical data and does not mention anything regarding hard prefix prompting or prompt engineering.
