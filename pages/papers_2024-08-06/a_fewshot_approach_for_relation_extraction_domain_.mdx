---
title: "A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models"
date: "2024-08-05"
authors: "[, ', V, a, n, n, i,  , Z, a, v, a, r, e, l, l, a, ', ,,  , ', J, u, a, n,  , C, a, r, l, o, s,  , G, a, m, e, r, o, -, S, a, l, i, n, a, s, ', ,,  , ', S, e, r, g, i, o,  , C, o, n, s, o, l, i, ', ]"
---

import Image from 'next/image';

<div className="bg-gray-800 text-white min-h-screen p-8">
  <h1 className="text-4xl font-bold mb-6">A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models</h1>

  <div className="mb-8">
    <Image
      src="/images/papers/A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models.png"
      alt="Paper image"
      width={800}
      height={600}
      layout="responsive"
      className="rounded-lg"
    />
    <p className="text-sm text-gray-400 mt-2">nan</p>
  </div>

  <p className="text-gray-300 mb-2"><strong>Date:</strong> 2024-08-05</p>
  <p className="text-gray-300 italic mb-6"><strong>Authors:</strong> [, ', V, a, n, n, i,  , Z, a, v, a, r, e, l, l, a, ', ,,  , ', J, u, a, n,  , C, a, r, l, o, s,  , G, a, m, e, r, o, -, S, a, l, i, n, a, s, ', ,,  , ', S, e, r, g, i, o,  , C, o, n, s, o, l, i, ', ]</p>

  <div className="bg-gray-700 p-6 rounded-lg mb-8">
    <h2 className="text-2xl font-semibold mb-4">Abstract</h2>
    <p>Knowledge graphs (KGs) have been successfully applied to the analysis of
complex scientific and technological domains, with automatic KG generation
methods typically building upon relation extraction models capturing
fine-grained relations between domain entities in text. While these relations
are fully applicable across scientific areas, existing models are trained on
few domain-specific datasets such as SciERC and do not perform well on new
target domains. In this paper, we experiment with leveraging in-context
learning capabilities of Large Language Models to perform schema-constrained
data annotation, collecting in-domain training instances for a
Transformer-based relation extraction model deployed on titles and abstracts of
research papers in the Architecture, Construction, Engineering and Operations
(AECO) domain. By assessing the performance gain with respect to a baseline
Deep Learning architecture trained on off-domain data, we show that by using a
few-shot learning strategy with structured prompts and only minimal expert
annotation the presented approach can potentially support domain adaptation of
a science KG generation model.</p>
  </div>

  <div className="bg-gray-700 p-6 rounded-lg mb-8">
    <h2 className="text-2xl font-semibold mb-4">AI-Generated Summary</h2>
    <p>The paper includes a mention of using structured prompts for a few-shot learning strategy, which aligns with the concept of hard prefix prompts.</p>
  </div>

  
    href="http://arxiv.org/pdf/2408.02377v1"
    className="bg-blue-500 text-white py-3 px-6 rounded-lg hover:bg-blue-600 transition duration-300 inline-block"
    target="_blank"
    rel="noopener noreferrer"
  >
    Read the full paper
  </a>

  <p className="text-sm text-gray-400 mt-8">
    The summary is AI-generated and may not perfectly reflect the paper's content.
  </p>
</div>
