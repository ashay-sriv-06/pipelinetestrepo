---
title: "PENDRAM: Enabling High-Performance and Energy-Efficient Processing of Deep Neural Networks through a Generalized DRAM Data Mapping Policy"
date: "2024-08-05"
authors: "[, ', R, a, c, h, m, a, d,  , V, i, d, y, a,  , W, i, c, a, k, s, a, n, a,  , P, u, t, r, a, ', ,,  , ', M, u, h, a, m, m, a, d,  , A, b, d, u, l, l, a, h,  , H, a, n, i, f, ', ,,  , ', M, u, h, a, m, m, a, d,  , S, h, a, f, i, q, u, e, ', ]"
---

import Image from 'next/image';

<div className="bg-gray-800 text-white min-h-screen p-8">
  <h1 className="text-4xl font-bold mb-6">PENDRAM: Enabling High-Performance and Energy-Efficient Processing of Deep Neural Networks through a Generalized DRAM Data Mapping Policy</h1>

  <div className="mb-8">
    <Image
      src="/images/papers/PENDRAM_ Enabling High-Performance and Energy-Efficient Processing of Deep Neural Networks through a.png"
      alt="Paper image"
      width={800}
      height={600}
      layout="responsive"
      className="rounded-lg"
    />
    <p className="text-sm text-gray-400 mt-2">nan</p>
  </div>

  <p className="text-gray-300 mb-2"><strong>Date:</strong> 2024-08-05</p>
  <p className="text-gray-300 italic mb-6"><strong>Authors:</strong> [, ', R, a, c, h, m, a, d,  , V, i, d, y, a,  , W, i, c, a, k, s, a, n, a,  , P, u, t, r, a, ', ,,  , ', M, u, h, a, m, m, a, d,  , A, b, d, u, l, l, a, h,  , H, a, n, i, f, ', ,,  , ', M, u, h, a, m, m, a, d,  , S, h, a, f, i, q, u, e, ', ]</p>

  <div className="bg-gray-700 p-6 rounded-lg mb-8">
    <h2 className="text-2xl font-semibold mb-4">Abstract</h2>
    <p>Convolutional Neural Networks (CNNs), a prominent type of Deep Neural
Networks (DNNs), have emerged as a state-of-the-art solution for solving
machine learning tasks. To improve the performance and energy efficiency of CNN
inference, the employment of specialized hardware accelerators is prevalent.
However, CNN accelerators still face performance- and energy-efficiency
challenges due to high off-chip memory (DRAM) access latency and energy, which
are especially crucial for latency- and energy-constrained embedded
applications. Moreover, different DRAM architectures have different profiles of
access latency and energy, thus making it challenging to optimize them for high
performance and energy-efficient CNN accelerators. To address this, we present
PENDRAM, a novel design space exploration methodology that enables
high-performance and energy-efficient CNN acceleration through a generalized
DRAM data mapping policy. Specifically, it explores the impact of different
DRAM data mapping policies and DRAM architectures across different CNN
partitioning and scheduling schemes on the DRAM access latency and energy, then
identifies the pareto-optimal design choices. The experimental results show
that our DRAM data mapping policy improves the energy-delay-product of DRAM
accesses in the CNN accelerator over other mapping policies by up to 96%. In
this manner, our PENDRAM methodology offers high-performance and
energy-efficient CNN acceleration under any given DRAM architectures for
diverse embedded AI applications.</p>
  </div>

  <div className="bg-gray-700 p-6 rounded-lg mb-8">
    <h2 className="text-2xl font-semibold mb-4">AI-Generated Summary</h2>
    <p>The paper is focused on optimizing performance and energy efficiency for convolutional neural networks through hardware acceleration and DRAM data mapping, not on prompt engineering.</p>
  </div>

  
    href="http://arxiv.org/pdf/2408.02412v1"
    className="bg-blue-500 text-white py-3 px-6 rounded-lg hover:bg-blue-600 transition duration-300 inline-block"
    target="_blank"
    rel="noopener noreferrer"
  >
    Read the full paper
  </a>

  <p className="text-sm text-gray-400 mt-8">
    The summary is AI-generated and may not perfectly reflect the paper's content.
  </p>
</div>
