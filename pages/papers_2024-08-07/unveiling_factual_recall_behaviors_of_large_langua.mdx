---
title: "Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons"
date: "2024-08-06"
authors: "[, ', Y, i, f, e, i,  , W, a, n, g, ', ,,  , ', Y, u, h, e, n, g,  , C, h, e, n, ', ,,  , ', W, a, n, t, i, n, g,  , W, e, n, ', ,,  , ', Y, u,  , S, h, e, n, g, ', ,,  , ', L, i, n, j, i, n, g,  , L, i, ', ,,  , ', D, a, n, i, e, l,  , D, a, j, u, n,  , Z, e, n, g, ', ]"
---

import Image from 'next/image';

<div className="bg-gray-800 text-white min-h-screen p-8">
  <h1 className="text-4xl font-bold mb-6">Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons</h1>

  <div className="mb-8">
    <Image
      src="/images/papers/Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons.png"
      alt="Paper image"
      width={800}
      height={600}
      layout="responsive"
      className="rounded-lg"
    />
    <p className="text-sm text-gray-400 mt-2">nan</p>
  </div>

  <p className="text-gray-300 mb-2"><strong>Date:</strong> 2024-08-06</p>
  <p className="text-gray-300 italic mb-6"><strong>Authors:</strong> [, ', Y, i, f, e, i,  , W, a, n, g, ', ,,  , ', Y, u, h, e, n, g,  , C, h, e, n, ', ,,  , ', W, a, n, t, i, n, g,  , W, e, n, ', ,,  , ', Y, u,  , S, h, e, n, g, ', ,,  , ', L, i, n, j, i, n, g,  , L, i, ', ,,  , ', D, a, n, i, e, l,  , D, a, j, u, n,  , Z, e, n, g, ', ]</p>

  <div className="bg-gray-700 p-6 rounded-lg mb-8">
    <h2 className="text-2xl font-semibold mb-4">Abstract</h2>
    <p>In this paper, we investigate whether Large Language Models (LLMs) actively
recall or retrieve their internal repositories of factual knowledge when faced
with reasoning tasks. Through an analysis of LLMs' internal factual recall at
each reasoning step via Knowledge Neurons, we reveal that LLMs fail to harness
the critical factual associations under certain circumstances. Instead, they
tend to opt for alternative, shortcut-like pathways to answer reasoning
questions. By manually manipulating the recall process of parametric knowledge
in LLMs, we demonstrate that enhancing this recall process directly improves
reasoning performance whereas suppressing it leads to notable degradation.
Furthermore, we assess the effect of Chain-of-Thought (CoT) prompting, a
powerful technique for addressing complex reasoning tasks. Our findings
indicate that CoT can intensify the recall of factual knowledge by encouraging
LLMs to engage in orderly and reliable reasoning. Furthermore, we explored how
contextual conflicts affect the retrieval of facts during the reasoning process
to gain a comprehensive understanding of the factual recall behaviors of LLMs.
Code and data will be available soon.</p>
  </div>

  <div className="bg-gray-700 p-6 rounded-lg mb-8">
    <h2 className="text-2xl font-semibold mb-4">AI-Generated Summary</h2>
    <p>The paper discusses Chain-of-Thought (CoT) prompting as a technique for enhancing complex reasoning tasks but doesn't specifically mention hard prefix prompting.</p>
  </div>


    href="http://arxiv.org/pdf/2408.03247v1"
    className="bg-blue-500 text-white py-3 px-6 rounded-lg hover:bg-blue-600 transition duration-300 inline-block"
    target="_blank"
    rel="noopener noreferrer"
  >
    Read the full paper
  </a>

  <p className="text-sm text-gray-400 mt-8">
    The summary is AI-generated and may not perfectly reflect the paper's content.
  </p>
</div>
