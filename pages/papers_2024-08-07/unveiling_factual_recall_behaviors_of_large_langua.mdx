---
title: "Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons"
date: "2024-08-06"
authors: "Yifei Wang, Yuheng Chen, Wanting Wen, Yu Sheng, Linjing Li, Daniel Dajun, and Zeng"
---

import Image from 'next/image';

<div className="bg-gray-800 text-white min-h-screen p-8">
  <h1 className="text-4xl font-bold mb-6">Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons</h1>

  <div className="mb-8">
    {{/* eslint-disable-next-line @next/next/no-img-element */}}
    <img
      src="/images/papers/Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons.png"
      alt="Paper image"
      className="w-full h-auto rounded-lg"
    />
    <p className="text-sm text-gray-400 mt-2">3.
(12)
))
(13)
nguistic
uthentic
shared
Figure 11: Distribution of intermediate layers in all FFNs for Mistral-7B.
</p>
  </div>

  <p className="text-gray-300 mb-2"><strong>Date:</strong> 2024-08-06</p>
  <p className="text-gray-300 italic mb-6"><strong>Authors:</strong> Yifei Wang, Yuheng Chen, Wanting Wen, Yu Sheng, Linjing Li, Daniel Dajun, and Zeng</p>

  <div className="bg-gray-700 p-6 rounded-lg mb-8">
    <h2 className="text-2xl font-semibold mb-4">Abstract</h2>
    <p>In this paper, we investigate whether Large Language Models (LLMs) actively
recall or retrieve their internal repositories of factual knowledge when faced
with reasoning tasks. Through an analysis of LLMs' internal factual recall at
each reasoning step via Knowledge Neurons, we reveal that LLMs fail to harness
the critical factual associations under certain circumstances. Instead, they
tend to opt for alternative, shortcut-like pathways to answer reasoning
questions. By manually manipulating the recall process of parametric knowledge
in LLMs, we demonstrate that enhancing this recall process directly improves
reasoning performance whereas suppressing it leads to notable degradation.
Furthermore, we assess the effect of Chain-of-Thought (CoT) prompting, a
powerful technique for addressing complex reasoning tasks. Our findings
indicate that CoT can intensify the recall of factual knowledge by encouraging
LLMs to engage in orderly and reliable reasoning. Furthermore, we explored how
contextual conflicts affect the retrieval of facts during the reasoning process
to gain a comprehensive understanding of the factual recall behaviors of LLMs.
Code and data will be available soon.</p>
  </div>

  <div className="bg-gray-700 p-6 rounded-lg mb-8">
    <h2 className="text-2xl font-semibold mb-4">AI-Generated Summary</h2>
    <p>The paper discusses the use of 'Chain-of-Thought' prompting technique, which falls under hard prefix prompt engineering.</p>
  </div>

  <p className="text-sm text-gray-400 mt-8 mb-8">
    The summary is AI-generated and may not perfectly reflect the paper's content.
  </p>

  <div className="flex justify-center">
    
      href="http://arxiv.org/pdf/2408.03247v1"
      className="bg-green-500 text-white py-3 px-6 rounded-lg hover:bg-green-600 transition duration-300 inline-block text-center"
      target="_blank"
      rel="noopener noreferrer"
    >
      Read Full Paper
    </a>
  </div>
</div>
