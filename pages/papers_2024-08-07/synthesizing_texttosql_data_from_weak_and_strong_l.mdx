---
title: "Synthesizing Text-to-SQL Data from Weak and Strong LLMs"
date: "2024-08-06"
authors: "Jiaxi Yang, Binyuan Hui, Min Yang, Jian Yang, Junyang Lin, and Chang Zhou"
---

import Image from 'next/image';

<div className="bg-gray-800 text-white min-h-screen p-8">
  <h1 className="text-4xl font-bold mb-6">Synthesizing Text-to-SQL Data from Weak and Strong LLMs</h1>

  <div className="mb-8">
    {{/* eslint-disable-next-line @next/next/no-img-element */}}
    <img
      src="/images/papers/Synthesizing Text-to-SQL Data from Weak and Strong LLMs.png"
      alt="Paper image"
      className="w-full h-auto rounded-lg"
    />
    <p className="text-sm text-gray-400 mt-2">nan</p>
  </div>

  <p className="text-gray-300 mb-2"><strong>Date:</strong> 2024-08-06</p>
  <p className="text-gray-300 italic mb-6"><strong>Authors:</strong> Jiaxi Yang, Binyuan Hui, Min Yang, Jian Yang, Junyang Lin, and Chang Zhou</p>

  <div className="bg-gray-700 p-6 rounded-lg mb-8">
    <h2 className="text-2xl font-semibold mb-4">Abstract</h2>
    <p>The capability gap between open-source and closed-source large language
models (LLMs) remains a challenge in text-to-SQL tasks. In this paper, we
introduce a synthetic data approach that combines data produced by larger, more
powerful models (strong models) with error information data generated by
smaller, not well-aligned models (weak models). The method not only enhances
the domain generalization of text-to-SQL models but also explores the potential
of error data supervision through preference learning. Furthermore, we employ
the synthetic data approach for instruction tuning on open-source LLMs,
resulting SENSE, a specialized text-to-SQL model. The effectiveness of SENSE is
demonstrated through state-of-the-art results on the SPIDER and BIRD
benchmarks, bridging the performance gap between open-source models and methods
prompted by closed-source models.</p>
  </div>

  <div className="bg-gray-700 p-6 rounded-lg mb-8">
    <h2 className="text-2xl font-semibold mb-4">AI-Generated Summary</h2>
    <p>The paper focuses on synthetic data approaches and model tuning for text-to-SQL tasks and while it mentions prompt in the context of closed-source models, it's unclear if this pertains to hard prefix prompting.</p>
  </div>

  <p className="text-sm text-gray-400 mt-8 mb-8">
    The summary is AI-generated and may not perfectly reflect the paper's content.
  </p>

  <div className="flex justify-center">
    
      href="http://arxiv.org/pdf/2408.03256v1"
      className="bg-green-500 text-white py-3 px-6 rounded-lg hover:bg-green-600 transition duration-300 inline-block text-center"
      target="_blank"
      rel="noopener noreferrer"
    >
      Read Full Paper
    </a>
  </div>
</div>
